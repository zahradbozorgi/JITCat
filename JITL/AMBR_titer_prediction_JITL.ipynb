{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a683265-5556-4ea9-b537-477150acee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "# from torch import cdist\n",
    "# import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981294f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtaidistance import dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348c0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from databricks import sql\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9154f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303f38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d94dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.python.framework.errors_impl import InvalidArgumentError\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e15da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import math\n",
    "# from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83db0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path().cwd()\n",
    "while not ROOT_DIR.joinpath(\"data\").exists():\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "401acdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMBR\n",
      "CSL312\n",
      "Astrazeneca\n",
      "bpic2011_f1\n",
      "bpic2011_f2\n",
      "bpic2011_f3\n",
      "bpic2011_f4\n"
     ]
    }
   ],
   "source": [
    "from data import EncoderFactory\n",
    "from data import DatasetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73759837",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id_col = \"UID\"\n",
    "timestamp_col = \"timestamp\"\n",
    "target_col = \"titre(g/l)\"\n",
    "work_day_col = \"working day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce988d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed/ambr_preprocessed.csv')\n",
    "df[case_id_col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0bfa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glutamate(g/l)</th>\n",
       "      <th>UID</th>\n",
       "      <th>ammonia(g/l)</th>\n",
       "      <th>viable cell density(1e6 cells/ml)</th>\n",
       "      <th>lactate(g/l)</th>\n",
       "      <th>ph</th>\n",
       "      <th>glucose(g/l)</th>\n",
       "      <th>glutamine(g/l)</th>\n",
       "      <th>working day</th>\n",
       "      <th>viability(%)</th>\n",
       "      <th>titre(g/l)</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.328100</td>\n",
       "      <td>X5272_1</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.18</td>\n",
       "      <td>7.518035</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.046765</td>\n",
       "      <td>0</td>\n",
       "      <td>98.1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.169200</td>\n",
       "      <td>X5272_1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0033</td>\n",
       "      <td>0.51</td>\n",
       "      <td>7.473426</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.046765</td>\n",
       "      <td>1</td>\n",
       "      <td>98.5583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.406079</td>\n",
       "      <td>X5272_1</td>\n",
       "      <td>0.025434</td>\n",
       "      <td>2.4509</td>\n",
       "      <td>1.09</td>\n",
       "      <td>7.315561</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.062840</td>\n",
       "      <td>2</td>\n",
       "      <td>98.6044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.467873</td>\n",
       "      <td>X5272_1</td>\n",
       "      <td>0.040406</td>\n",
       "      <td>5.6209</td>\n",
       "      <td>2.40</td>\n",
       "      <td>6.919863</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.137372</td>\n",
       "      <td>3</td>\n",
       "      <td>97.9084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.526725</td>\n",
       "      <td>X5272_1</td>\n",
       "      <td>0.048343</td>\n",
       "      <td>10.5987</td>\n",
       "      <td>2.93</td>\n",
       "      <td>6.892140</td>\n",
       "      <td>4.19</td>\n",
       "      <td>0.140294</td>\n",
       "      <td>4</td>\n",
       "      <td>97.7362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>0.545852</td>\n",
       "      <td>X5363_9</td>\n",
       "      <td>0.041128</td>\n",
       "      <td>7.4617</td>\n",
       "      <td>2.02</td>\n",
       "      <td>7.006278</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.263052</td>\n",
       "      <td>10</td>\n",
       "      <td>84.4259</td>\n",
       "      <td>1.770021</td>\n",
       "      <td>2019-08-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>0.545852</td>\n",
       "      <td>X5363_9</td>\n",
       "      <td>0.058264</td>\n",
       "      <td>5.9781</td>\n",
       "      <td>1.74</td>\n",
       "      <td>6.949349</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.263052</td>\n",
       "      <td>11</td>\n",
       "      <td>76.3473</td>\n",
       "      <td>1.786633</td>\n",
       "      <td>2019-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0.545852</td>\n",
       "      <td>X5363_9</td>\n",
       "      <td>0.062052</td>\n",
       "      <td>5.8575</td>\n",
       "      <td>1.55</td>\n",
       "      <td>6.993632</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.263052</td>\n",
       "      <td>12</td>\n",
       "      <td>71.2714</td>\n",
       "      <td>2.046050</td>\n",
       "      <td>2019-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>0.545852</td>\n",
       "      <td>X5363_9</td>\n",
       "      <td>0.064938</td>\n",
       "      <td>4.5045</td>\n",
       "      <td>0.99</td>\n",
       "      <td>7.141263</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.263052</td>\n",
       "      <td>13</td>\n",
       "      <td>64.1087</td>\n",
       "      <td>2.231495</td>\n",
       "      <td>2019-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>0.545852</td>\n",
       "      <td>X5363_9</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>4.4777</td>\n",
       "      <td>0.75</td>\n",
       "      <td>7.132508</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.263052</td>\n",
       "      <td>14</td>\n",
       "      <td>61.2741</td>\n",
       "      <td>2.508989</td>\n",
       "      <td>2019-08-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1782 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      glutamate(g/l)      UID  ammonia(g/l)  \\\n",
       "0           0.328100  X5272_1      0.007576   \n",
       "1           0.169200  X5272_1      0.000000   \n",
       "2           0.406079  X5272_1      0.025434   \n",
       "3           0.467873  X5272_1      0.040406   \n",
       "4           0.526725  X5272_1      0.048343   \n",
       "...              ...      ...           ...   \n",
       "1777        0.545852  X5363_9      0.041128   \n",
       "1778        0.545852  X5363_9      0.058264   \n",
       "1779        0.545852  X5363_9      0.062052   \n",
       "1780        0.545852  X5363_9      0.064938   \n",
       "1781        0.545852  X5363_9      0.063856   \n",
       "\n",
       "      viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       "0                                0.4977          0.18  7.518035          6.12   \n",
       "1                                1.0033          0.51  7.473426          6.07   \n",
       "2                                2.4509          1.09  7.315561          5.00   \n",
       "3                                5.6209          2.40  6.919863          3.15   \n",
       "4                               10.5987          2.93  6.892140          4.19   \n",
       "...                                 ...           ...       ...           ...   \n",
       "1777                             7.4617          2.02  7.006278          1.48   \n",
       "1778                             5.9781          1.74  6.949349          1.64   \n",
       "1779                             5.8575          1.55  6.993632          0.69   \n",
       "1780                             4.5045          0.99  7.141263          0.07   \n",
       "1781                             4.4777          0.75  7.132508          4.08   \n",
       "\n",
       "      glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \n",
       "0           0.046765            0       98.1579         NaN  2019-08-15  \n",
       "1           0.046765            1       98.5583         NaN  2019-08-16  \n",
       "2           0.062840            2       98.6044         NaN  2019-08-17  \n",
       "3           0.137372            3       97.9084         NaN  2019-08-18  \n",
       "4           0.140294            4       97.7362         NaN  2019-08-19  \n",
       "...              ...          ...           ...         ...         ...  \n",
       "1777        0.263052           10       84.4259    1.770021  2019-08-25  \n",
       "1778        0.263052           11       76.3473    1.786633  2019-08-26  \n",
       "1779        0.263052           12       71.2714    2.046050  2019-08-27  \n",
       "1780        0.263052           13       64.1087    2.231495  2019-08-28  \n",
       "1781        0.263052           14       61.2741    2.508989  2019-08-29  \n",
       "\n",
       "[1782 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67396428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[case_id_col, work_day_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f21fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_ids = df[df[target_col].isnull()][case_id_col].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9047ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[case_id_col].isin(null_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7884a4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[case_id_col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a21d9121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['glutamate(g/l)', 'UID', 'ammonia(g/l)',\n",
       "       'viable cell density(1e6 cells/ml)', 'lactate(g/l)', 'ph',\n",
       "       'glucose(g/l)', 'glutamine(g/l)', 'working day', 'viability(%)',\n",
       "       'titre(g/l)', 'timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee9017",
   "metadata": {},
   "source": [
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f07f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61f76d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = ['glutamate(g/l)', 'ammonia(g/l)',\n",
    "       'viable cell density(1e6 cells/ml)', 'lactate(g/l)', 'ph',\n",
    "       'glucose(g/l)', 'glutamine(g/l)','viability(%)',\n",
    "       'titre(g/l)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c986cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glutamate(g/l)', 'ammonia(g/l)', 'viable cell density(1e6 cells/ml)', 'lactate(g/l)', 'ph', 'glucose(g/l)', 'glutamine(g/l)', 'viability(%)']\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in columns_to_normalize if x != target_col]\n",
    "print(features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bae39c13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming your data is stored in a DataFrame called 'data'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m average_max_work_day \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(case_id_col)[work_day_col]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Maximum work_day_col:\u001b[39m\u001b[38;5;124m\"\u001b[39m, average_max_work_day)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming your data is stored in a DataFrame called 'data'\n",
    "average_max_work_day = data.groupby(case_id_col)[work_day_col].max().mean()\n",
    "\n",
    "print(\"Average Maximum work_day_col:\", average_max_work_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62f2a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "UIDs = df_normalized[case_id_col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d7ce453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalers = {}\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for column in columns_to_normalize:\n",
    "    scalers[column] = StandardScaler()\n",
    "    df_normalized[column] = scalers[column].fit_transform(df_normalized[[column]])\n",
    "\n",
    "# Normalize the selected columns\n",
    "# df_normalized[columns_to_normalize] = scaler.fit_transform(df_normalized[columns_to_normalize])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d5c8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "method = 'Catboost'\n",
    "config = 'no_encoding_no_bucketing'\n",
    "# config = 'no_encoding_bucketing'\n",
    "# config = 'encoding_no_bucketing'\n",
    "# config = 'encoding_bucketing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "994035a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/processed/databricks_preprocessed_forTiter_normalised_withClusters_10Feb25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84142777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.drop(columns=['Titer (g/L) original', 'Cluster'], inplace=True)\n",
    "# df.drop(columns=['range_indicator'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e637fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized = pd.read_csv('data/processed/CSL312_preprocessed_forTiter_normalised_6Feb25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bdc69871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Identification No.', 'Time (hrs)',\n",
       "       'Product Content pre clean up (g/L)', 'Working Day (d)', 'BR Temp (°C)',\n",
       "       'pH (Internal)', 'Viability (%)', 'VCD (10^6 cells/mL)',\n",
       "       'Glucose (g/L)', 'Lactate (g/L)', 'Ca2+ (g/L)', 'Glutamine (g/L)',\n",
       "       'Glutamate (g/L)', 'Na+ (g/L)', 'K+ (g/L)', 'NH4+ (g/L)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "876f110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "df_normalized['Identification No.'] = df_normalized['Identification No.'].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4197382d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identification No.</th>\n",
       "      <th>Time (hrs)</th>\n",
       "      <th>Product Content pre clean up (g/L)</th>\n",
       "      <th>Working Day (d)</th>\n",
       "      <th>BR Temp (°C)</th>\n",
       "      <th>pH (Internal)</th>\n",
       "      <th>Viability (%)</th>\n",
       "      <th>VCD (10^6 cells/mL)</th>\n",
       "      <th>Glucose (g/L)</th>\n",
       "      <th>Lactate (g/L)</th>\n",
       "      <th>Ca2+ (g/L)</th>\n",
       "      <th>Glutamine (g/L)</th>\n",
       "      <th>Glutamate (g/L)</th>\n",
       "      <th>Na+ (g/L)</th>\n",
       "      <th>K+ (g/L)</th>\n",
       "      <th>NH4+ (g/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.087131</td>\n",
       "      <td>0</td>\n",
       "      <td>1.056810</td>\n",
       "      <td>1.327097</td>\n",
       "      <td>0.537907</td>\n",
       "      <td>-1.635679</td>\n",
       "      <td>1.621778</td>\n",
       "      <td>-1.195156</td>\n",
       "      <td>-0.007709</td>\n",
       "      <td>-0.793751</td>\n",
       "      <td>0.313125</td>\n",
       "      <td>0.585203</td>\n",
       "      <td>-2.197873</td>\n",
       "      <td>-1.826047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...</td>\n",
       "      <td>22.28</td>\n",
       "      <td>-1.042176</td>\n",
       "      <td>1</td>\n",
       "      <td>1.031827</td>\n",
       "      <td>1.327097</td>\n",
       "      <td>0.558432</td>\n",
       "      <td>-1.557811</td>\n",
       "      <td>1.406825</td>\n",
       "      <td>-0.994354</td>\n",
       "      <td>-0.007709</td>\n",
       "      <td>-0.793751</td>\n",
       "      <td>0.374743</td>\n",
       "      <td>0.690240</td>\n",
       "      <td>-2.211087</td>\n",
       "      <td>-1.476049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...</td>\n",
       "      <td>46.08</td>\n",
       "      <td>-1.003795</td>\n",
       "      <td>2</td>\n",
       "      <td>1.031827</td>\n",
       "      <td>-0.012148</td>\n",
       "      <td>0.650795</td>\n",
       "      <td>-1.352296</td>\n",
       "      <td>0.659161</td>\n",
       "      <td>-0.426871</td>\n",
       "      <td>-0.007709</td>\n",
       "      <td>-0.344009</td>\n",
       "      <td>0.297720</td>\n",
       "      <td>0.752027</td>\n",
       "      <td>-2.164839</td>\n",
       "      <td>-0.795498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...</td>\n",
       "      <td>69.65</td>\n",
       "      <td>-0.926388</td>\n",
       "      <td>3</td>\n",
       "      <td>1.031827</td>\n",
       "      <td>-1.351394</td>\n",
       "      <td>0.650795</td>\n",
       "      <td>-0.968536</td>\n",
       "      <td>-0.153923</td>\n",
       "      <td>0.062037</td>\n",
       "      <td>-0.006285</td>\n",
       "      <td>0.426978</td>\n",
       "      <td>0.328529</td>\n",
       "      <td>0.677883</td>\n",
       "      <td>-2.170124</td>\n",
       "      <td>0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...</td>\n",
       "      <td>93.63</td>\n",
       "      <td>-0.775909</td>\n",
       "      <td>4</td>\n",
       "      <td>1.021833</td>\n",
       "      <td>-1.649004</td>\n",
       "      <td>0.671320</td>\n",
       "      <td>-0.469905</td>\n",
       "      <td>-1.275418</td>\n",
       "      <td>0.044576</td>\n",
       "      <td>-0.002012</td>\n",
       "      <td>0.459102</td>\n",
       "      <td>0.058951</td>\n",
       "      <td>1.023889</td>\n",
       "      <td>-2.162196</td>\n",
       "      <td>0.643381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>6043d134d5716658e65a69bf75eec99b33ca07dce1d902...</td>\n",
       "      <td>188.78</td>\n",
       "      <td>0.885811</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.966839</td>\n",
       "      <td>0.136657</td>\n",
       "      <td>0.363444</td>\n",
       "      <td>1.104122</td>\n",
       "      <td>0.350750</td>\n",
       "      <td>-0.147495</td>\n",
       "      <td>-0.031921</td>\n",
       "      <td>-0.568880</td>\n",
       "      <td>-1.034768</td>\n",
       "      <td>0.165052</td>\n",
       "      <td>0.566476</td>\n",
       "      <td>-0.231613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>6043d134d5716658e65a69bf75eec99b33ca07dce1d902...</td>\n",
       "      <td>214.63</td>\n",
       "      <td>1.397926</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.016806</td>\n",
       "      <td>0.434267</td>\n",
       "      <td>0.240294</td>\n",
       "      <td>1.168448</td>\n",
       "      <td>-1.125885</td>\n",
       "      <td>-0.531637</td>\n",
       "      <td>-0.033345</td>\n",
       "      <td>-0.761627</td>\n",
       "      <td>-1.050173</td>\n",
       "      <td>0.183588</td>\n",
       "      <td>0.731650</td>\n",
       "      <td>-0.464945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>6043d134d5716658e65a69bf75eec99b33ca07dce1d902...</td>\n",
       "      <td>238.02</td>\n",
       "      <td>1.676235</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.966839</td>\n",
       "      <td>0.186259</td>\n",
       "      <td>-0.242045</td>\n",
       "      <td>1.118220</td>\n",
       "      <td>0.528320</td>\n",
       "      <td>-0.627673</td>\n",
       "      <td>-0.034769</td>\n",
       "      <td>-0.793751</td>\n",
       "      <td>-1.050173</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.665580</td>\n",
       "      <td>-0.445501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>6043d134d5716658e65a69bf75eec99b33ca07dce1d902...</td>\n",
       "      <td>262.90</td>\n",
       "      <td>2.189987</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.966839</td>\n",
       "      <td>0.632674</td>\n",
       "      <td>-0.847534</td>\n",
       "      <td>1.062861</td>\n",
       "      <td>-0.882895</td>\n",
       "      <td>-0.601481</td>\n",
       "      <td>-0.031921</td>\n",
       "      <td>-0.793751</td>\n",
       "      <td>-1.050173</td>\n",
       "      <td>-0.267455</td>\n",
       "      <td>0.641795</td>\n",
       "      <td>-0.445501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>6043d134d5716658e65a69bf75eec99b33ca07dce1d902...</td>\n",
       "      <td>287.58</td>\n",
       "      <td>1.871837</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.966839</td>\n",
       "      <td>0.682276</td>\n",
       "      <td>-1.432498</td>\n",
       "      <td>0.829917</td>\n",
       "      <td>0.976918</td>\n",
       "      <td>-0.732439</td>\n",
       "      <td>-0.031921</td>\n",
       "      <td>-0.793751</td>\n",
       "      <td>-1.050173</td>\n",
       "      <td>-0.372493</td>\n",
       "      <td>0.422444</td>\n",
       "      <td>-0.289946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Identification No.  Time (hrs)  \\\n",
       "0     eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...        0.75   \n",
       "1     eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...       22.28   \n",
       "2     eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...       46.08   \n",
       "3     eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...       69.65   \n",
       "4     eac4c7a9387af7885a6eac0d7e662ec6ba71ab4ebff047...       93.63   \n",
       "...                                                 ...         ...   \n",
       "1941  6043d134d5716658e65a69bf75eec99b33ca07dce1d902...      188.78   \n",
       "1942  6043d134d5716658e65a69bf75eec99b33ca07dce1d902...      214.63   \n",
       "1943  6043d134d5716658e65a69bf75eec99b33ca07dce1d902...      238.02   \n",
       "1944  6043d134d5716658e65a69bf75eec99b33ca07dce1d902...      262.90   \n",
       "1945  6043d134d5716658e65a69bf75eec99b33ca07dce1d902...      287.58   \n",
       "\n",
       "      Product Content pre clean up (g/L)  Working Day (d)  BR Temp (°C)  \\\n",
       "0                              -1.087131                0      1.056810   \n",
       "1                              -1.042176                1      1.031827   \n",
       "2                              -1.003795                2      1.031827   \n",
       "3                              -0.926388                3      1.031827   \n",
       "4                              -0.775909                4      1.021833   \n",
       "...                                  ...              ...           ...   \n",
       "1941                            0.885811                8     -0.966839   \n",
       "1942                            1.397926                9     -1.016806   \n",
       "1943                            1.676235               10     -0.966839   \n",
       "1944                            2.189987               11     -0.966839   \n",
       "1945                            1.871837               12     -0.966839   \n",
       "\n",
       "      pH (Internal)  Viability (%)  VCD (10^6 cells/mL)  Glucose (g/L)  \\\n",
       "0          1.327097       0.537907            -1.635679       1.621778   \n",
       "1          1.327097       0.558432            -1.557811       1.406825   \n",
       "2         -0.012148       0.650795            -1.352296       0.659161   \n",
       "3         -1.351394       0.650795            -0.968536      -0.153923   \n",
       "4         -1.649004       0.671320            -0.469905      -1.275418   \n",
       "...             ...            ...                  ...            ...   \n",
       "1941       0.136657       0.363444             1.104122       0.350750   \n",
       "1942       0.434267       0.240294             1.168448      -1.125885   \n",
       "1943       0.186259      -0.242045             1.118220       0.528320   \n",
       "1944       0.632674      -0.847534             1.062861      -0.882895   \n",
       "1945       0.682276      -1.432498             0.829917       0.976918   \n",
       "\n",
       "      Lactate (g/L)  Ca2+ (g/L)  Glutamine (g/L)  Glutamate (g/L)  Na+ (g/L)  \\\n",
       "0         -1.195156   -0.007709        -0.793751         0.313125   0.585203   \n",
       "1         -0.994354   -0.007709        -0.793751         0.374743   0.690240   \n",
       "2         -0.426871   -0.007709        -0.344009         0.297720   0.752027   \n",
       "3          0.062037   -0.006285         0.426978         0.328529   0.677883   \n",
       "4          0.044576   -0.002012         0.459102         0.058951   1.023889   \n",
       "...             ...         ...              ...              ...        ...   \n",
       "1941      -0.147495   -0.031921        -0.568880        -1.034768   0.165052   \n",
       "1942      -0.531637   -0.033345        -0.761627        -1.050173   0.183588   \n",
       "1943      -0.627673   -0.034769        -0.793751        -1.050173   0.016764   \n",
       "1944      -0.601481   -0.031921        -0.793751        -1.050173  -0.267455   \n",
       "1945      -0.732439   -0.031921        -0.793751        -1.050173  -0.372493   \n",
       "\n",
       "      K+ (g/L)  NH4+ (g/L)  \n",
       "0    -2.197873   -1.826047  \n",
       "1    -2.211087   -1.476049  \n",
       "2    -2.164839   -0.795498  \n",
       "3    -2.170124    0.001719  \n",
       "4    -2.162196    0.643381  \n",
       "...        ...         ...  \n",
       "1941  0.566476   -0.231613  \n",
       "1942  0.731650   -0.464945  \n",
       "1943  0.665580   -0.445501  \n",
       "1944  0.641795   -0.445501  \n",
       "1945  0.422444   -0.289946  \n",
       "\n",
       "[1946 rows x 16 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a8529fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.to_csv('data/processed/CSL312_anonymised_normalised.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0729d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from processors.AMBRProcessor import AMBRProcessor\n",
    "# from data.dataset_confs import dataset_configs\n",
    "\n",
    "# config = dataset_configs['CSL_5L']\n",
    "results = []\n",
    "use_encoding = False\n",
    "use_bucketing = False\n",
    "num_nearest_neighbors = 400\n",
    "distance_metric = 'cosine_expotential'\n",
    "\n",
    "processor = AMBRProcessor(\"AMBR\", use_encoding, use_bucketing, num_nearest_neighbors, distance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8709bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ baseline ############\n",
    "results = []\n",
    "method = 'Catboost'\n",
    "config = 'no_encoding_no_bucketing'\n",
    "# config = 'no_encoding_bucketing'\n",
    "# config = 'encoding_no_bucketing'\n",
    "# config = 'encoding_bucketing'\n",
    "\n",
    "data = df_normalized.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "data['Target'] = data.groupby(case_id_col)[target_col].shift(-1)\n",
    "# data['Target_orig'] = data.groupby(case_id_col)['Titer (g/L) original'].shift(-1)\n",
    "data['Target'] = data.groupby(case_id_col)['Target'].ffill()\n",
    "# data['Target_orig'] = data.groupby(case_id_col)['Target_orig'].ffill()\n",
    "\n",
    "historic, current = processor.split_data(data, train_ratio=0.5, split=\"temporal\")\n",
    "historic.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort', inplace=True)\n",
    "current.sort_values([timestamp_col], ascending=True, kind='mergesort', inplace=True)\n",
    "\n",
    "if config == 'no_encoding_bucketing' or config == 'encoding_bucketing':\n",
    "    features_used = features + ['Cluster']\n",
    "else:\n",
    "    features_used = features\n",
    "\n",
    "\n",
    "for index, row in current.iterrows():\n",
    "\n",
    "    target = historic['Target'].values\n",
    "    target_test = row['Target']\n",
    "\n",
    "    if target_test is None:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    if method == 'Catboost':\n",
    "        # Create the CatBoostRegressor model\n",
    "        model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='MAE', verbose=0, random_state=123)\n",
    "        model.fit(historic[features_used], target)\n",
    "\n",
    "    if method == 'HMM':\n",
    "        # Create an instance of the HMM model\n",
    "        model = hmm.GaussianHMM(n_components=7)  # Specify the number of hidden states\n",
    "        model.fit(historic[features_used])\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    preds = model.predict(row[features_used])\n",
    "\n",
    "    row['predicted_value'] = preds\n",
    "    results.append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fa195cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = pd.DataFrame(results)\n",
    "# .to_csv(f'data/processed/predictions_{method}_{config}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0b85663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.391159610128279\n",
      "MSE: 0.37356086475686084\n",
      "RMSE: 0.6111962571522022\n",
      "R2: 0.6711037715008926\n",
      "MAPE: 0.6198759090047311\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(baseline_results[\"Target\"], baseline_results[\"predicted_value\"])\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(baseline_results[\"Target\"], baseline_results[\"predicted_value\"], squared=True)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(baseline_results[\"Target\"], baseline_results[\"predicted_value\"], squared=False)\n",
    "\n",
    "# Calculate R2\n",
    "r2 = r2_score(baseline_results[\"Target\"], baseline_results[\"predicted_value\"])\n",
    "\n",
    "# Calculate MAPE\n",
    "mape = mean_absolute_percentage_error(baseline_results[\"Target\"], baseline_results[\"predicted_value\"])\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2:\", r2)\n",
    "print(\"MAPE:\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30983ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results.to_csv(f'results/AMBR/baseline_{method}_{config}_{num_nearest_neighbors}_{distance_metric}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb33bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from processors import processor_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83980fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'AMBR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15db96d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting with num_nearest_neighbors=100 and distance_metric=euclidean\n",
      "MAE: 0.16959364293793092\n",
      "MSE: 0.06386230233056991\n",
      "RMSE: 0.25270991735697657\n",
      "R2: 0.9464420376738679\n",
      "MAPE: 0.7218010960332537\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=100 and distance_metric=cosine\n",
      "MAE: 0.18029104938886764\n",
      "MSE: 0.0704507395624542\n",
      "RMSE: 0.2654255819668749\n",
      "R2: 0.940916661040454\n",
      "MAPE: 0.7150634087908665\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=100 and distance_metric=chebyshev\n",
      "MAE: 0.17771685406299725\n",
      "MSE: 0.07136863625956893\n",
      "RMSE: 0.26714908994710973\n",
      "R2: 0.9401468692395121\n",
      "MAPE: 0.660778486287254\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=200 and distance_metric=euclidean\n",
      "MAE: 0.17561818749379055\n",
      "MSE: 0.06774205098632372\n",
      "RMSE: 0.26027303161550125\n",
      "R2: 0.9431882960335473\n",
      "MAPE: 0.7046042928673665\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=200 and distance_metric=cosine\n",
      "MAE: 0.17571055366031876\n",
      "MSE: 0.06764932160447427\n",
      "RMSE: 0.2600948319449548\n",
      "R2: 0.943266063300908\n",
      "MAPE: 0.6935666304100548\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=200 and distance_metric=chebyshev\n",
      "MAE: 0.16566027294392785\n",
      "MSE: 0.06082747867634959\n",
      "RMSE: 0.24663227419855172\n",
      "R2: 0.9489871850457531\n",
      "MAPE: 0.680755325195026\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=300 and distance_metric=euclidean\n",
      "MAE: 0.1718939842083469\n",
      "MSE: 0.06665988393532266\n",
      "RMSE: 0.2581857547102912\n",
      "R2: 0.9440958527615851\n",
      "MAPE: 0.6684010084716745\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=300 and distance_metric=cosine\n",
      "MAE: 0.16641960022327387\n",
      "MSE: 0.05973037153551128\n",
      "RMSE: 0.24439797776477465\n",
      "R2: 0.9499072712432816\n",
      "MAPE: 0.6982945636955614\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=300 and distance_metric=chebyshev\n",
      "MAE: 0.17556850991828307\n",
      "MSE: 0.07077549061885233\n",
      "RMSE: 0.2660366339789547\n",
      "R2: 0.94064430936804\n",
      "MAPE: 0.7078488507040123\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=400 and distance_metric=euclidean\n",
      "MAE: 0.17726381290193116\n",
      "MSE: 0.07166333700981162\n",
      "RMSE: 0.26770008780314514\n",
      "R2: 0.9398997191822328\n",
      "MAPE: 0.6807851881251433\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=400 and distance_metric=cosine\n",
      "MAE: 0.17520202898271148\n",
      "MSE: 0.06727089350493157\n",
      "RMSE: 0.2593663307079999\n",
      "R2: 0.943583431093155\n",
      "MAPE: 0.7070588877350389\n",
      "***********************************\n",
      "Experimenting with num_nearest_neighbors=400 and distance_metric=chebyshev\n",
      "MAE: 0.17229313463858975\n",
      "MSE: 0.06809650210146427\n",
      "RMSE: 0.26095306493977855\n",
      "R2: 0.9428910364801273\n",
      "MAPE: 0.6791100254763452\n",
      "***********************************\n"
     ]
    }
   ],
   "source": [
    "# Define the values to experiment with\n",
    "num_nearest_neighbors_values = [100, 200, 300, 400]\n",
    "distance_metrics = ['euclidean', 'cosine', 'chebyshev']\n",
    "\n",
    "results = []\n",
    "# Loop through the values and create processors\n",
    "for num_nearest_neighbors in num_nearest_neighbors_values:\n",
    "    for distance_metric in distance_metrics:\n",
    "        print(f\"Experimenting with num_nearest_neighbors={num_nearest_neighbors} and distance_metric={distance_metric}\")\n",
    "        \n",
    "        # Create the processor with the current values\n",
    "        # processor = processor_factory.get_processor(dataset_name, use_encoding=False, use_bucketing=False, num_nearest_neighbors=num_nearest_neighbors, distance_metric=distance_metric)\n",
    "        processor = AMBRProcessor(\"AMBR\", use_encoding, use_bucketing, num_nearest_neighbors, distance_metric)\n",
    "    \n",
    "\n",
    "        data = df_normalized.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "        data['Target'] = data.groupby(case_id_col)[target_col].shift(-1)\n",
    "        # data['Target_orig'] = data.groupby(case_id_col)['Titer (g/L) original'].shift(-1)\n",
    "        data['Target'] = data.groupby(case_id_col)['Target'].ffill().bfill()\n",
    "        # data['Target_orig'] = data.groupby(case_id_col)['Target_orig'].ffill()\n",
    "\n",
    "        historic, current = processor.split_data(data, train_ratio=0.5, split=\"temporal\")\n",
    "        historic.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort', inplace=True)\n",
    "        current.sort_values(timestamp_col, ascending=True, kind='mergesort', inplace=True)\n",
    "\n",
    "        if config == 'no_encoding_bucketing' or config == 'encoding_bucketing':\n",
    "            features_used = features + ['Cluster']\n",
    "        else:\n",
    "            features_used = features\n",
    "\n",
    "        # n_neighbors = 200\n",
    "        # # Initialize the NearestNeighbors model\n",
    "        # nn_model = NearestNeighbors(n_neighbors=n_neighbors, metric=\"cosine\")\n",
    "        # # Fit the model on the historic data\n",
    "        # nn_model.fit(historic[features_used])\n",
    "\n",
    "        batch_size = 50\n",
    "\n",
    "        nn_model = processor.train_nn_model(historic[features_used])\n",
    "\n",
    "        for start in range(0, len(current), batch_size):\n",
    "            end = start + batch_size\n",
    "            batch = current.iloc[start:end]\n",
    "            # Find the n nearest neighbors for the selected row\n",
    "            # distances, indices = nn_model.kneighbors([row[features_used]])\n",
    "            distances, indices = processor.find_nearest_neighbors(nn_model, batch[features_used])\n",
    "            nearest_neighbors = pd.concat([historic.iloc[indices[i]] for i in range(len(batch))])\n",
    "\n",
    "            target = nearest_neighbors['Target'].values\n",
    "            target_test = batch['Target']\n",
    "\n",
    "            if target_test is None:\n",
    "                continue\n",
    "            \n",
    "\n",
    "            if method == 'Catboost':\n",
    "                # Create the CatBoostRegressor model\n",
    "                model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='MAE', verbose=0)\n",
    "                model.fit(nearest_neighbors[features_used], target)\n",
    "\n",
    "            if method == 'HMM':\n",
    "                # Create an instance of the HMM model\n",
    "                model = hmm.GaussianHMM(n_components=7)  # Specify the number of hidden states\n",
    "                model.fit(nearest_neighbors[features_used])\n",
    "\n",
    "            # Make predictions on the testing data\n",
    "            preds = model.predict(batch[features_used])\n",
    "\n",
    "            # true_conc_glu = row['Target_orig']\n",
    "            # preds_scaled = scalers[target_col].inverse_transform(preds.reshape(-1, 1))\n",
    "\n",
    "            batch.loc[:, 'predicted_value'] = preds\n",
    "\n",
    "            results.append(batch)\n",
    "\n",
    "            # Add the current row with its prediction to the historic data\n",
    "            # row_with_prediction[target_col] = preds_scaled[0][0]\n",
    "            historic = pd.concat([historic, batch], ignore_index=True)\n",
    "            historic.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort', inplace=True)\n",
    "            nn_model =processor.train_nn_model(historic[features_used])  # Refit the model with the updated historic data\n",
    "\n",
    "        results_df = pd.concat(results)\n",
    "        results = []\n",
    "\n",
    "        # Calculate metrics\n",
    "        true_values = results_df[target_col]\n",
    "        predicted_values = results_df['predicted_value']\n",
    "\n",
    "        MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "        MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "        RMSE_t = math.sqrt(MSE_t)\n",
    "        r2_t = r2_score(true_values, predicted_values)\n",
    "        mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "        # Save results to a CSV file\n",
    "        # results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"MAE: {MAE_t}\")\n",
    "        print(f\"MSE: {MSE_t}\")\n",
    "        print(f\"RMSE: {RMSE_t}\")\n",
    "        print(f\"R2: {r2_t}\")\n",
    "        print(f\"MAPE: {mape_t}\")\n",
    "\n",
    "        results_df.to_csv(f'results/{dataset_name}/AMBR_{method}_{config}_{num_nearest_neighbors}_{distance_metric}.csv', index=False)\n",
    "        print('***********************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "629e5f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1044       -0.258619  X5356_12     -0.984814   \n",
       " 1062       -0.204529  X5356_13     -0.993470   \n",
       " 1080        0.018591  X5356_14     -1.149280   \n",
       " 1098        0.106487  X5356_15     -1.114656   \n",
       " 1116        0.005069  X5356_16     -1.097343   \n",
       " 1134       -0.021976  X5356_17     -1.080031   \n",
       " 1152       -0.157201  X5356_18     -1.088687   \n",
       " 1170       -0.069305  X5356_19     -1.036750   \n",
       " 1188        0.241711   X5356_2     -1.054063   \n",
       " 1206       -0.136917  X5356_20     -1.036750   \n",
       " 1224       -0.021976  X5356_21     -0.976158   \n",
       " 1242       -1.698756  X5356_22     -1.400308   \n",
       " 1260        0.566249  X5356_23     -0.292324   \n",
       " 1278        0.600055  X5356_24     -0.266355   \n",
       " 1296        0.106487   X5356_3     -1.201217   \n",
       " 1314        0.011830   X5356_4     -1.209873   \n",
       " 1332       -0.130156   X5356_5     -0.820347   \n",
       " 1350       -0.096350   X5356_6     -0.803035   \n",
       " 1368       -0.569634   X5356_7     -1.140624   \n",
       " 1386       -0.170723   X5356_8     -0.993470   \n",
       " 1404       -0.130156   X5356_9     -1.010782   \n",
       " 1422        0.086203   X5363_1     -1.279122   \n",
       " 1437       -0.157201  X5363_10     -1.175248   \n",
       " 1452       -0.163962  X5363_11     -1.175248   \n",
       " 1467       -0.184245  X5363_12     -1.175248   \n",
       " 1482        0.059158  X5363_13     -0.725130   \n",
       " 1497        0.025352  X5363_14     -0.725130   \n",
       " 1512        0.045636  X5363_15     -0.707818   \n",
       " 1527        0.052397  X5363_16     -0.603944   \n",
       " 1542        0.065919  X5363_17     -0.569320   \n",
       " 1557        0.079442  X5363_18     -0.569320   \n",
       " 1572       -0.028738  X5363_19     -0.673193   \n",
       " 1587       -0.143678   X5363_2     -1.209873   \n",
       " 1602       -0.008454  X5363_20     -0.664537   \n",
       " 1617        0.079442  X5363_21     -0.699162   \n",
       " 1632        0.140293  X5363_22     -0.517383   \n",
       " 1647        0.092964  X5363_23     -0.465446   \n",
       " 1662        0.092964  X5363_24     -0.439478   \n",
       " 1677       -0.238335   X5363_3     -1.209873   \n",
       " 1692       -0.326231   X5363_4     -1.201217   \n",
       " 1707       -0.353276   X5363_5     -1.209873   \n",
       " 1722       -0.393843   X5363_6     -1.192561   \n",
       " 1737       -0.076066   X5363_7     -1.192561   \n",
       " 1752       -0.123394   X5363_8     -1.175248   \n",
       " 1767       -0.136917   X5363_9     -1.183905   \n",
       " 1045       -0.103111  X5356_12     -0.777067   \n",
       " 1063       -0.130156  X5356_13     -0.681849   \n",
       " 1081       -0.062544  X5356_14     -0.707818   \n",
       " 1099       -0.170723  X5356_15     -0.768411   \n",
       " 1117        0.005069  X5356_16     -0.751098   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1044                          -1.713554     -1.169452  2.874880      1.056634   \n",
       " 1062                          -1.734582     -1.150226  2.986214      1.046117   \n",
       " 1080                          -1.730815     -1.188678  3.016554      1.182842   \n",
       " 1098                          -1.739614     -1.207904  2.958808      1.245946   \n",
       " 1116                          -1.733345     -1.198291  2.952163      1.209135   \n",
       " 1134                          -1.732080     -1.207904  2.978358      1.188101   \n",
       " 1152                          -1.725165     -1.198291  2.950183      1.198618   \n",
       " 1170                          -1.717012     -1.159839  3.207652      1.177583   \n",
       " 1188                          -1.738040     -1.198291  1.192719      1.198618   \n",
       " 1206                          -1.710434     -1.150226  3.213694      1.203877   \n",
       " 1224                          -1.556322     -1.159839  3.227198      1.177583   \n",
       " 1242                          -1.492000     -1.419391  3.241344     -2.003910   \n",
       " 1260                          -0.082249     -0.832995  2.587666      0.583354   \n",
       " 1278                           0.245710     -0.842608  2.584085      0.609647   \n",
       " 1296                          -1.772871     -1.294421  2.868161      1.219653   \n",
       " 1314                          -1.781980     -1.313647  2.903130      1.245946   \n",
       " 1332                          -1.653309     -1.073321  3.111703      0.940943   \n",
       " 1350                          -1.668378     -1.054095  3.135855      1.030341   \n",
       " 1368                          -1.721088     -1.236743  2.864129      0.046970   \n",
       " 1386                          -1.734891     -1.179065  2.863991      1.088186   \n",
       " 1404                          -1.725811     -1.159839  2.931442      1.072410   \n",
       " 1422                          -1.751534     -1.111773  3.009168      1.182842   \n",
       " 1437                          -1.769413     -1.102160  3.493578      1.046117   \n",
       " 1452                          -1.753108     -1.092547  3.530865      1.072410   \n",
       " 1467                          -1.763763     -1.092547  3.521154      1.040858   \n",
       " 1482                          -0.074097     -0.496539  2.620773      0.415077   \n",
       " 1497                          -0.103586     -0.506152  2.625845      0.404559   \n",
       " 1512                          -0.040812     -0.477313  2.616814      0.409818   \n",
       " 1527                           0.155638     -0.265826  2.649548      0.241541   \n",
       " 1542                           0.258585     -0.265826  2.666465      0.262575   \n",
       " 1557                           0.242870     -0.246600  2.648362      0.246799   \n",
       " 1572                           0.958415     -0.217760  2.637261      0.209989   \n",
       " 1587                          -1.765646     -1.111773  2.998627      1.161807   \n",
       " 1602                           0.972246     -0.217760  2.647238      0.199471   \n",
       " 1617                           0.910736     -0.198534  2.661607      0.199471   \n",
       " 1632                           0.396027     -0.179308  2.655026      0.231023   \n",
       " 1647                           0.193308     -0.188921  2.658747      0.215247   \n",
       " 1662                           0.369685     -0.150469  2.656937      0.220506   \n",
       " 1677                          -1.755301     -1.111773  3.011740      1.146031   \n",
       " 1692                          -1.754683     -1.130999  3.071361      1.114479   \n",
       " 1707                          -1.747458     -1.111773  2.984027      1.135514   \n",
       " 1722                          -1.765028     -1.111773  3.044835      1.146031   \n",
       " 1737                          -1.750606     -1.102160  3.512180      1.040858   \n",
       " 1752                          -1.754683     -1.102160  3.504372      1.030341   \n",
       " 1767                          -1.754036     -1.102160  3.517810      1.035599   \n",
       " 1045                          -1.664920     -0.977191  1.261403      1.025082   \n",
       " 1063                          -1.617522     -0.919512  1.421902      0.967237   \n",
       " 1081                          -1.634165     -0.919512  1.172743      0.998789   \n",
       " 1099                          -1.617522     -0.996417  1.046952      0.956719   \n",
       " 1117                          -1.619406     -0.967578  1.191706      0.983013   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1044        1.864688            0      0.949926   -1.240566  2019-08-15   \n",
       " 1062        2.069525            0      0.886373   -1.240191  2019-08-15   \n",
       " 1080        2.160564            0      0.852117   -1.240368  2019-08-15   \n",
       " 1098        1.711060            0      0.921921   -1.240403  2019-08-15   \n",
       " 1116        1.893138            0      0.950878   -1.240179  2019-08-15   \n",
       " 1134        2.228843            0      0.993917   -1.240248  2019-08-15   \n",
       " 1152        2.194704            0      0.786913   -1.240161  2019-08-15   \n",
       " 1170        1.938657            0      0.928785   -1.238349  2019-08-15   \n",
       " 1188        1.728130            0      0.945924   -1.240521  2019-08-15   \n",
       " 1206        2.217463            0      0.884218   -1.238294  2019-08-15   \n",
       " 1224        1.500533            0      0.985913   -1.238937  2019-08-15   \n",
       " 1242        2.006936            0      0.903859   -1.237167  2019-08-15   \n",
       " 1260        3.190441            0      0.960893   -1.212345  2019-08-15   \n",
       " 1278        3.287170            0      0.995092   -1.214155  2019-08-15   \n",
       " 1296        1.443633            0      1.022874   -1.242968  2019-08-15   \n",
       " 1314        1.181897            0      0.899071   -1.242600  2019-08-15   \n",
       " 1332        2.166254            0      0.889856   -1.231861  2019-08-15   \n",
       " 1350        1.836238            0      1.017704   -1.231438  2019-08-15   \n",
       " 1368        1.750889            0      0.905741   -1.240616  2019-08-15   \n",
       " 1386        1.864688            0      0.928014   -1.240718  2019-08-15   \n",
       " 1404        1.910207            0      0.804204   -1.240370  2019-08-15   \n",
       " 1422       -0.354384            0      0.829043   -1.239205  2019-08-15   \n",
       " 1437        0.038221            0      0.927624   -1.238161  2019-08-15   \n",
       " 1452        0.055291            0      0.900794   -1.238468  2019-08-15   \n",
       " 1467        0.055291            0      0.937365   -1.238627  2019-08-15   \n",
       " 1482        0.180469            0      0.809763   -1.040012  2019-08-15   \n",
       " 1497        0.191849            0      0.795984   -1.042687  2019-08-15   \n",
       " 1512        0.197539            0      0.797772   -1.037319  2019-08-15   \n",
       " 1527        0.231679            0      0.774014   -0.989287  2019-08-15   \n",
       " 1542        0.231679            0      0.757538   -0.990336  2019-08-15   \n",
       " 1557        0.237368            0      0.836167   -0.989762  2019-08-15   \n",
       " 1572        0.191849            0      0.807556   -0.992574  2019-08-15   \n",
       " 1587       -0.297485            0      0.874224   -1.238632  2019-08-15   \n",
       " 1602        0.197539            0      0.793763   -0.982938  2019-08-15   \n",
       " 1617        0.180469            0      0.786560   -0.981240  2019-08-15   \n",
       " 1632        0.254438            0      0.760343   -0.974539  2019-08-15   \n",
       " 1647        0.282888            0      0.791441   -0.976397  2019-08-15   \n",
       " 1662        0.299958            0      0.808155   -0.976383  2019-08-15   \n",
       " 1677       -0.263345            0      0.976222   -1.238682  2019-08-15   \n",
       " 1692       -0.234896            0      0.950323   -1.239121  2019-08-15   \n",
       " 1707       -0.217826            0      0.792278   -1.238941  2019-08-15   \n",
       " 1722       -0.200756            0      0.731148   -1.238987  2019-08-15   \n",
       " 1737       -0.007298            0      0.831430   -1.238034  2019-08-15   \n",
       " 1752        0.021151            0      0.695730   -1.238059  2019-08-15   \n",
       " 1767        0.026841            0      0.873337   -1.238230  2019-08-15   \n",
       " 1045        1.864688            1      0.891341   -1.229589  2019-08-16   \n",
       " 1063        2.069525            1      0.887058   -1.228826  2019-08-16   \n",
       " 1081        2.160564            1      0.905286   -1.228670  2019-08-16   \n",
       " 1099        1.711060            1      0.877281   -1.228932  2019-08-16   \n",
       " 1117        1.893138            1      0.905423   -1.228812  2019-08-16   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1044 -1.229589        -0.963416  \n",
       " 1062 -1.228826        -0.990148  \n",
       " 1080 -1.228670        -0.775065  \n",
       " 1098 -1.228932        -0.761131  \n",
       " 1116 -1.228812        -0.830954  \n",
       " 1134 -1.228886        -0.901752  \n",
       " 1152 -1.228655        -0.873145  \n",
       " 1170 -1.225738        -0.983593  \n",
       " 1188 -1.229399        -0.852817  \n",
       " 1206 -1.225158        -0.980049  \n",
       " 1224 -1.208106        -0.941804  \n",
       " 1242 -1.204937        -0.204530  \n",
       " 1260 -1.022964        -0.770341  \n",
       " 1278 -1.003556        -0.548314  \n",
       " 1296 -1.242968        -0.741226  \n",
       " 1314 -1.242600        -0.727301  \n",
       " 1332 -1.214165        -0.984801  \n",
       " 1350 -1.213254        -1.027274  \n",
       " 1368 -1.228934        -0.694670  \n",
       " 1386 -1.229195        -0.994977  \n",
       " 1404 -1.228743        -0.958563  \n",
       " 1422 -1.225025        -0.719956  \n",
       " 1437 -1.226541        -0.861691  \n",
       " 1452 -1.226642        -0.848340  \n",
       " 1467 -1.226653        -0.867714  \n",
       " 1482 -0.797413        -0.704923  \n",
       " 1497 -0.798123        -0.671888  \n",
       " 1512 -0.802966        -0.598449  \n",
       " 1527 -0.709827        -0.413991  \n",
       " 1542 -0.707569        -0.282046  \n",
       " 1557 -0.709284        -0.460073  \n",
       " 1572 -0.625126        -0.138475  \n",
       " 1587 -1.227638        -0.866633  \n",
       " 1602 -0.634925        -0.106396  \n",
       " 1617 -0.635890        -0.131912  \n",
       " 1632 -0.699779        -0.296731  \n",
       " 1647 -0.701856        -0.460139  \n",
       " 1662 -0.695181        -0.402423  \n",
       " 1677 -1.228033        -0.848338  \n",
       " 1692 -1.228903        -0.827040  \n",
       " 1707 -1.228538        -0.738495  \n",
       " 1722 -1.227604        -0.666634  \n",
       " 1737 -1.226458        -0.745777  \n",
       " 1752 -1.226877        -0.576076  \n",
       " 1767 -1.226501        -0.813975  \n",
       " 1045 -1.203744        -1.038379  \n",
       " 1063 -1.195861        -1.130519  \n",
       " 1081 -1.197069        -1.067441  \n",
       " 1099 -1.200631        -1.010384  \n",
       " 1117 -1.198280        -1.003718  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1135       -0.136917  X5356_17     -0.725130   \n",
       " 1153       -0.157201  X5356_18     -0.716474   \n",
       " 1171       -0.136917  X5356_19     -0.681849   \n",
       " 1189        0.228188   X5356_2     -0.759754   \n",
       " 1207       -0.136917  X5356_20     -0.655881   \n",
       " 1225       -0.204529  X5356_21     -0.318292   \n",
       " 1243        0.025352  X5356_22     -0.283668   \n",
       " 1261        0.566249  X5356_23      1.914988   \n",
       " 1279        0.600055  X5356_24      2.183328   \n",
       " 1297        0.106487   X5356_3     -1.045407   \n",
       " 1315       -0.015215   X5356_4     -1.002126   \n",
       " 1333        0.147054   X5356_5     -0.430822   \n",
       " 1351        0.018591   X5356_6     -0.404853   \n",
       " 1369       -0.082827   X5356_7     -0.759754   \n",
       " 1387        0.059158   X5356_8     -0.777067   \n",
       " 1405        0.011830   X5356_9     -0.742442   \n",
       " 1423        0.140293   X5363_1     -1.019438   \n",
       " 1438        0.613577  X5363_10     -1.071375   \n",
       " 1453        0.600055  X5363_11     -0.967501   \n",
       " 1468        0.545965  X5363_12     -0.967501   \n",
       " 1483        1.343788  X5363_13      1.032063   \n",
       " 1498        1.276176  X5363_14      1.006095   \n",
       " 1513        1.641281  X5363_15      0.962814   \n",
       " 1528        1.370833  X5363_16      1.092656   \n",
       " 1543        1.255892  X5363_17      1.153249   \n",
       " 1558        1.228848  X5363_18      1.161905   \n",
       " 1573        0.998966  X5363_19      1.170561   \n",
       " 1588       -0.062544   X5363_2     -0.958845   \n",
       " 1603        1.053056  X5363_20      1.127281   \n",
       " 1618        0.978683  X5363_21      1.161905   \n",
       " 1633        1.120668  X5363_22      1.196530   \n",
       " 1648        1.093623  X5363_23      1.205186   \n",
       " 1663        1.086862  X5363_24      1.222498   \n",
       " 1678       -0.089588   X5363_3     -0.941533   \n",
       " 1693       -0.238335   X5363_4     -0.941533   \n",
       " 1708       -0.278902   X5363_5     -0.932877   \n",
       " 1723       -0.339753   X5363_6     -0.915565   \n",
       " 1738       -0.042260   X5363_7     -0.915565   \n",
       " 1753        0.275517   X5363_8     -1.019438   \n",
       " 1768        0.099725   X5363_9     -0.976158   \n",
       " 1046        0.079442  X5356_12     -0.214419   \n",
       " 1064        0.180860  X5356_13      0.027953   \n",
       " 1082        0.147054  X5356_14      0.019297   \n",
       " 1100       -0.049021  X5356_15     -0.101889   \n",
       " 1118       -0.028738  X5356_16     -0.110545   \n",
       " 1136        0.147054  X5356_17     -0.084577   \n",
       " 1154        0.086203  X5356_18     -0.093233   \n",
       " 1172        0.573010  X5356_19     -0.049952   \n",
       " 1190        0.539204   X5356_2     -0.153826   \n",
       " 1208       -0.136917  X5356_20     -0.032640   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1135                          -1.650470     -0.909899  1.400756      0.935685   \n",
       " 1153                          -1.626012     -0.967578  1.125810      0.940943   \n",
       " 1171                          -1.591490     -0.890673  1.203322      0.935685   \n",
       " 1189                          -1.638241     -0.996417  1.192719      1.067151   \n",
       " 1207                          -1.620024     -0.919512  1.017148      0.914650   \n",
       " 1225                          -1.288636     -0.717639  0.930740      0.751631   \n",
       " 1243                          -1.250656     -0.573443  1.070276      0.672751   \n",
       " 1261                           1.148623      0.272505 -0.983169     -0.584070   \n",
       " 1279                           1.182498      0.291731 -1.013820     -0.668209   \n",
       " 1297                          -1.741807     -1.150226  1.315185      1.193359   \n",
       " 1315                          -1.723590     -1.159839  1.240948      1.114479   \n",
       " 1333                          -1.530908     -0.756091  1.232107      0.841029   \n",
       " 1351                          -1.550053     -0.765704  1.148970      0.846287   \n",
       " 1369                          -1.627249     -0.929126  1.432140      0.988271   \n",
       " 1387                          -1.616595     -0.967578  1.274273      1.004047   \n",
       " 1405                          -1.638241     -0.948352  1.351937      0.983013   \n",
       " 1423                          -1.715128     -0.929126  1.151556      1.019823   \n",
       " 1438                          -1.707285     -0.900286  1.060516      1.030341   \n",
       " 1453                          -1.725165     -0.871447  1.143328      1.040858   \n",
       " 1468                          -1.706329     -0.832995  1.295425      1.077669   \n",
       " 1483                           0.895021      0.964644 -1.135728     -0.068721   \n",
       " 1498                           0.810937      0.926192 -1.138755     -0.073979   \n",
       " 1513                           0.829126      0.945418 -1.106813     -0.042427   \n",
       " 1528                           1.350104      1.041548 -1.183111     -0.126566   \n",
       " 1543                           1.108450      1.031935 -1.179905     -0.163377   \n",
       " 1558                           1.341305      1.031935 -1.185885     -0.131825   \n",
       " 1573                           1.772830      1.012709 -1.140523     -0.457862   \n",
       " 1588                          -1.686257     -0.909899  1.263726      0.998789   \n",
       " 1603                           2.125894      1.022322 -1.149771     -0.426310   \n",
       " 1618                           1.830264      1.012709 -1.162931     -0.436827   \n",
       " 1633                           1.317466      1.003096 -1.190881     -0.152859   \n",
       " 1648                           1.207603      0.993483 -1.187337     -0.152859   \n",
       " 1663                           1.296747      1.031935 -1.193160     -0.126566   \n",
       " 1678                          -1.698177     -0.890673  1.300903      0.967237   \n",
       " 1693                          -1.717968     -0.929126  1.120255      1.009306   \n",
       " 1708                          -1.702590     -0.929126  1.053233      0.972495   \n",
       " 1723                          -1.716703     -0.909899  1.055006      1.009306   \n",
       " 1738                          -1.717012     -0.871447  1.222720      0.904133   \n",
       " 1753                          -1.695365     -0.842608  1.123620      1.019823   \n",
       " 1768                          -1.706329     -0.861834  0.858869      1.025082   \n",
       " 1046                          -1.481009     -0.640734  1.203460      0.614906   \n",
       " 1064                          -1.344495     -0.506152  0.948597      0.546543   \n",
       " 1082                          -1.415422     -0.544604  0.936292      0.557061   \n",
       " 1100                          -1.408197     -0.659960  1.048880      0.678010   \n",
       " 1118                          -1.386551     -0.583056  1.251853      0.572837   \n",
       " 1136                          -1.322511     -0.525378  1.174109      0.562319   \n",
       " 1154                          -1.383402     -0.592669  1.108734      0.562319   \n",
       " 1172                          -1.348571     -0.515765  1.190553      0.572837   \n",
       " 1190                          -1.425458     -0.563830  1.019318      0.662234   \n",
       " 1208                          -1.345423     -0.602282  0.992087      0.651717   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1135        2.228843            1      0.950460   -1.228886  2019-08-16   \n",
       " 1153        2.194704            1      0.800029   -1.228655  2019-08-16   \n",
       " 1171        1.938657            1      0.869674   -1.225738  2019-08-16   \n",
       " 1189        1.728130            1      0.891406   -1.229399  2019-08-16   \n",
       " 1207        2.217463            1      0.885140   -1.225158  2019-08-16   \n",
       " 1225        1.500533            1      0.904299   -1.208106  2019-08-16   \n",
       " 1243        2.006936            1      0.866213   -1.204937  2019-08-16   \n",
       " 1261        3.190441            1      0.885934   -1.022964  2019-08-16   \n",
       " 1279        3.287170            1      0.890678   -1.003556  2019-08-16   \n",
       " 1297        1.443633            1      0.896288   -1.242968  2019-08-16   \n",
       " 1315        1.181897            1      0.883561   -1.242600  2019-08-16   \n",
       " 1333        2.166254            1      0.849896   -1.214165  2019-08-16   \n",
       " 1351        1.836238            1      0.918734   -1.213254  2019-08-16   \n",
       " 1369        1.750889            1      0.848843   -1.228934  2019-08-16   \n",
       " 1387        1.864688            1      0.878031   -1.229195  2019-08-16   \n",
       " 1405        1.910207            1      0.859089   -1.228743  2019-08-16   \n",
       " 1423       -0.343004            1      0.966503   -1.225025  2019-08-16   \n",
       " 1438       -0.212136            1      0.855383   -1.226541  2019-08-16   \n",
       " 1453       -0.229206            1      0.824321   -1.226642  2019-08-16   \n",
       " 1468       -0.217826            1      0.760545   -1.226653  2019-08-16   \n",
       " 1483        0.299958            1      0.785384   -0.797413  2019-08-16   \n",
       " 1498        0.305648            1      0.810044   -0.798123  2019-08-16   \n",
       " 1513        0.214609            1      0.767438   -0.802966  2019-08-16   \n",
       " 1528        0.260128            1      0.697569   -0.709827  2019-08-16   \n",
       " 1543        0.334097            1      0.757588   -0.707569  2019-08-16   \n",
       " 1558        0.379617            1      0.707505   -0.709284  2019-08-16   \n",
       " 1573        0.305648            1      0.780575   -0.625126  2019-08-16   \n",
       " 1588       -0.286105            1      0.812387   -1.227638  2019-08-16   \n",
       " 1603        0.362547            1      0.714347   -0.634925  2019-08-16   \n",
       " 1618        0.362547            1      0.767048   -0.635890  2019-08-16   \n",
       " 1633        0.436516            1      0.696451   -0.699779  2019-08-16   \n",
       " 1648        0.447896            1      0.721745   -0.701856  2019-08-16   \n",
       " 1663        0.487725            1      0.760653   -0.695181  2019-08-16   \n",
       " 1678       -0.223516            1      0.674012   -1.228033  2019-08-16   \n",
       " 1693       -0.200756            1      0.750327   -1.228903  2019-08-16   \n",
       " 1708       -0.177996            1      0.722546   -1.228538  2019-08-16   \n",
       " 1723       -0.160927            1      0.857755   -1.227604  2019-08-16   \n",
       " 1738        0.043911            1      0.735488   -1.226458  2019-08-16   \n",
       " 1753        0.021151            1      0.841842   -1.226877  2019-08-16   \n",
       " 1768        0.021151            1      0.939060   -1.226501  2019-08-16   \n",
       " 1046        1.864688            2      0.884246   -1.203744  2019-08-17   \n",
       " 1064        2.069525            2      0.861216   -1.195861  2019-08-17   \n",
       " 1082        2.160564            2      0.854503   -1.197069  2019-08-17   \n",
       " 1100        1.711060            2      0.928230   -1.200631  2019-08-17   \n",
       " 1118        1.893138            2      0.900578   -1.198280  2019-08-17   \n",
       " 1136        2.228843            2      0.902849   -1.199226  2019-08-17   \n",
       " 1154        2.194704            2      0.911184   -1.197850  2019-08-17   \n",
       " 1172        1.938657            2      0.912518   -1.190974  2019-08-17   \n",
       " 1190        1.728130            2      0.818783   -1.199843  2019-08-17   \n",
       " 1208        2.217463            2      0.800505   -1.192673  2019-08-17   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1135 -1.199226        -1.175385  \n",
       " 1153 -1.197850        -1.175954  \n",
       " 1171 -1.190974        -1.186947  \n",
       " 1189 -1.199843        -1.178094  \n",
       " 1207 -1.192673        -1.184801  \n",
       " 1225 -1.118056        -1.138331  \n",
       " 1243 -1.126867        -1.118542  \n",
       " 1261 -0.665072        -0.337293  \n",
       " 1279 -0.602042        -0.301401  \n",
       " 1297 -1.229124        -1.228857  \n",
       " 1315 -1.227433        -1.225832  \n",
       " 1333 -1.168208        -1.180304  \n",
       " 1351 -1.165984        -1.175716  \n",
       " 1369 -1.200509        -1.234039  \n",
       " 1387 -1.202459        -1.173499  \n",
       " 1405 -1.200027        -1.171194  \n",
       " 1423 -1.199152        -1.215937  \n",
       " 1438 -1.194792        -1.219399  \n",
       " 1453 -1.195549        -1.206440  \n",
       " 1468 -1.194560        -1.204162  \n",
       " 1483 -0.583123        -0.207158  \n",
       " 1498 -0.384799        -0.252192  \n",
       " 1513 -0.385382        -0.218238  \n",
       " 1528 -0.297277        -0.111942  \n",
       " 1543 -0.281018        -0.122465  \n",
       " 1558 -0.295268        -0.147301  \n",
       " 1573 -0.160120        -0.253942  \n",
       " 1588 -1.194164        -1.262348  \n",
       " 1603 -0.183230        -0.186534  \n",
       " 1618 -0.163481        -0.248469  \n",
       " 1633 -0.280638        -0.153509  \n",
       " 1648 -0.275736        -0.150343  \n",
       " 1663 -0.280162        -0.156709  \n",
       " 1678 -1.196567        -1.166513  \n",
       " 1693 -1.199369        -1.213555  \n",
       " 1708 -1.199037        -1.202483  \n",
       " 1723 -1.198476        -1.214696  \n",
       " 1738 -1.194410        -1.202954  \n",
       " 1753 -1.195608        -1.220902  \n",
       " 1768 -1.193883        -1.223973  \n",
       " 1046 -1.122006        -1.133479  \n",
       " 1064 -1.105034        -1.154328  \n",
       " 1082 -1.112138        -1.157435  \n",
       " 1100 -1.111761        -1.163310  \n",
       " 1118 -1.110385        -1.162316  \n",
       " 1136 -1.109999        -1.152590  \n",
       " 1154 -1.109547        -1.172634  \n",
       " 1172 -1.116593        -1.150501  \n",
       " 1190 -1.115034        -1.123335  \n",
       " 1208 -1.121247        -1.170500  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1226        1.208564  X5356_21      0.581945   \n",
       " 1244        1.438445  X5356_22      0.590601   \n",
       " 1262        2.013148  X5356_23      2.079454   \n",
       " 1280        2.236268  X5356_24      2.088110   \n",
       " 1298        0.376935   X5356_3     -0.621256   \n",
       " 1316        0.187621   X5356_4     -0.612600   \n",
       " 1334        0.816414   X5356_5      0.348229   \n",
       " 1352        0.397219   X5356_6      0.365542   \n",
       " 1370       -0.082827   X5356_7     -0.179794   \n",
       " 1388        0.268756   X5356_8     -0.145170   \n",
       " 1406        0.207905   X5356_9      0.001984   \n",
       " 1424        0.505398   X5363_1     -0.526039   \n",
       " 1439        0.092964  X5363_10     -1.071375   \n",
       " 1454        0.045636  X5363_11     -0.404853   \n",
       " 1469        0.018591  X5363_12     -0.352917   \n",
       " 1484        0.370174  X5363_13      0.919534   \n",
       " 1499        0.376935  X5363_14      0.919534   \n",
       " 1514        0.370174  X5363_15      0.936846   \n",
       " 1529        0.302562  X5363_16      0.633882   \n",
       " 1544        0.343129  X5363_17      0.651194   \n",
       " 1559        0.383696  X5363_18      0.633882   \n",
       " 1574        0.059158  X5363_19      0.253012   \n",
       " 1589        0.241711   X5363_2     -0.396197   \n",
       " 1604        0.234950  X5363_20      0.218388   \n",
       " 1619        0.174099  X5363_21      0.253012   \n",
       " 1634        0.349890  X5363_22      0.599257   \n",
       " 1649        0.336368  X5363_23      0.547320   \n",
       " 1664        0.343129  X5363_24      0.625225   \n",
       " 1679        0.376935   X5363_3     -0.396197   \n",
       " 1694        0.099725   X5363_4     -0.456790   \n",
       " 1709        0.086203   X5363_5     -0.474102   \n",
       " 1724       -0.096350   X5363_6     -0.413509   \n",
       " 1739        0.113248   X5363_7     -0.378885   \n",
       " 1754        0.201144   X5363_8     -0.396197   \n",
       " 1769        0.221427   X5363_9     -0.456790   \n",
       " 1047        0.640622  X5356_12      0.607913   \n",
       " 1065        0.782608  X5356_13      0.798348   \n",
       " 1083        1.019250  X5356_14      0.807004   \n",
       " 1101        0.579771  X5356_15      0.694474   \n",
       " 1119        0.640622  X5356_16      0.720443   \n",
       " 1137        0.796130  X5356_17      0.703130   \n",
       " 1155        0.762324  X5356_18      0.694474   \n",
       " 1173        1.458729  X5356_19      0.703130   \n",
       " 1191        1.235609   X5356_2      0.651194   \n",
       " 1209        1.688610  X5356_20     -0.032640   \n",
       " 1227        1.451967  X5356_21      0.391510   \n",
       " 1245        1.391117  X5356_22      0.304949   \n",
       " 1263        1.776506  X5356_23      1.109968   \n",
       " 1281        1.898207  X5356_24      1.066688   \n",
       " 1299        0.992205   X5356_3      0.235700   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1226                          -0.609188     -0.044726  0.157724      0.199471   \n",
       " 1244                          -0.504975      0.128309  0.012970      0.083781   \n",
       " 1262                           1.759336      0.541670 -0.983169      0.062746   \n",
       " 1280                           2.455427      0.541670 -1.013820     -0.000358   \n",
       " 1298                          -1.613137     -0.919512  1.108618      0.909391   \n",
       " 1316                          -1.604338     -0.938739  1.093899      0.940943   \n",
       " 1334                          -1.126062     -0.256213  0.570310      0.320421   \n",
       " 1352                          -1.169692     -0.236987  0.533759      0.341455   \n",
       " 1370                          -1.405049     -0.602282  1.063485      0.651717   \n",
       " 1388                          -1.374631     -0.583056  1.093982      0.572837   \n",
       " 1406                          -1.339772     -0.496539  0.975855      0.546543   \n",
       " 1424                          -1.550671     -0.477313  0.939879      0.630682   \n",
       " 1439                          -1.505804     -0.361956  0.983241      0.525509   \n",
       " 1454                          -1.530599     -0.342730  0.863034      0.525509   \n",
       " 1469                          -1.504848     -0.265826  0.817862      0.499215   \n",
       " 1484                           1.218904      0.878126 -1.077510     -0.520966   \n",
       " 1499                           1.498229      0.858900 -1.153710     -0.499931   \n",
       " 1514                           1.422915      0.858900 -1.167542     -0.510449   \n",
       " 1529                           1.934758      1.003096 -0.873775     -0.452603   \n",
       " 1544                           1.835914      1.012709 -0.863656     -0.457862   \n",
       " 1559                           1.855677      0.983870 -0.899762     -0.447345   \n",
       " 1574                           2.717153      0.781996 -0.746394     -0.447345   \n",
       " 1589                          -1.536559     -0.410021  0.871234      0.541285   \n",
       " 1604                           2.733149      0.810835 -0.726206     -0.400017   \n",
       " 1619                           2.717153      0.781996 -0.731399     -0.405275   \n",
       " 1634                           2.474234      0.955031 -0.988509     -0.494673   \n",
       " 1649                           1.882047      0.993483 -0.940033     -0.520966   \n",
       " 1664                           1.884858      0.964644 -1.005419     -0.473638   \n",
       " 1679                          -1.534057     -0.361956  0.886989      0.536026   \n",
       " 1694                          -1.521490     -0.477313  0.812603      0.667493   \n",
       " 1709                          -1.564502     -0.486926  1.018723      0.641199   \n",
       " 1724                          -1.543783     -0.419634  0.882240      0.620165   \n",
       " 1739                          -1.516149     -0.323504  0.926367      0.520250   \n",
       " 1754                          -1.516796     -0.313891  0.935172      0.488698   \n",
       " 1769                          -1.568241     -0.371569  1.014530      0.541285   \n",
       " 1047                          -0.979175     -0.083178  0.347070      0.041711   \n",
       " 1065                          -0.683545      0.099470 -0.230574     -0.168635   \n",
       " 1083                          -0.680424      0.157148 -0.128867     -0.100273   \n",
       " 1101                          -0.742553     -0.063952  0.165291      0.004901   \n",
       " 1119                          -0.817247      0.061018 -0.043376     -0.089755   \n",
       " 1137                          -0.737549      0.118696  0.005155     -0.116049   \n",
       " 1155                          -0.745701      0.089857  0.139749     -0.095014   \n",
       " 1173                          -0.792143      0.157148  1.190553      0.036453   \n",
       " 1191                          -0.829813      0.061018 -0.095368     -0.073979   \n",
       " 1209                          -0.668505      0.109083  0.284734      0.052229   \n",
       " 1227                           0.345818      0.349409 -0.545060     -0.699761   \n",
       " 1245                           0.306910      0.455153 -0.515774     -0.778641   \n",
       " 1263                           5.278050      0.272505 -0.519841     -0.010875   \n",
       " 1281                           6.689038      0.176374 -0.473250     -0.073979   \n",
       " 1299                          -1.229628     -0.361956  0.839028      0.351973   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1226        1.500533            2      0.848310   -1.118056  2019-08-17   \n",
       " 1244        2.006936            2      0.835403   -1.126867  2019-08-17   \n",
       " 1262        3.190441            2      0.828524   -0.665072  2019-08-17   \n",
       " 1280        3.287170            2      0.797411   -0.602042  2019-08-17   \n",
       " 1298        1.443633            2      0.833132   -1.229124  2019-08-17   \n",
       " 1316        1.181897            2      0.915042   -1.227433  2019-08-17   \n",
       " 1334        2.166254            2      0.871707   -1.168208  2019-08-17   \n",
       " 1352        1.836238            2      0.914797   -1.165984  2019-08-17   \n",
       " 1370        1.750889            2      0.894016   -1.200509  2019-08-17   \n",
       " 1388        1.864688            2      0.899857   -1.202459  2019-08-17   \n",
       " 1406        1.910207            2      0.884600   -1.200027  2019-08-17   \n",
       " 1424        0.095120            2      0.719553   -1.199152  2019-08-17   \n",
       " 1439       -0.212136            2      0.839448   -1.194792  2019-08-17   \n",
       " 1454       -0.229206            2      0.843161   -1.195549  2019-08-17   \n",
       " 1469       -0.217826            2      0.852852   -1.194560  2019-08-17   \n",
       " 1484        0.299958            2      0.748604   -0.583123  2019-08-17   \n",
       " 1499        0.305648            2      0.717765   -0.384799  2019-08-17   \n",
       " 1514        0.214609            2      0.717650   -0.385382  2019-08-17   \n",
       " 1529        0.260128            2      0.637290   -0.297277  2019-08-17   \n",
       " 1544        0.334097            2      0.728768   -0.281018  2019-08-17   \n",
       " 1559        0.379617            2      0.593595   -0.295268  2019-08-17   \n",
       " 1574        0.305648            2      0.696192   -0.160120  2019-08-17   \n",
       " 1589        0.032531            2      0.633396   -1.194164  2019-08-17   \n",
       " 1604        0.362547            2      0.586168   -0.183230  2019-08-17   \n",
       " 1619        0.362547            2      0.645164   -0.163481  2019-08-17   \n",
       " 1634        0.436516            2      0.661632   -0.280638  2019-08-17   \n",
       " 1649        0.447896            2      0.641392   -0.275736  2019-08-17   \n",
       " 1664        0.487725            2      0.679586   -0.280162  2019-08-17   \n",
       " 1679        0.089430            2      0.590783   -1.196567  2019-08-17   \n",
       " 1694       -0.200756            2      0.658842   -1.199369  2019-08-17   \n",
       " 1709       -0.177996            2      0.658697   -1.199037  2019-08-17   \n",
       " 1724       -0.160927            2      0.790763   -1.198476  2019-08-17   \n",
       " 1739        0.043911            2      0.793251   -1.194410  2019-08-17   \n",
       " 1754        0.021151            2      0.639258   -1.195608  2019-08-17   \n",
       " 1769        0.021151            2      0.775254   -1.193883  2019-08-17   \n",
       " 1047        1.864688            3      0.887700   -1.122006  2019-08-18   \n",
       " 1065        2.069525            3      0.789509   -1.105034  2019-08-18   \n",
       " 1083        2.160564            3      0.874613   -1.112138  2019-08-18   \n",
       " 1101        1.711060            3      0.814003   -1.111761  2019-08-18   \n",
       " 1119        1.893138            3      0.905604   -1.110385  2019-08-18   \n",
       " 1137        2.228843            3      0.896684   -1.109999  2019-08-18   \n",
       " 1155        2.194704            3      0.879704   -1.109547  2019-08-18   \n",
       " 1173        1.938657            3      0.774778   -1.116593  2019-08-18   \n",
       " 1191        1.728130            3      0.903758   -1.115034  2019-08-18   \n",
       " 1209        2.217463            3      0.810837   -1.121247  2019-08-18   \n",
       " 1227        1.921587            3      0.889524   -0.982468  2019-08-18   \n",
       " 1245        2.006936            3      0.826729   -0.962609  2019-08-18   \n",
       " 1263        3.190441            3      0.838013   -0.166959  2019-08-18   \n",
       " 1281        3.287170            3      0.831834   -0.007102  2019-08-18   \n",
       " 1299        1.443633            3      0.778571   -1.187876  2019-08-18   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1226 -0.982468        -0.951348  \n",
       " 1244 -0.962609        -0.774674  \n",
       " 1262 -0.166959        -0.499506  \n",
       " 1280 -0.007102        -0.469347  \n",
       " 1298 -1.187876        -1.183265  \n",
       " 1316 -1.182980        -1.181049  \n",
       " 1334 -1.049073        -1.071937  \n",
       " 1352 -1.063280        -1.078664  \n",
       " 1370 -1.122086        -1.129806  \n",
       " 1388 -1.121109        -1.117075  \n",
       " 1406 -1.116006        -1.106440  \n",
       " 1424 -1.136862        -1.130748  \n",
       " 1439 -1.124127        -1.121748  \n",
       " 1454 -1.123957        -1.111894  \n",
       " 1469 -1.121002        -1.110163  \n",
       " 1484  0.019413        -0.204288  \n",
       " 1499  0.126681        -0.165961  \n",
       " 1514  0.072170        -0.172594  \n",
       " 1529  0.175535        -0.011147  \n",
       " 1544  0.168486        -0.028735  \n",
       " 1559  0.123359        -0.004846  \n",
       " 1574  0.364401        -0.003773  \n",
       " 1589 -1.135728        -0.915264  \n",
       " 1604  0.286030         0.054086  \n",
       " 1619  0.307483         0.052561  \n",
       " 1634  0.226203        -0.011724  \n",
       " 1649  0.220299         0.021122  \n",
       " 1664  0.159345        -0.060332  \n",
       " 1679 -1.139281        -0.914849  \n",
       " 1694 -1.138059        -0.973217  \n",
       " 1709 -1.139050        -0.976144  \n",
       " 1724 -1.132951        -1.128910  \n",
       " 1739 -1.125572        -1.109118  \n",
       " 1754 -1.128909        -0.922550  \n",
       " 1769 -1.126654        -1.111787  \n",
       " 1047 -1.018926        -1.052478  \n",
       " 1065 -0.948365        -0.939801  \n",
       " 1083 -0.972446        -0.986849  \n",
       " 1101 -0.985731        -1.053626  \n",
       " 1119 -0.988911        -1.093876  \n",
       " 1137 -0.973033        -1.049478  \n",
       " 1155 -1.010011        -1.035640  \n",
       " 1173 -0.924081        -1.014758  \n",
       " 1191 -0.999177        -0.998221  \n",
       " 1209 -0.940946        -0.910899  \n",
       " 1227 -0.656988        -0.585882  \n",
       " 1245 -0.646555        -0.539356  \n",
       " 1263  0.428058        -0.305323  \n",
       " 1281  0.508618        -0.242827  \n",
       " 1299 -1.122437        -1.057343  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1317        0.640622   X5356_4      0.270324   \n",
       " 1335        1.140952   X5356_5      0.651194   \n",
       " 1353        0.843459   X5356_6      0.703130   \n",
       " 1371        0.769085   X5356_7      0.625225   \n",
       " 1389        0.802891   X5356_8      0.633882   \n",
       " 1407        0.802891   X5356_9      0.720443   \n",
       " 1425        0.992205   X5363_1      0.244356   \n",
       " 1440        0.207905  X5363_10      0.607913   \n",
       " 1455        0.194382  X5363_11      0.599257   \n",
       " 1470        0.194382  X5363_12      0.625225   \n",
       " 1485       -0.015215  X5363_13      0.235700   \n",
       " 1500        0.059158  X5363_14      0.183763   \n",
       " 1515        0.059158  X5363_15      0.227044   \n",
       " 1530        0.092964  X5363_16      0.027953   \n",
       " 1545        0.099725  X5363_17      0.088546   \n",
       " 1560        0.221427  X5363_18      0.053921   \n",
       " 1575       -0.204529  X5363_19     -0.508727   \n",
       " 1590        0.654145   X5363_2      0.339573   \n",
       " 1605        0.735279  X5363_20     -0.612600   \n",
       " 1620        0.769085  X5363_21     -0.647225   \n",
       " 1635        0.897548  X5363_22     -0.041296   \n",
       " 1650        0.809652  X5363_23     -0.110545   \n",
       " 1665        0.816414  X5363_24      0.027953   \n",
       " 1680        0.660906   X5363_3      0.322261   \n",
       " 1695        0.424264   X5363_4      0.322261   \n",
       " 1710        0.410741   X5363_5      0.313605   \n",
       " 1725        0.201144   X5363_6      0.365542   \n",
       " 1740        0.302562   X5363_7      0.607913   \n",
       " 1755        0.397219   X5363_8      0.590601   \n",
       " 1770        0.234950   X5363_9      0.599257   \n",
       " 1048        1.059817  X5356_12      1.205186   \n",
       " 1066        1.127429  X5356_13      1.222498   \n",
       " 1084        1.147713  X5356_14      1.222498   \n",
       " 1102        0.856981  X5356_15      1.257122   \n",
       " 1120        0.924593  X5356_16      1.170561   \n",
       " 1138        1.032772  X5356_17      1.179217   \n",
       " 1156        1.032772  X5356_18      1.179217   \n",
       " 1174        1.458729  X5356_19      0.703130   \n",
       " 1192        1.573669   X5356_2      1.101312   \n",
       " 1210        1.249131  X5356_20      1.248466   \n",
       " 1228        0.593294  X5356_21      0.287637   \n",
       " 1246        0.586533  X5356_22      0.201075   \n",
       " 1264        0.586533  X5356_23      0.590601   \n",
       " 1282        0.755563  X5356_24      0.512696   \n",
       " 1300        1.593953   X5356_3      1.239810   \n",
       " 1318        1.215325   X5356_4      1.274435   \n",
       " 1336        1.167997   X5356_5      0.659850   \n",
       " 1354        0.843459   X5356_6      0.737755   \n",
       " 1372        1.337027   X5356_7      1.118624   \n",
       " 1390        1.215325   X5356_8      1.109968   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1317                          -1.174387     -0.410021  0.817092      0.373007   \n",
       " 1335                          -0.513465      0.310957 -0.388626     -0.457862   \n",
       " 1353                          -0.350891      0.243666 -0.433456     -0.484155   \n",
       " 1371                          -0.844854     -0.063952  0.162083     -0.031910   \n",
       " 1389                          -0.797793      0.032179  0.021468     -0.084497   \n",
       " 1407                          -0.674774      0.089857 -0.218869     -0.200187   \n",
       " 1425                          -1.217708      0.320570 -0.322407      0.062746   \n",
       " 1440                          -1.133596      0.637800 -0.133840     -0.305361   \n",
       " 1455                          -1.123869      0.618574  0.022275     -0.268550   \n",
       " 1470                          -1.107873      0.685866 -0.095918     -0.300102   \n",
       " 1485                           1.569465      0.637800 -0.955520     -0.505190   \n",
       " 1500                           1.574160      0.753157 -0.764414     -0.620881   \n",
       " 1515                           1.524261      0.608961 -1.003563     -0.515707   \n",
       " 1530                           1.866023      0.733931 -0.638866     -0.415793   \n",
       " 1545                           1.808617      0.724318 -0.664945     -0.431569   \n",
       " 1560                           1.687144      0.695479 -0.681260     -0.363206   \n",
       " 1575                           3.064566      0.320570 -0.316814     -0.258033   \n",
       " 1590                          -1.236543      0.320570 -0.309162      0.041711   \n",
       " 1605                           2.575916      0.330183 -0.300497     -0.168635   \n",
       " 1620                           3.009972      0.378248 -0.304237     -0.194929   \n",
       " 1635                           1.604297      0.753157 -0.598212     -0.368465   \n",
       " 1650                           1.997842      0.810835 -0.600015     -0.357947   \n",
       " 1665                           2.032673      0.781996 -0.618634     -0.357947   \n",
       " 1680                          -1.198254      0.387861 -0.437350     -0.010875   \n",
       " 1695                          -1.294286      0.272505 -0.285259      0.031194   \n",
       " 1710                          -1.302130      0.253279 -0.202746      0.057487   \n",
       " 1725                          -1.227744      0.320570 -0.483033     -0.010875   \n",
       " 1740                          -1.140174      0.618574  0.053437     -0.300102   \n",
       " 1755                          -1.151785      0.705092 -0.059686     -0.310619   \n",
       " 1770                          -1.187262      0.657026 -0.061243     -0.279067   \n",
       " 1048                          -0.474529      0.195600 -0.363961     -0.847003   \n",
       " 1066                          -0.293767      0.262892 -0.631020     -1.046832   \n",
       " 1084                          -0.279345      0.253279 -0.621066     -1.041574   \n",
       " 1102                          -0.319518      0.176374 -0.664818     -0.941659   \n",
       " 1120                          -0.273048      0.243666 -0.639350     -0.999504   \n",
       " 1138                          -0.242940      0.310957 -0.706656     -1.041574   \n",
       " 1156                          -0.271164      0.282118 -0.580099     -1.025798   \n",
       " 1174                          -0.141876      0.503218 -0.571755      0.330938   \n",
       " 1192                          -0.173896      0.205213 -0.717142     -1.083643   \n",
       " 1210                          -0.027655      0.455153 -0.454203     -0.862779   \n",
       " 1228                           0.845459      0.253279 -0.621983      0.383525   \n",
       " 1246                           1.011154      0.243666 -0.650817      0.399301   \n",
       " 1264                           2.736916     -0.169695 -0.269715      0.004901   \n",
       " 1282                           3.202963     -0.256213 -0.172046     -0.000358   \n",
       " 1300                          -0.982942     -0.006273 -0.315816     -0.631398   \n",
       " 1318                          -0.848621     -0.044726 -0.430442     -0.647174   \n",
       " 1336                          -0.025771      0.262892 -0.749658     -1.425456   \n",
       " 1354                           0.008132      0.359022 -0.433456     -1.320283   \n",
       " 1372                          -0.363457      0.272505 -0.658239     -0.936400   \n",
       " 1390                          -0.367224      0.272505 -0.661807     -0.983728   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1317        1.181897            3      0.858541   -1.182980  2019-08-18   \n",
       " 1335        2.166254            3      0.835634   -1.049073  2019-08-18   \n",
       " 1353        1.836238            3      0.905589   -1.063280  2019-08-18   \n",
       " 1371        1.750889            3      0.879725   -1.122086  2019-08-18   \n",
       " 1389        1.864688            3      0.829974   -1.121109  2019-08-18   \n",
       " 1407        1.910207            3      0.901458   -1.116006  2019-08-18   \n",
       " 1425       -0.934757            3      0.773610   -1.136862  2019-08-18   \n",
       " 1440       -0.325934            3      0.809337   -1.124127  2019-08-18   \n",
       " 1455       -0.223516            3      0.833370   -1.123957  2019-08-18   \n",
       " 1470       -0.177996            3      0.786069   -1.121002  2019-08-18   \n",
       " 1485       -0.746989            3      0.522615    0.019413  2019-08-18   \n",
       " 1500       -0.308865            3      0.544261    0.126681  2019-08-18   \n",
       " 1515        0.214609            3      0.564681    0.072170  2019-08-18   \n",
       " 1530        0.260128            3      0.483946    0.175535  2019-08-18   \n",
       " 1545        0.334097            3      0.466216    0.168486  2019-08-18   \n",
       " 1560        0.379617            3      0.383642    0.123359  2019-08-18   \n",
       " 1575        0.305648            3      0.669701    0.364401  2019-08-18   \n",
       " 1590       -0.934757            3      0.831531   -1.135728  2019-08-18   \n",
       " 1605       -0.746989            3      0.535378    0.286030  2019-08-18   \n",
       " 1620       -0.792509            3      0.570493    0.307483  2019-08-18   \n",
       " 1635       -0.803888            3      0.483903    0.226203  2019-08-18   \n",
       " 1650       -0.343004            3      0.547679    0.220299  2019-08-18   \n",
       " 1665        0.487725            3      0.550433    0.159345  2019-08-18   \n",
       " 1680       -0.934757            3      0.697864   -1.139281  2019-08-18   \n",
       " 1695       -0.934757            3      0.716453   -1.138059  2019-08-18   \n",
       " 1710       -0.934757            3      0.685001   -1.139050  2019-08-18   \n",
       " 1725       -0.934757            3      0.724968   -1.132951  2019-08-18   \n",
       " 1740       -0.860788            3      0.874202   -1.125572  2019-08-18   \n",
       " 1755       -0.269035            3      0.718082   -1.128909  2019-08-18   \n",
       " 1770       -0.337314            3      0.844878   -1.126654  2019-08-18   \n",
       " 1048        2.666968            4      0.898465   -1.018926  2019-08-19   \n",
       " 1066        2.775076            4      0.811248   -0.948365  2019-08-19   \n",
       " 1084        2.752317            4      0.778390   -0.972446  2019-08-19   \n",
       " 1102        2.445061            4      0.928735   -0.985731  2019-08-19   \n",
       " 1120        2.564549            4      0.921337   -0.988911  2019-08-19   \n",
       " 1138        2.837666            4      0.816187   -0.973033  2019-08-19   \n",
       " 1156        2.786456            4      0.852650   -1.010011  2019-08-19   \n",
       " 1174        1.938657            4      0.898357   -0.924081  2019-08-19   \n",
       " 1192        2.268673            4      0.815704   -0.999177  2019-08-19   \n",
       " 1210        3.053883            4      0.836989   -0.940946  2019-08-19   \n",
       " 1228        1.881758            4      0.883086   -0.656988  2019-08-19   \n",
       " 1246        1.836238            4      0.835821   -0.646555  2019-08-19   \n",
       " 1264        2.957154            4      0.712776    0.428058  2019-08-19   \n",
       " 1282        3.207511            4      0.668929    0.508618  2019-08-19   \n",
       " 1300        2.433681            4      0.758165   -1.122437  2019-08-19   \n",
       " 1318        2.137805            4      0.861707   -1.113129  2019-08-19   \n",
       " 1336        2.240223            4      0.832519   -0.913589  2019-08-19   \n",
       " 1354        1.836238            4      0.899280   -0.939236  2019-08-19   \n",
       " 1372        2.496270            4      0.883799   -1.024763  2019-08-19   \n",
       " 1390        2.513340            4      0.900989   -1.022348  2019-08-19   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1317 -1.113129        -1.092911  \n",
       " 1335 -0.913589        -0.723735  \n",
       " 1353 -0.939236        -0.747031  \n",
       " 1371 -1.024763        -1.037767  \n",
       " 1389 -1.022348        -0.989022  \n",
       " 1407 -0.989781        -0.970704  \n",
       " 1425 -1.013478        -0.612837  \n",
       " 1440 -0.984099        -0.980997  \n",
       " 1455 -0.984818        -1.011145  \n",
       " 1470 -0.978146        -0.984145  \n",
       " 1485  0.735363        -0.222623  \n",
       " 1500  0.746442         0.107576  \n",
       " 1515  0.726772         0.122985  \n",
       " 1530  0.687266         0.316728  \n",
       " 1545  0.684614         0.315330  \n",
       " 1560  0.654992         0.326930  \n",
       " 1575  0.854817         0.083772  \n",
       " 1590 -1.003642        -0.655545  \n",
       " 1605  0.805146        -0.066358  \n",
       " 1620  0.842072        -0.099269  \n",
       " 1635  0.711138        -0.115353  \n",
       " 1650  0.728756         0.083837  \n",
       " 1665  0.688261         0.174537  \n",
       " 1680 -1.024709        -0.536229  \n",
       " 1695 -1.013377        -0.633683  \n",
       " 1710 -1.018357        -0.692543  \n",
       " 1725 -0.999828        -0.521163  \n",
       " 1740 -0.978523        -0.741158  \n",
       " 1755 -0.996275        -0.967722  \n",
       " 1770 -0.987295        -0.994028  \n",
       " 1048 -0.809565        -0.917371  \n",
       " 1066 -0.763719        -0.810651  \n",
       " 1084 -0.759808        -0.806249  \n",
       " 1102 -0.749137        -0.924702  \n",
       " 1120 -0.777909        -0.894813  \n",
       " 1138 -0.805859        -0.820854  \n",
       " 1156 -0.765175        -0.870688  \n",
       " 1174 -0.624750        -0.678972  \n",
       " 1192 -0.849082        -0.839475  \n",
       " 1210 -0.700887        -0.788397  \n",
       " 1228 -0.295245        -0.009655  \n",
       " 1246 -0.367734         0.080689  \n",
       " 1264  0.917775         0.118365  \n",
       " 1282  0.359395         0.145470  \n",
       " 1300 -0.744919        -0.935299  \n",
       " 1318 -0.761310        -0.971536  \n",
       " 1336 -0.806013        -0.707076  \n",
       " 1354 -0.802786        -0.728011  \n",
       " 1372 -0.626879        -0.873543  \n",
       " 1390 -0.652544        -0.879234  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1408        1.195041   X5356_9      1.109968   \n",
       " 1426        1.019250   X5363_1      0.382854   \n",
       " 1441        0.349890  X5363_10      0.625225   \n",
       " 1456        0.302562  X5363_11      0.616569   \n",
       " 1471        0.282278  X5363_12      0.633882   \n",
       " 1486       -0.191007  X5363_13     -0.049952   \n",
       " 1501       -0.150439  X5363_14     -0.197106   \n",
       " 1516       -0.069305  X5363_15     -0.110545   \n",
       " 1531        0.126770  X5363_16     -0.603944   \n",
       " 1546        0.113248  X5363_17     -0.595288   \n",
       " 1561        0.282278  X5363_18     -0.552007   \n",
       " 1576       -0.583157  X5363_19     -0.889596   \n",
       " 1591        0.748802   X5363_2      0.469415   \n",
       " 1606       -0.177484  X5363_20     -0.846316   \n",
       " 1621       -0.319470  X5363_21     -0.872284   \n",
       " 1636        0.113248  X5363_22     -0.603944   \n",
       " 1651        0.018591  X5363_23     -0.621256   \n",
       " 1666        0.106487  X5363_24     -0.586632   \n",
       " 1681        0.701473   X5363_3      0.478071   \n",
       " 1696        0.559488   X5363_4      0.504040   \n",
       " 1711        0.485114   X5363_5      0.452103   \n",
       " 1726        0.336368   X5363_6      0.555976   \n",
       " 1741        0.349890   X5363_7      0.651194   \n",
       " 1756        0.464831   X5363_8      0.625225   \n",
       " 1771        0.363413   X5363_9      0.659850   \n",
       " 1049        1.113907  X5356_12      1.040719   \n",
       " 1067        1.012489  X5356_13      0.884909   \n",
       " 1085        0.965160  X5356_14      0.902221   \n",
       " 1103        0.782608  X5356_15      0.858941   \n",
       " 1121        0.769085  X5356_16      0.772379   \n",
       " 1139        1.276176  X5356_17      0.858941   \n",
       " 1157        1.208564  X5356_18      0.910877   \n",
       " 1175        1.749461  X5356_19      1.075344   \n",
       " 1193        1.289698   X5356_2      0.746411   \n",
       " 1211        1.762983  X5356_20      1.231154   \n",
       " 1229        0.694712  X5356_21      0.183763   \n",
       " 1247        1.039534  X5356_22      0.261668   \n",
       " 1265        0.627100  X5356_23      0.426135   \n",
       " 1283        0.363413  X5356_24      0.512696   \n",
       " 1301        1.857640   X5356_3      1.499494   \n",
       " 1319        1.627759   X5356_4      1.482182   \n",
       " 1337        0.755563   X5356_5      0.339573   \n",
       " 1355        0.532443   X5356_6      0.374198   \n",
       " 1373        1.499296   X5356_7      0.824316   \n",
       " 1391        1.289698   X5356_8      0.815660   \n",
       " 1409        1.411400   X5356_9      1.326371   \n",
       " 1427        0.809652   X5363_1      0.010641   \n",
       " 1442        0.214666  X5363_10     -0.136514   \n",
       " 1457        0.309323  X5363_11     -0.093233   \n",
       " 1472        0.268756  X5363_12     -0.119201   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1408                          -0.423084      0.262892 -0.383116     -1.073126   \n",
       " 1426                          -0.859303      0.772383 -1.199323     -0.620881   \n",
       " 1441                          -0.704573      1.166518 -1.017535     -1.173040   \n",
       " 1456                          -0.747585      1.156905 -1.065345     -1.173040   \n",
       " 1471                          -0.745055      1.195357 -1.027808     -1.178299   \n",
       " 1486                           1.246538      0.359022 -0.791083     -0.594587   \n",
       " 1501                           1.351032      0.512831 -0.746641     -0.662950   \n",
       " 1516                           0.899126      0.368635 -0.755467     -0.594587   \n",
       " 1531                           1.839681      0.243666 -0.327633     -0.152859   \n",
       " 1546                           1.924412      0.176374 -0.345529     -0.147601   \n",
       " 1561                           1.847216      0.243666 -0.401224     -0.116049   \n",
       " 1576                           2.778354     -0.188921 -0.042179     -0.421051   \n",
       " 1591                          -0.946536      0.762770 -1.168753     -0.662950   \n",
       " 1606                           2.526017     -0.160082  0.014739     -0.384241   \n",
       " 1621                           2.328303     -0.188921 -0.034659     -0.415793   \n",
       " 1636                           1.621248      0.157148 -0.294727     -0.210705   \n",
       " 1651                           2.014793      0.137922 -0.264987     -0.242257   \n",
       " 1666                           1.973356      0.137922 -0.277010     -0.215963   \n",
       " 1681                          -0.899476      0.801222 -1.215469     -0.641915   \n",
       " 1696                          -0.936809      0.762770 -1.212304     -0.647174   \n",
       " 1711                          -0.882215      0.753157 -1.130940     -0.641915   \n",
       " 1726                          -0.817556      0.753157 -1.262946     -0.668209   \n",
       " 1741                          -0.683236      1.195357 -1.066267     -1.188816   \n",
       " 1756                          -0.764846      1.243422 -1.127715     -1.157264   \n",
       " 1771                          -0.672581      1.195357 -1.102480     -1.183558   \n",
       " 1049                           0.047686      0.493605 -0.997336      0.735855   \n",
       " 1067                          -0.088518      0.378248 -0.692744      0.762149   \n",
       " 1085                          -0.123040      0.368635 -0.969146      0.746373   \n",
       " 1103                           0.108549      0.339796 -1.025292      0.656975   \n",
       " 1121                           0.132417      0.387861 -0.994756      0.693786   \n",
       " 1139                           0.109196      0.474379 -0.982496      0.756890   \n",
       " 1157                          -0.055880      0.455153 -0.934484      0.735855   \n",
       " 1175                           0.851728      0.378248 -0.735734     -1.593734   \n",
       " 1193                          -0.037044      0.522444 -0.858898      0.557061   \n",
       " 1211                           0.857379      0.560896 -0.949802      0.520250   \n",
       " 1229                           1.822111      0.070631 -0.547117     -0.841744   \n",
       " 1247                           1.634433      0.474379 -0.650817     -0.578811   \n",
       " 1265                           3.038196     -0.227373  0.053939     -0.052945   \n",
       " 1283                           3.082445     -0.496539  0.068965     -0.683985   \n",
       " 1301                          -0.574975      0.512831 -0.919582      0.793701   \n",
       " 1319                          -0.485212      0.445539 -0.773011      0.856805   \n",
       " 1337                           0.294344      0.503218 -0.899214      0.925167   \n",
       " 1355                           0.193927      0.416700 -0.902149      0.709562   \n",
       " 1373                           0.088477      0.474379 -1.029816      0.746373   \n",
       " 1391                          -0.099201      0.474379 -1.008233      0.756890   \n",
       " 1409                          -0.054643      0.474379 -0.946615      0.825253   \n",
       " 1427                          -0.381028      0.820448 -1.229155      0.357231   \n",
       " 1442                          -0.296915      1.166518 -1.172867      0.651717   \n",
       " 1457                          -0.294413      1.176131 -1.128893      0.678010   \n",
       " 1472                          -0.197116      1.195357 -1.110748      0.641199   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1408        2.587309            4      0.885789   -0.989781  2019-08-19   \n",
       " 1426       -0.496632            4      0.764691   -1.013478  2019-08-19   \n",
       " 1441        0.220299            4      0.805119   -0.984099  2019-08-19   \n",
       " 1456        0.282888            4      0.772471   -0.984818  2019-08-19   \n",
       " 1471        0.345477            4      0.738884   -0.978146  2019-08-19   \n",
       " 1486       -0.047128            4      0.340069    0.735363  2019-08-19   \n",
       " 1501       -0.308865            4      0.262067    0.746442  2019-08-19   \n",
       " 1516       -0.109717            4      0.274808    0.726772  2019-08-19   \n",
       " 1531        0.157709            4      0.363525    0.687266  2019-08-19   \n",
       " 1546        0.072361            4      0.371766    0.684614  2019-08-19   \n",
       " 1561        0.265818            4      0.272803    0.654992  2019-08-19   \n",
       " 1576       -0.121097            4      0.501121    0.854817  2019-08-19   \n",
       " 1591       -0.337314            4      0.650312   -1.003642  2019-08-19   \n",
       " 1606        0.060981            4      0.318907    0.805146  2019-08-19   \n",
       " 1621       -0.001609            4      0.412166    0.842072  2019-08-19   \n",
       " 1636        0.174779            4      0.448442    0.711138  2019-08-19   \n",
       " 1651       -0.343004            4      0.414012    0.728756  2019-08-19   \n",
       " 1666        0.487725            4      0.452184    0.688261  2019-08-19   \n",
       " 1681       -0.212136            4      0.490933   -1.024709  2019-08-19   \n",
       " 1696       -0.177996            4      0.609984   -1.013377  2019-08-19   \n",
       " 1711       -0.104027            4      0.659325   -1.018357  2019-08-19   \n",
       " 1726       -0.138167            4      0.701239   -0.999828  2019-08-19   \n",
       " 1741        0.220299            4      0.785947   -0.978523  2019-08-19   \n",
       " 1756        0.282888            4      0.714095   -0.996275  2019-08-19   \n",
       " 1771        0.208919            4      0.808198   -0.987295  2019-08-19   \n",
       " 1049        2.365402            5      0.829750   -0.809565  2019-08-20   \n",
       " 1067        2.274363            5      0.654523   -0.763719  2019-08-20   \n",
       " 1085        2.319882            5      0.730023   -0.759808  2019-08-20   \n",
       " 1103        2.024006            5      0.876207   -0.749137  2019-08-20   \n",
       " 1121        2.041076            5      0.830615   -0.777909  2019-08-20   \n",
       " 1139        2.103665            5      0.761100   -0.805859  2019-08-20   \n",
       " 1157        2.132115            5      0.772146   -0.765175  2019-08-20   \n",
       " 1175        2.917325            5      0.894716   -0.624750  2019-08-20   \n",
       " 1193        2.149184            5      0.847697   -0.849082  2019-08-20   \n",
       " 1211        3.014053            5      0.742785   -0.700887  2019-08-20   \n",
       " 1229        1.676920            5      0.841626   -0.295245  2019-08-20   \n",
       " 1247        2.189014            5      0.830320   -0.367734  2019-08-20   \n",
       " 1265        2.786456            5      0.591345    0.917775  2019-08-20   \n",
       " 1283        1.910207            5      0.454463    0.359395  2019-08-20   \n",
       " 1301        3.173371            5      0.664495   -0.744919  2019-08-20   \n",
       " 1319        2.854735            5      0.737788   -0.761310  2019-08-20   \n",
       " 1337        1.671230            5      0.756514   -0.806013  2019-08-20   \n",
       " 1355        1.398114            5      0.873049   -0.802786  2019-08-20   \n",
       " 1373        1.927277            5      0.894507   -0.626879  2019-08-20   \n",
       " 1391        1.938657            5      0.855145   -0.652544  2019-08-20   \n",
       " 1409        2.575929            5      0.793475   -0.966860  2019-08-20   \n",
       " 1427       -0.553532            5      0.669535   -0.835909  2019-08-20   \n",
       " 1442       -0.325934            5      0.756406   -0.786009  2019-08-20   \n",
       " 1457       -0.331624            5      0.740752   -0.784731  2019-08-20   \n",
       " 1472       -0.331624            5      0.784202   -0.785550  2019-08-20   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1408 -0.966860        -0.775595  \n",
       " 1426 -0.835909        -0.882902  \n",
       " 1441 -0.786009        -0.866971  \n",
       " 1456 -0.784731        -0.871079  \n",
       " 1471 -0.785550        -0.855158  \n",
       " 1486  1.081805         0.313836  \n",
       " 1501  1.120725         0.494936  \n",
       " 1516  1.082699         0.228056  \n",
       " 1531  1.070993         0.647994  \n",
       " 1546  1.076778         0.649756  \n",
       " 1561  0.977173         0.707116  \n",
       " 1576  1.269115         0.696269  \n",
       " 1591 -0.806852        -0.866331  \n",
       " 1606  1.177299         0.851985  \n",
       " 1621  1.198925         0.766246  \n",
       " 1636  1.082015         0.573805  \n",
       " 1651  1.127222         0.635044  \n",
       " 1666  1.074207         0.642361  \n",
       " 1681 -0.843684        -0.786698  \n",
       " 1696 -0.843536        -0.869198  \n",
       " 1711 -0.840661        -0.879717  \n",
       " 1726 -0.817411        -0.885560  \n",
       " 1741 -0.785323        -0.836883  \n",
       " 1756 -0.811335        -0.801542  \n",
       " 1771 -0.792522        -0.850421  \n",
       " 1049 -0.660857        -0.721981  \n",
       " 1067 -0.589805        -0.535530  \n",
       " 1085 -0.614501        -0.703423  \n",
       " 1103 -0.609721        -0.699395  \n",
       " 1121 -0.606211        -0.688042  \n",
       " 1139 -0.634715        -0.652287  \n",
       " 1157 -0.545125        -0.767253  \n",
       " 1175 -0.432347        -0.258273  \n",
       " 1193 -0.611380        -0.772037  \n",
       " 1211 -0.509515        -0.065761  \n",
       " 1229 -0.073247        -0.050965  \n",
       " 1247 -0.066340         0.140470  \n",
       " 1265  1.352955         0.624542  \n",
       " 1283  1.384818         0.733525  \n",
       " 1301 -0.860615        -0.646396  \n",
       " 1319 -0.823071        -0.746175  \n",
       " 1337 -0.466288        -0.472793  \n",
       " 1355 -0.444610        -0.677908  \n",
       " 1373 -0.648342        -0.751840  \n",
       " 1391 -0.656035        -0.799700  \n",
       " 1409 -0.648743        -0.803166  \n",
       " 1427 -0.586510        -0.398890  \n",
       " 1442 -0.482943        -0.580938  \n",
       " 1457 -0.487949        -0.596717  \n",
       " 1472 -0.476688        -0.636155  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1487        0.214666  X5363_13     -0.119201   \n",
       " 1502        0.126770  X5363_14     -0.266355   \n",
       " 1517        0.153815  X5363_15     -0.136514   \n",
       " 1532       -0.150439  X5363_16     -0.785723   \n",
       " 1547       -0.035499  X5363_17     -0.742442   \n",
       " 1562        0.147054  X5363_18     -0.707818   \n",
       " 1577       -1.015874  X5363_19     -0.837660   \n",
       " 1592        0.606816   X5363_2      0.045265   \n",
       " 1607       -0.623724  X5363_20     -0.794379   \n",
       " 1622       -0.738665  X5363_21     -0.829003   \n",
       " 1637        0.248472  X5363_22     -0.716474   \n",
       " 1652        0.086203  X5363_23     -0.768411   \n",
       " 1667        0.275517  X5363_24     -0.733786   \n",
       " 1682        0.877265   X5363_3      0.131826   \n",
       " 1697        0.667667   X5363_4      0.114514   \n",
       " 1712        0.667667   X5363_5      0.097202   \n",
       " 1727        0.403980   X5363_6     -0.491415   \n",
       " 1742        0.451308   X5363_7     -0.101889   \n",
       " 1757        0.627100   X5363_8     -0.067265   \n",
       " 1772        0.336368   X5363_9     -0.119201   \n",
       " 1050        0.951638  X5356_12      0.633882   \n",
       " 1068        0.890787  X5356_13      0.633882   \n",
       " 1086        0.917832  X5356_14      0.677162   \n",
       " 1104        0.701473  X5356_15      0.538664   \n",
       " 1122        0.660906  X5356_16      0.495384   \n",
       " 1140        0.708234  X5356_17      0.538664   \n",
       " 1158        0.748802  X5356_18      0.910877   \n",
       " 1176        1.776506  X5356_19      0.850285   \n",
       " 1194        0.829936   X5356_2      0.530008   \n",
       " 1212        1.817073  X5356_20      0.936846   \n",
       " 1230        0.958399  X5356_21      0.114514   \n",
       " 1248        0.951638  X5356_22      0.097202   \n",
       " 1266        0.343129  X5356_23      0.218388   \n",
       " 1284        0.890787  X5356_24      0.261668   \n",
       " 1302        1.648043   X5356_3      1.127281   \n",
       " 1320        1.411400   X5356_4      1.153249   \n",
       " 1338        0.120009   X5356_5      0.175107   \n",
       " 1356       -0.150439   X5356_6      0.261668   \n",
       " 1374        0.525682   X5356_7      0.538664   \n",
       " 1392        0.437786   X5356_8      0.504040   \n",
       " 1410        0.863742   X5356_9      0.486727   \n",
       " 1428        0.809652   X5363_1      0.010641   \n",
       " 1443        0.214666  X5363_10     -0.136514   \n",
       " 1458        0.309323  X5363_11     -0.093233   \n",
       " 1473        0.268756  X5363_12     -0.119201   \n",
       " 1488        0.214666  X5363_13     -0.119201   \n",
       " 1503        0.126770  X5363_14     -0.266355   \n",
       " 1518        0.153815  X5363_15     -0.136514   \n",
       " 1533       -0.150439  X5363_16     -0.785723   \n",
       " 1548       -0.035499  X5363_17     -0.742442   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1487                           1.046941      0.157148 -0.579500      0.004901   \n",
       " 1502                           1.134483      0.339796 -0.389324      0.004901   \n",
       " 1517                           1.392470      0.157148 -0.642140     -0.031910   \n",
       " 1532                           1.470594     -0.227373 -0.153486     -0.179153   \n",
       " 1547                           1.328430     -0.294665 -0.174414     -0.142342   \n",
       " 1562                           1.705051     -0.217760 -0.270452     -0.100273   \n",
       " 1577                           2.332070     -0.438860  0.038158     -0.310619   \n",
       " 1592                          -0.490244      0.676253 -1.212337      0.588613   \n",
       " 1607                           2.109898     -0.390795  0.069712     -0.242257   \n",
       " 1622                           2.414945     -0.429247  0.075326     -0.263291   \n",
       " 1637                           2.065649      0.214826 -0.136329     -0.079238   \n",
       " 1652                           1.657035      0.234053  0.048503     -0.116049   \n",
       " 1667                           1.582650      0.262892  0.020675     -0.110790   \n",
       " 1682                          -0.658440      0.772383 -1.230856      0.714821   \n",
       " 1697                          -0.567441      0.714705 -1.210350      0.678010   \n",
       " 1712                          -0.563674      0.695479 -0.994721      0.656975   \n",
       " 1727                          -0.520352      0.628187 -1.268812      0.641199   \n",
       " 1742                          -0.294413      1.089613 -1.185683      0.699045   \n",
       " 1757                          -0.436240      1.176131 -1.169449      0.720079   \n",
       " 1772                          -0.400481      1.156905 -1.180358      0.735855   \n",
       " 1050                          -0.033924      0.551283 -0.675414      0.373007   \n",
       " 1068                          -0.136534      0.397474 -0.571230      0.467663   \n",
       " 1086                          -0.070639      0.397474 -0.712537      0.430853   \n",
       " 1104                           0.305955      0.359022 -0.695656      0.309903   \n",
       " 1122                           0.216529      0.378248 -0.666296      0.346714   \n",
       " 1140                           0.078132      0.455153 -0.443483      0.394042   \n",
       " 1158                           0.159096      0.435926 -0.577117      0.367749   \n",
       " 1176                           1.349149      0.416700 -0.617576      0.756890   \n",
       " 1194                          -0.051803      0.359022 -0.739348      0.025935   \n",
       " 1212                           0.914166      0.580122 -0.626525     -0.152859   \n",
       " 1230                           2.118359      0.080244 -0.338957      0.714821   \n",
       " 1248                           1.801083      0.022566 -0.176629      0.399301   \n",
       " 1266                           2.437519     -0.736865  0.263016      0.136367   \n",
       " 1284                           2.105175     -0.573443  0.163164      0.683269   \n",
       " 1302                          -0.377570      0.512831 -0.724221      0.315162   \n",
       " 1320                          -0.259891      0.435926 -0.836695      0.362490   \n",
       " 1338                           0.477328      0.272505 -0.418733      0.357231   \n",
       " 1356                           0.385063      0.176374 -0.564554      0.125850   \n",
       " 1374                           0.257011      0.387861 -0.759299      0.220506   \n",
       " 1392                           0.085666      0.387861 -0.643456      0.262575   \n",
       " 1410                           0.260778      0.349409 -0.581207      0.362490   \n",
       " 1428                          -0.114269      0.820448 -0.874747      0.357231   \n",
       " 1443                           0.195810      1.166518 -0.747827      0.651717   \n",
       " 1458                           0.130533      1.176131 -0.744263      0.678010   \n",
       " 1473                           0.049570      1.195357 -0.605126      0.641199   \n",
       " 1488                           0.797443      0.157148 -0.486839      0.004901   \n",
       " 1503                           1.027149      0.339796 -0.419162      0.004901   \n",
       " 1518                           1.177804      0.157148 -0.492569     -0.031910   \n",
       " 1533                           1.284181     -0.227373 -0.049349     -0.179153   \n",
       " 1548                           1.057286     -0.294665 -0.087665     -0.142342   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1487        0.146330            5      0.102140    1.081805  2019-08-20   \n",
       " 1502        0.055291            5      0.099054    1.120725  2019-08-20   \n",
       " 1517        0.038221            5      0.161302    1.082699  2019-08-20   \n",
       " 1532       -0.081268            5      0.203728    1.070993  2019-08-20   \n",
       " 1547       -0.058508            5      0.080704    1.076778  2019-08-20   \n",
       " 1562        0.060981            5     -0.112629    0.977173  2019-08-20   \n",
       " 1577       -0.240586            5      0.257186    1.269115  2019-08-20   \n",
       " 1592       -0.519392            5      0.715256   -0.806852  2019-08-20   \n",
       " 1607       -0.166616            5      0.020958    1.177299  2019-08-20   \n",
       " 1622       -0.246275            5      0.224537    1.198925  2019-08-20   \n",
       " 1637       -0.007298            5      0.183365    1.082015  2019-08-20   \n",
       " 1652       -0.064198            5      0.250249    1.127222  2019-08-20   \n",
       " 1667        0.021151            5      0.226924    1.074207  2019-08-20   \n",
       " 1682       -0.411283            5      0.498266   -0.843684  2019-08-20   \n",
       " 1697       -0.422663            5      0.631824   -0.843536  2019-08-20   \n",
       " 1712       -0.405593            5      0.567580   -0.840661  2019-08-20   \n",
       " 1727       -0.456803            5      0.643116   -0.817411  2019-08-20   \n",
       " 1742       -0.354384            5      0.775773   -0.785323  2019-08-20   \n",
       " 1757       -0.280415            5      0.578251   -0.811335  2019-08-20   \n",
       " 1772       -0.354384            5      0.732799   -0.792522  2019-08-20   \n",
       " 1050        1.773649            6      0.768548   -0.660857  2019-08-21   \n",
       " 1068        1.796409            6      0.532205   -0.589805  2019-08-21   \n",
       " 1086        1.858998            6      0.570399   -0.614501  2019-08-21   \n",
       " 1104        1.551742            6      0.833557   -0.609721  2019-08-21   \n",
       " 1122        1.506222            6      0.784130   -0.606211  2019-08-21   \n",
       " 1140        1.642781            6      0.671871   -0.634715  2019-08-21   \n",
       " 1158        1.693990            6      0.779717   -0.545125  2019-08-21   \n",
       " 1176        3.139232            6      0.834603   -0.432347  2019-08-21   \n",
       " 1194        1.420874            6      0.786834   -0.611380  2019-08-21   \n",
       " 1212        3.395279            6      0.712285   -0.509515  2019-08-21   \n",
       " 1230        2.035386            6      0.762938   -0.073247  2019-08-21   \n",
       " 1248        2.154874            6      0.719690   -0.066340  2019-08-21   \n",
       " 1266        2.797836            6      0.190114    1.352955  2019-08-21   \n",
       " 1284        3.048193            6      0.217846    1.384818  2019-08-21   \n",
       " 1302        2.666968            6      0.575980   -0.860615  2019-08-21   \n",
       " 1320        2.484890            6      0.736894   -0.823071  2019-08-21   \n",
       " 1338        0.920160            6      0.677019   -0.466288  2019-08-21   \n",
       " 1356        0.590144            6      0.818372   -0.444610  2019-08-21   \n",
       " 1374        1.432253            6      0.859003   -0.648342  2019-08-21   \n",
       " 1392        1.375354            6      0.808789   -0.656035  2019-08-21   \n",
       " 1410        1.489153            6      0.727269   -0.648743  2019-08-21   \n",
       " 1428       -0.553532            6      0.586334   -0.586510  2019-08-21   \n",
       " 1443       -0.325934            6      0.550642   -0.482943  2019-08-21   \n",
       " 1458       -0.331624            6      0.576845   -0.487949  2019-08-21   \n",
       " 1473       -0.331624            6      0.635393   -0.476688  2019-08-21   \n",
       " 1488        0.146330            6     -0.394830    1.500600  2019-08-21   \n",
       " 1503        0.055291            6     -0.329814    1.515201  2019-08-21   \n",
       " 1518        0.038221            6     -0.331105    1.473276  2019-08-21   \n",
       " 1533       -0.081268            6     -0.281129    1.434929  2019-08-21   \n",
       " 1548       -0.058508            6     -0.366854    1.389901  2019-08-21   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1487  1.500600         0.475879  \n",
       " 1502  1.515201         0.530366  \n",
       " 1517  1.473276         0.693132  \n",
       " 1532  1.434929         0.914127  \n",
       " 1547  1.389901         0.808348  \n",
       " 1562  1.255642         0.924242  \n",
       " 1577  1.444159         1.532104  \n",
       " 1592 -0.526753        -0.619186  \n",
       " 1607  1.441977         1.491158  \n",
       " 1622  1.456140         1.494433  \n",
       " 1637  1.420471         1.131020  \n",
       " 1652  1.501844         0.856593  \n",
       " 1667  1.425364         0.731927  \n",
       " 1682 -0.592933        -0.458935  \n",
       " 1697 -0.569007        -0.621959  \n",
       " 1712 -0.574197        -0.575318  \n",
       " 1727 -0.535568        -0.574068  \n",
       " 1742 -0.485495        -0.568648  \n",
       " 1757 -0.535126        -0.561802  \n",
       " 1772 -0.493544        -0.538490  \n",
       " 1050 -0.396605        -0.388471  \n",
       " 1068 -0.325958        -0.446243  \n",
       " 1086 -0.329799        -0.337395  \n",
       " 1104 -0.317520        -0.586811  \n",
       " 1122 -0.230726        -0.392242  \n",
       " 1140 -0.272760        -0.284374  \n",
       " 1158 -0.228073        -0.398033  \n",
       " 1176 -0.035177         0.048550  \n",
       " 1194 -0.325143        -0.536529  \n",
       " 1212 -0.138303         0.067337  \n",
       " 1230  0.432052         0.452721  \n",
       " 1248  0.405192         0.357423  \n",
       " 1266  1.820815         1.103881  \n",
       " 1284  1.998491         0.955106  \n",
       " 1302 -0.591619        -0.722571  \n",
       " 1320 -0.542438        -0.718298  \n",
       " 1338 -0.173312        -0.056349  \n",
       " 1356 -0.105460        -0.445778  \n",
       " 1374 -0.384064        -0.638493  \n",
       " 1392 -0.289487        -0.637559  \n",
       " 1410 -0.324839        -0.298335  \n",
       " 1428 -0.288566        -0.542901  \n",
       " 1443 -0.243809        -0.154778  \n",
       " 1458 -0.246332        -0.278278  \n",
       " 1473 -0.249680        -0.330429  \n",
       " 1488  1.712557         0.552498  \n",
       " 1503  1.734675         0.666716  \n",
       " 1518  1.670224         0.647473  \n",
       " 1533  1.608785         1.071463  \n",
       " 1548  1.583356         1.144295  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1563        0.147054  X5363_18     -0.707818   \n",
       " 1578       -1.015874  X5363_19     -0.837660   \n",
       " 1593        0.606816   X5363_2      0.045265   \n",
       " 1608       -0.623724  X5363_20     -0.794379   \n",
       " 1623       -0.738665  X5363_21     -0.829003   \n",
       " 1638        0.248472  X5363_22     -0.716474   \n",
       " 1653        0.086203  X5363_23     -0.768411   \n",
       " 1668        0.275517  X5363_24     -0.733786   \n",
       " 1683        0.877265   X5363_3      0.131826   \n",
       " 1698        0.667667   X5363_4      0.114514   \n",
       " 1713        0.667667   X5363_5      0.097202   \n",
       " 1728        0.403980   X5363_6     -0.491415   \n",
       " 1743        0.451308   X5363_7     -0.101889   \n",
       " 1758        0.627100   X5363_8     -0.067265   \n",
       " 1773        0.336368   X5363_9     -0.119201   \n",
       " 1051        0.120009  X5356_12      0.183763   \n",
       " 1069        0.065919  X5356_13      0.244356   \n",
       " 1087        0.755563  X5356_14      0.157795   \n",
       " 1105        0.322845  X5356_15      0.071233   \n",
       " 1123        0.234950  X5356_16      0.027953   \n",
       " 1141        0.221427  X5356_17      0.097202   \n",
       " 1159        0.309323  X5356_18      0.140482   \n",
       " 1177        1.898207  X5356_19      0.685818   \n",
       " 1195        0.248472   X5356_2      0.105858   \n",
       " 1213        2.006387  X5356_20      0.668506   \n",
       " 1231        0.884026  X5356_21      0.071233   \n",
       " 1249        1.107146  X5356_22      0.019297   \n",
       " 1267        0.092964  X5356_23      0.538664   \n",
       " 1285        0.437786  X5356_24      0.633882   \n",
       " 1303        1.282937   X5356_3      0.659850   \n",
       " 1321        1.073340   X5356_4      0.659850   \n",
       " 1339       -0.434410   X5356_5     -0.119201   \n",
       " 1357       -0.779232   X5356_6     -0.041296   \n",
       " 1375       -0.035499   X5356_7      0.105858   \n",
       " 1393       -0.130156   X5356_8      0.097202   \n",
       " 1411        0.018591   X5356_9      0.183763   \n",
       " 1429        0.316084   X5363_1     -0.448134   \n",
       " 1444        0.322845  X5363_10      0.209731   \n",
       " 1459        0.667667  X5363_11      0.062577   \n",
       " 1474        0.410741  X5363_12      0.123170   \n",
       " 1489       -0.434410  X5363_13     -0.214419   \n",
       " 1504       -0.285663  X5363_14     -0.396197   \n",
       " 1519       -0.346514  X5363_15     -0.179794   \n",
       " 1534       -0.623724  X5363_16     -0.508727   \n",
       " 1549       -0.549351  X5363_17     -0.456790   \n",
       " 1564       -0.427649  X5363_18     -0.378885   \n",
       " 1579       -1.157860  X5363_19     -0.837660   \n",
       " 1594        0.207905   X5363_2     -0.335604   \n",
       " 1609       -0.982068  X5363_20     -0.448134   \n",
       " 1624       -1.117292  X5363_21     -0.526039   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1563                           1.284181     -0.217760 -0.089431     -0.100273   \n",
       " 1578                           1.959243     -0.438860  0.206714     -0.310619   \n",
       " 1593                          -0.108619      0.676253 -0.916223      0.588613   \n",
       " 1608                           1.482851     -0.390795  0.276983     -0.242257   \n",
       " 1623                           1.795433     -0.429247  0.313972     -0.263291   \n",
       " 1638                           1.337847      0.214826 -0.106978     -0.079238   \n",
       " 1653                           1.186266      0.234053 -0.029503     -0.116049   \n",
       " 1668                           1.211679      0.262892 -0.059328     -0.110790   \n",
       " 1683                          -0.259891      0.772383 -1.000874      0.714821   \n",
       " 1698                          -0.180165      0.714705 -0.929843      0.678010   \n",
       " 1713                          -0.303803      0.695479 -0.993784      0.656975   \n",
       " 1728                          -0.081631      0.628187 -0.838283      0.641199   \n",
       " 1743                           0.102927      1.089613 -0.829363      0.699045   \n",
       " 1758                           0.047040      1.176131 -0.731132      0.720079   \n",
       " 1773                           0.124883      1.156905 -0.761103      0.735855   \n",
       " 1051                           0.344553      0.205213 -0.558329     -0.179153   \n",
       " 1069                           0.026349      0.012953 -0.429307     -0.100273   \n",
       " 1087                          -0.074406      0.128309 -0.486165      0.015418   \n",
       " 1105                           0.371878      0.051405 -0.457300     -0.163377   \n",
       " 1123                           0.427428      0.089857 -0.470569     -0.152859   \n",
       " 1141                           0.276774      0.214826 -0.460870     -0.105531   \n",
       " 1159                           0.232525      0.234053 -0.513258     -0.142342   \n",
       " 1177                           1.501686      0.128309 -0.438434     -0.068721   \n",
       " 1195                           0.419894      0.032179 -0.438125     -0.484155   \n",
       " 1213                           1.249350      0.253279 -0.452345     -0.910107   \n",
       " 1231                           1.992191     -0.381182 -0.008765     -0.321137   \n",
       " 1249                           1.804850     -0.342730  0.040701     -0.552518   \n",
       " 1267                           1.853794     -0.813769  0.335118     -0.147601   \n",
       " 1285                           2.015721     -0.794543  0.195034     -0.326395   \n",
       " 1303                           0.001863      0.330183 -0.594285     -0.095014   \n",
       " 1321                           0.002791      0.253279 -0.678668     -0.073979   \n",
       " 1339                           0.400103     -0.083178 -0.272768     -0.142342   \n",
       " 1357                           0.723058     -0.227373 -0.264223     -0.394758   \n",
       " 1375                           0.384107      0.061018 -0.524312     -0.279067   \n",
       " 1393                           0.341742      0.061018 -0.526900     -0.236998   \n",
       " 1411                           0.259822     -0.015887 -0.426688     -0.184411   \n",
       " 1429                           0.440613      0.570509 -0.725611     -1.488560   \n",
       " 1444                           0.354617      0.983870 -0.739393     -1.425456   \n",
       " 1459                           0.520311      1.070387 -0.847508     -1.362352   \n",
       " 1474                           0.379075      1.041548 -0.828448     -1.404422   \n",
       " 1489                           0.531922      0.012953 -0.770598     -0.000358   \n",
       " 1504                           0.817206      0.301344 -0.766898      0.046970   \n",
       " 1519                           0.682576      0.089857 -0.852261     -0.010875   \n",
       " 1534                           0.986668     -0.429247 -0.223667      0.015418   \n",
       " 1549                           0.780491     -0.438860 -0.046903      0.004901   \n",
       " 1564                           0.686343     -0.275439 -0.306570     -0.052945   \n",
       " 1579                           1.287020     -0.650347  0.023492     -0.137083   \n",
       " 1594                           0.254172      0.503218 -0.773697     -1.241403   \n",
       " 1609                           1.081772     -0.698413  0.011967     -0.095014   \n",
       " 1624                           1.468711     -0.631121 -0.054347     -0.147601   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1563        0.060981            6     -0.610515    1.255642  2019-08-21   \n",
       " 1578       -0.240586            6     -0.144694    1.444159  2019-08-21   \n",
       " 1593       -0.519392            6      0.490839   -0.526753  2019-08-21   \n",
       " 1608       -0.166616            6     -0.443147    1.441977  2019-08-21   \n",
       " 1623       -0.246275            6     -0.154817    1.456140  2019-08-21   \n",
       " 1638       -0.007298            6     -0.172858    1.420471  2019-08-21   \n",
       " 1653       -0.064198            6     -0.120092    1.501844  2019-08-21   \n",
       " 1668        0.021151            6     -0.105606    1.425364  2019-08-21   \n",
       " 1683       -0.411283            6      0.263754   -0.592933  2019-08-21   \n",
       " 1698       -0.422663            6      0.404530   -0.569007  2019-08-21   \n",
       " 1713       -0.405593            6      0.302164   -0.574197  2019-08-21   \n",
       " 1728       -0.456803            6      0.501063   -0.535568  2019-08-21   \n",
       " 1743       -0.354384            6      0.667134   -0.485495  2019-08-21   \n",
       " 1758       -0.280415            6      0.519818   -0.535126  2019-08-21   \n",
       " 1773       -0.354384            6      0.553541   -0.493544  2019-08-21   \n",
       " 1051        1.119307            7      0.708269   -0.396605  2019-08-22   \n",
       " 1069        1.176207            7      0.571870   -0.325958  2019-08-22   \n",
       " 1087        1.386734            7      0.519609   -0.329799  2019-08-22   \n",
       " 1105        0.959989            7      0.779876   -0.317520  2019-08-22   \n",
       " 1123        0.914470            7      0.715004   -0.230726  2019-08-22   \n",
       " 1141        1.022579            7      0.680285   -0.272760  2019-08-22   \n",
       " 1159        1.153447            7      0.705133   -0.228073  2019-08-22   \n",
       " 1177        3.492007            7      0.789401   -0.035177  2019-08-22   \n",
       " 1195        0.851881            7      0.694879   -0.325143  2019-08-22   \n",
       " 1213        3.844783            7      0.643029   -0.138303  2019-08-22   \n",
       " 1231        2.541789            7      0.708406    0.432052  2019-08-22   \n",
       " 1249        2.905945            7      0.595332    0.405192  2019-08-22   \n",
       " 1267        2.740937            7     -0.009448    1.820815  2019-08-22   \n",
       " 1285        3.292860            7     -0.046474    1.998491  2019-08-22   \n",
       " 1303        2.211774            7      0.575468   -0.591619  2019-08-22   \n",
       " 1321        2.086595            7      0.670148   -0.542438  2019-08-22   \n",
       " 1339        0.345477            7      0.576282   -0.173312  2019-08-22   \n",
       " 1357       -0.052818            7      0.792004   -0.105460  2019-08-22   \n",
       " 1375        0.766532            7      0.792667   -0.384064  2019-08-22   \n",
       " 1393        0.692563            7      0.767567   -0.289487  2019-08-22   \n",
       " 1411        0.971369            7      0.622667   -0.324839  2019-08-22   \n",
       " 1429       -0.695780            7      0.486852   -0.288566  2019-08-22   \n",
       " 1444       -0.030058            7      0.481999   -0.243809  2019-08-22   \n",
       " 1459       -0.058508            7      0.504669   -0.246332  2019-08-22   \n",
       " 1474        0.009771            7      0.505217   -0.249680  2019-08-22   \n",
       " 1489        0.169089            7     -0.843152    1.712557  2019-08-22   \n",
       " 1504        0.060981            7     -0.861856    1.734675  2019-08-22   \n",
       " 1519        0.060981            7     -0.761177    1.670224  2019-08-22   \n",
       " 1534       -0.018678            7     -0.577809    1.608785  2019-08-22   \n",
       " 1549       -0.018678            7     -0.825515    1.583356  2019-08-22   \n",
       " 1564       -0.001609            7     -0.985507    1.524488  2019-08-22   \n",
       " 1579       -0.115407            7     -0.351330    1.525202  2019-08-22   \n",
       " 1594       -0.599051            7      0.420516   -0.261541  2019-08-22   \n",
       " 1609       -0.075578            7     -0.719220    1.555341  2019-08-22   \n",
       " 1624       -0.121097            7     -0.459760    1.593352  2019-08-22   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1563  1.524488         1.467442  \n",
       " 1578  1.525202         1.773185  \n",
       " 1593 -0.261541        -0.238588  \n",
       " 1608  1.555341         1.596012  \n",
       " 1623  1.593352         1.613125  \n",
       " 1638  1.668271         1.265096  \n",
       " 1653  1.712314         1.087490  \n",
       " 1668  1.608383         0.982829  \n",
       " 1683 -0.364467        -0.099543  \n",
       " 1698 -0.319281        -0.239202  \n",
       " 1713 -0.341721        -0.217047  \n",
       " 1728 -0.277598        -0.142188  \n",
       " 1743 -0.240079        -0.374015  \n",
       " 1758 -0.310108        -0.206009  \n",
       " 1773 -0.262029        -0.185683  \n",
       " 1051 -0.207952        -0.175456  \n",
       " 1069 -0.149890        -0.038497  \n",
       " 1087 -0.158585         0.101801  \n",
       " 1105 -0.094205        -0.358833  \n",
       " 1123 -0.074628        -0.202881  \n",
       " 1141 -0.116483        -0.228525  \n",
       " 1159 -0.127054        -0.284392  \n",
       " 1177  0.120615         0.228273  \n",
       " 1195 -0.093345        -0.171315  \n",
       " 1213  0.044287         0.089553  \n",
       " 1231  0.583325         0.650532  \n",
       " 1249  0.490311         0.782621  \n",
       " 1267  1.915575         1.529083  \n",
       " 1285  2.082997         1.832942  \n",
       " 1303 -0.467272        -0.320181  \n",
       " 1321 -0.401152        -0.435374  \n",
       " 1339  0.029555         0.090958  \n",
       " 1357  0.120889        -0.252849  \n",
       " 1375 -0.113034        -0.404939  \n",
       " 1393 -0.098885        -0.315280  \n",
       " 1411 -0.104324        -0.152106  \n",
       " 1429 -0.060907        -0.218497  \n",
       " 1444  0.041905        -0.141105  \n",
       " 1459  0.037335        -0.258053  \n",
       " 1474  0.032045        -0.198241  \n",
       " 1489  1.914214         1.190157  \n",
       " 1504  2.025207         1.042276  \n",
       " 1519  1.924317         1.133627  \n",
       " 1534  1.755673         1.271306  \n",
       " 1549  1.735339         1.272730  \n",
       " 1564  1.787534         1.170082  \n",
       " 1579  1.585661         1.620971  \n",
       " 1594 -0.027268        -0.135459  \n",
       " 1609  1.635591         1.221642  \n",
       " 1624  1.681347         1.417105  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1639       -0.495261  X5363_22     -0.430822   \n",
       " 1654       -0.657530  X5363_23     -0.465446   \n",
       " 1669       -0.495261  X5363_24     -0.439478   \n",
       " 1684        0.586533   X5363_3     -0.223075   \n",
       " 1699        0.268756   X5363_4     -0.231731   \n",
       " 1714        0.397219   X5363_5      0.097202   \n",
       " 1729        0.092964   X5363_6      0.088546   \n",
       " 1744        0.478353   X5363_7      0.209731   \n",
       " 1759        0.559488   X5363_8      0.192419   \n",
       " 1774        0.275517   X5363_9      0.218388   \n",
       " 1052       -0.387082  X5356_12     -0.223075   \n",
       " 1070       -0.461455  X5356_13     -0.214419   \n",
       " 1088       -0.265380  X5356_14     -0.179794   \n",
       " 1106       -0.583157  X5356_15     -0.231731   \n",
       " 1124       -0.623724  X5356_16     -0.275012   \n",
       " 1142       -0.630485  X5356_17     -0.223075   \n",
       " 1160       -0.488500  X5356_18     -0.171138   \n",
       " 1178        1.350549  X5356_19      0.564633   \n",
       " 1196       -0.360037   X5356_2     -0.292324   \n",
       " 1214        1.397878  X5356_20      0.616569   \n",
       " 1232        0.728518  X5356_21      0.183763   \n",
       " 1250        0.877265  X5356_22      0.123170   \n",
       " 1268       -0.130156  X5356_23      0.876253   \n",
       " 1286        0.180860  X5356_24      0.954158   \n",
       " 1304        0.796130   X5356_3      0.105858   \n",
       " 1322        0.559488   X5356_4      0.114514   \n",
       " 1340       -0.961784   X5356_5     -0.404853   \n",
       " 1358       -1.360696   X5356_6     -0.361573   \n",
       " 1376       -0.657530   X5356_7     -0.266355   \n",
       " 1394       -0.779232   X5356_8     -0.283668   \n",
       " 1412       -0.414126   X5356_9     -0.300980   \n",
       " 1430        0.708234   X5363_1     -0.110545   \n",
       " 1445        0.748802  X5363_10      0.105858   \n",
       " 1460        0.769085  X5363_11      0.053921   \n",
       " 1475        0.755563  X5363_12      0.071233   \n",
       " 1490       -0.481739  X5363_13     -0.110545   \n",
       " 1505       -0.447933  X5363_14     -0.205763   \n",
       " 1520       -0.393843  X5363_15     -0.041296   \n",
       " 1535       -0.542589  X5363_16     -0.344261   \n",
       " 1550       -0.454694  X5363_17     -0.300980   \n",
       " 1565       -0.272141  X5363_18     -0.465446   \n",
       " 1580       -0.975307  X5363_19     -0.231731   \n",
       " 1595        1.059817   X5363_2     -0.162482   \n",
       " 1610       -0.785993  X5363_20     -0.179794   \n",
       " 1625       -0.975307  X5363_21     -0.214419   \n",
       " 1640       -0.387082  X5363_22     -0.257699   \n",
       " 1655       -0.529067  X5363_23     -0.352917   \n",
       " 1670       -0.400604  X5363_24     -0.266355   \n",
       " 1685        1.391117   X5363_3      0.088546   \n",
       " 1700        1.019250   X5363_4      0.105858   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1639                           1.064820     -0.246600 -0.011656     -0.173894   \n",
       " 1654                           1.092117     -0.294665 -0.062405     -0.158118   \n",
       " 1669                           0.843576     -0.294665 -0.052934     -0.084497   \n",
       " 1684                          -0.016972      0.676253 -0.802303     -0.910107   \n",
       " 1699                           0.165055      0.570509 -0.788045     -1.031056   \n",
       " 1714                           0.102927      0.647413 -0.934290     -1.057350   \n",
       " 1729                           0.119851      0.560896 -0.911207     -1.183558   \n",
       " 1744                           0.418629      0.926192 -0.836914     -1.346576   \n",
       " 1759                           0.242252      1.108839 -0.915142     -1.241403   \n",
       " 1774                           0.360886      1.003096 -0.889641     -1.383387   \n",
       " 1052                           0.385063     -0.054339 -0.284526     -0.699761   \n",
       " 1070                           0.051762     -0.313891 -0.120035     -0.578811   \n",
       " 1088                           0.044228     -0.294665 -0.121944     -0.573553   \n",
       " 1106                           0.395408     -0.371569 -0.120025     -0.752347   \n",
       " 1124                           0.507436     -0.342730 -0.107015     -0.736571   \n",
       " 1142                           0.514042     -0.256213 -0.166358     -0.673467   \n",
       " 1160                           0.372806     -0.246600 -0.100812     -0.668209   \n",
       " 1178                           1.412233     -0.256213 -0.270406     -0.931142   \n",
       " 1196                           0.354926     -0.265826 -0.102579     -1.020539   \n",
       " 1214                           1.044101     -0.044726 -0.422706      0.578095   \n",
       " 1232                           2.086339     -0.919512  0.231813     -1.130971   \n",
       " 1250                           1.261579     -0.756091  0.089882      0.478181   \n",
       " 1268                           1.854750     -1.198291  0.150607      0.246799   \n",
       " 1286                           1.814240     -1.217517  0.220311     -0.326395   \n",
       " 1304                          -0.331437      0.118696 -0.411932     -0.573553   \n",
       " 1322                          -0.011322      0.012953 -0.437247     -0.557777   \n",
       " 1340                           0.375645     -0.410021  0.235695     -0.683985   \n",
       " 1358                           0.715524     -0.573443  0.177492     -0.957435   \n",
       " 1376                           0.393525     -0.217760 -0.085791     -0.831227   \n",
       " 1394                           0.443424     -0.208147 -0.180359     -0.820710   \n",
       " 1412                           0.204272     -0.275439 -0.076648     -0.662950   \n",
       " 1430                           0.521577      0.493605 -0.864807      0.378266   \n",
       " 1445                           0.392569      0.743544 -0.708446      0.467663   \n",
       " 1460                           0.586544      0.685866 -0.629256      0.436111   \n",
       " 1475                           0.483906      0.705092 -0.677288      0.504474   \n",
       " 1490                           0.518737     -0.198534 -0.909492     -0.010875   \n",
       " 1505                           0.320095      0.012953 -0.883686     -0.131825   \n",
       " 1520                           0.595006     -0.083178 -1.051268     -0.068721   \n",
       " 1535                           0.788953     -0.756091 -0.150229     -0.100273   \n",
       " 1550                           0.266429     -0.765704 -0.141776     -0.026651   \n",
       " 1565                           0.415171     -0.688799 -0.184670     -0.000358   \n",
       " 1580                           0.885941     -1.006030 -0.063552     -0.168635   \n",
       " 1595                           0.502741      0.416700 -0.772361      0.362490   \n",
       " 1610                           0.803066     -1.054095 -0.042612     -0.105531   \n",
       " 1625                           1.151434     -0.775317 -0.149549     -0.121307   \n",
       " 1640                           1.092117     -0.275439 -0.218573     -0.021393   \n",
       " 1655                           1.092117     -0.602282 -0.127983      0.057487   \n",
       " 1670                           1.380213     -0.515765 -0.131568     -0.121307   \n",
       " 1685                           0.212762      0.551283 -0.780315      0.399301   \n",
       " 1700                           0.229714      0.493605 -0.788999      0.383525   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1639       -0.052818            7     -0.659986    1.668271  2019-08-22   \n",
       " 1654       -0.041438            7     -0.512144    1.712314  2019-08-22   \n",
       " 1669       -0.018678            7     -0.514415    1.608383  2019-08-22   \n",
       " 1684       -0.411283            7      0.024744   -0.364467  2019-08-22   \n",
       " 1699       -0.434043            7      0.310168   -0.319281  2019-08-22   \n",
       " 1714       -0.360074            7      0.150378   -0.341721  2019-08-22   \n",
       " 1729       -0.422663            7      0.411424   -0.277598  2019-08-22   \n",
       " 1744       -0.018678            7      0.497062   -0.240079  2019-08-22   \n",
       " 1759        0.140640            7      0.268874   -0.310108  2019-08-22   \n",
       " 1774       -0.007298            7      0.516811   -0.262029  2019-08-22   \n",
       " 1052        0.402376            8      0.494452   -0.207952  2019-08-23   \n",
       " 1070        0.493415            8      0.293144   -0.149890  2019-08-23   \n",
       " 1088        0.738082            8      0.281780   -0.158585  2019-08-23   \n",
       " 1106        0.248748            8      0.658402   -0.094205  2019-08-23   \n",
       " 1124        0.191849            8      0.607057   -0.074628  2019-08-23   \n",
       " 1142        0.243058            8      0.552863   -0.116483  2019-08-23   \n",
       " 1160        0.430826            8      0.504640   -0.127054  2019-08-23   \n",
       " 1178        3.622876            8      0.662670    0.120615  2019-08-23   \n",
       " 1196        0.260128            8      0.526942   -0.093345  2019-08-23   \n",
       " 1214        3.822023            8      0.527237    0.044287  2019-08-23   \n",
       " 1232        3.076643            8      0.608210    0.583325  2019-08-23   \n",
       " 1250        3.224581            8      0.362825    0.490311  2019-08-23   \n",
       " 1268        2.718177            8     -0.246599    1.915575  2019-08-23   \n",
       " 1286        3.292860            8     -0.268338    2.082997  2019-08-23   \n",
       " 1304        1.625711            8      0.394609   -0.467272  2019-08-23   \n",
       " 1322        1.449323            8      0.420530   -0.401152  2019-08-23   \n",
       " 1340       -0.246275            8      0.324654    0.029555  2019-08-23   \n",
       " 1358       -0.536462            8      0.677250    0.120889  2019-08-23   \n",
       " 1376        0.038221            8      0.631046   -0.113034  2019-08-23   \n",
       " 1394       -0.069888            8      0.653059   -0.098885  2019-08-23   \n",
       " 1412        0.379617            8      0.502188   -0.104324  2019-08-23   \n",
       " 1430       -0.445423            8      0.375054   -0.060907  2019-08-23   \n",
       " 1445        0.049601            8      0.424511    0.041905  2019-08-23   \n",
       " 1460        0.106500            8      0.348116    0.037335  2019-08-23   \n",
       " 1475        0.112190            8      0.322325    0.032045  2019-08-23   \n",
       " 1490        0.191849            8     -1.359338    1.914214  2019-08-23   \n",
       " 1505        0.078050            8     -1.379253    2.025207  2019-08-23   \n",
       " 1520        0.049601            8     -1.384070    1.924317  2019-08-23   \n",
       " 1535        0.055291            8     -1.028813    1.755673  2019-08-23   \n",
       " 1550        0.066671            8     -1.390675    1.735339  2019-08-23   \n",
       " 1565        0.089430            8     -1.178955    1.787534  2019-08-23   \n",
       " 1580        0.021151            8     -0.644628    1.585661  2019-08-23   \n",
       " 1595       -0.303175            8      0.237530   -0.027268  2019-08-23   \n",
       " 1610        0.049601            8     -1.106664    1.635591  2019-08-23   \n",
       " 1625        0.009771            8     -0.815248    1.681347  2019-08-23   \n",
       " 1640        0.026841            8     -0.752438    1.806565  2019-08-23   \n",
       " 1655        0.021151            8     -0.512144    1.772977  2019-08-23   \n",
       " 1670        0.066671            8     -0.778864    1.766014  2019-08-23   \n",
       " 1685       -0.092647            8     -0.156584   -0.159084  2019-08-23   \n",
       " 1700       -0.115407            8      0.145482   -0.121325  2019-08-23   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1639  1.806565         1.663869  \n",
       " 1654  1.772977         1.646180  \n",
       " 1669  1.766014         1.498251  \n",
       " 1684 -0.159084         0.302842  \n",
       " 1699 -0.121325        -0.006396  \n",
       " 1714 -0.127210         0.014004  \n",
       " 1729 -0.065091        -0.144130  \n",
       " 1744  0.041046        -0.104005  \n",
       " 1759 -0.049634        -0.129640  \n",
       " 1774  0.018829        -0.118527  \n",
       " 1052  0.041384         0.223531  \n",
       " 1070  0.070784         0.375299  \n",
       " 1088  0.057904         0.250322  \n",
       " 1106  0.163818        -0.004875  \n",
       " 1124  0.166596         0.037757  \n",
       " 1142  0.115158         0.126091  \n",
       " 1160  0.111550         0.260615  \n",
       " 1178  0.377919         0.146823  \n",
       " 1196  0.125214         0.192259  \n",
       " 1214  0.274952         0.122225  \n",
       " 1232  0.847375         1.130102  \n",
       " 1250  0.729169         1.252086  \n",
       " 1268  2.103969         1.722292  \n",
       " 1286  2.318085         1.798341  \n",
       " 1304 -0.268117        -0.156016  \n",
       " 1322 -0.157156         0.049632  \n",
       " 1340  0.223658         0.573095  \n",
       " 1358  0.342823        -0.012564  \n",
       " 1376  0.172562         0.051324  \n",
       " 1394  0.140213         0.131284  \n",
       " 1412  0.111384         0.263762  \n",
       " 1430  0.123075         0.032812  \n",
       " 1445  0.194821        -0.046502  \n",
       " 1460  0.185740        -0.004357  \n",
       " 1475  0.178910         0.020622  \n",
       " 1490  2.062665         1.517649  \n",
       " 1505  2.004612         1.489595  \n",
       " 1520  1.959059         1.511432  \n",
       " 1535  1.817593         1.472177  \n",
       " 1550  1.766158         1.360590  \n",
       " 1565  1.878449         1.196393  \n",
       " 1580  1.593834         1.357075  \n",
       " 1595  0.147995         0.039919  \n",
       " 1610  1.651130         1.361967  \n",
       " 1625  1.644163         1.621769  \n",
       " 1640  1.901393         1.650033  \n",
       " 1655  1.808027         1.621713  \n",
       " 1670  1.827536         1.550552  \n",
       " 1685 -0.035377         0.132890  \n",
       " 1700  0.025488        -0.010463  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1715        1.235609   X5363_5      0.651194   \n",
       " 1730        0.890787   X5363_6      0.668506   \n",
       " 1745        0.911071   X5363_7      0.053921   \n",
       " 1760        1.032772   X5363_8      0.131826   \n",
       " 1775        0.674428   X5363_9      0.123170   \n",
       " 1053       -0.921217  X5356_12     -0.370229   \n",
       " 1071       -1.002352  X5356_13     -0.335604   \n",
       " 1089       -0.711620  X5356_14     -0.326948   \n",
       " 1107       -1.090247  X5356_15     -0.378885   \n",
       " 1125       -1.117292  X5356_16     -0.404853   \n",
       " 1143       -1.151098  X5356_17     -0.361573   \n",
       " 1161       -0.975307  X5356_18     -0.335604   \n",
       " 1179        1.512818  X5356_19      0.530008   \n",
       " 1197       -0.887411   X5356_2     -0.448134   \n",
       " 1215        1.593953  X5356_20      0.581945   \n",
       " 1233        0.998966  X5356_21      0.313605   \n",
       " 1251        1.167997  X5356_22      0.244356   \n",
       " 1269        0.038875  X5356_23      1.473526   \n",
       " 1287        0.336368  X5356_24      1.889019   \n",
       " 1305        0.302562   X5356_3     -0.205763   \n",
       " 1323        0.025352   X5356_4     -0.197106   \n",
       " 1341       -1.353935   X5356_5     -0.482758   \n",
       " 1359       -1.590577   X5356_6     -0.413509   \n",
       " 1377       -1.252516   X5356_7     -0.413509   \n",
       " 1395       -1.374218   X5356_8     -0.387541   \n",
       " 1413       -0.975307   X5356_9     -0.387541   \n",
       " 1431        1.039534   X5363_1     -0.153826   \n",
       " 1446        0.748802  X5363_10      0.235700   \n",
       " 1461        0.769085  X5363_11      0.201075   \n",
       " 1476        1.587192  X5363_12      0.105858   \n",
       " 1491       -0.481739  X5363_13      0.400166   \n",
       " 1506       -0.447933  X5363_14      0.382854   \n",
       " 1521       -0.393843  X5363_15      0.573289   \n",
       " 1536       -0.542589  X5363_16      0.313605   \n",
       " 1551       -0.454694  X5363_17      0.339573   \n",
       " 1566       -0.272141  X5363_18      0.287637   \n",
       " 1581       -0.975307  X5363_19      0.547320   \n",
       " 1596        0.890787   X5363_2     -0.032640   \n",
       " 1611       -0.785993  X5363_20      0.599257   \n",
       " 1626       -0.975307  X5363_21      0.504040   \n",
       " 1641       -0.387082  X5363_22      0.400166   \n",
       " 1656       -0.529067  X5363_23      0.443447   \n",
       " 1671       -0.400604  X5363_24      0.452103   \n",
       " 1686        1.188280   X5363_3      0.218388   \n",
       " 1701        1.019250   X5363_4      0.209731   \n",
       " 1716        1.235609   X5363_5      0.988783   \n",
       " 1731        0.890787   X5363_6      0.962814   \n",
       " 1746        0.911071   X5363_7      0.209731   \n",
       " 1761        1.032772   X5363_8      0.287637   \n",
       " 1776        0.674428   X5363_9      0.244356   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1715                           0.247593      0.522444 -0.958607      0.394042   \n",
       " 1730                           0.217457      0.445539 -0.986118      0.362490   \n",
       " 1745                           0.428356      0.685866 -0.681553      0.514991   \n",
       " 1760                           0.576171      0.887739 -0.716058      0.530767   \n",
       " 1775                           0.573360      0.781996 -0.700598      0.483439   \n",
       " 1053                           0.270196     -0.246600 -0.093422      0.767407   \n",
       " 1071                           0.022582     -0.515765  0.116427      0.793701   \n",
       " 1089                          -0.078173     -0.477313  0.078316      0.767407   \n",
       " 1107                           0.369995     -0.563830 -0.001257      0.777925   \n",
       " 1125                           0.263589     -0.544604  0.065110      0.762149   \n",
       " 1143                           0.385063     -0.467700  0.050181      0.735855   \n",
       " 1161                           0.139333     -0.467700 -0.029342      0.741114   \n",
       " 1179                           1.101535     -0.342730 -0.318725      0.541285   \n",
       " 1197                           0.305027     -0.448473 -0.018540      0.841029   \n",
       " 1215                           0.896286     -0.188921 -0.261293     -0.231739   \n",
       " 1233                           1.611831     -0.948352  0.138613      0.478181   \n",
       " 1251                           1.374562     -0.900286  0.199818     -0.426310   \n",
       " 1269                           1.238049     -1.275195  0.039200      0.167919   \n",
       " 1287                           1.455554     -1.284808 -0.084687     -0.799675   \n",
       " 1305                          -0.277771     -0.063952 -0.217722      0.867322   \n",
       " 1323                           0.053646     -0.160082 -0.276640      0.804218   \n",
       " 1341                           0.533805     -0.573443  0.139677      0.735855   \n",
       " 1359                           0.742821     -0.765704  0.459462      0.746373   \n",
       " 1377                           0.436846     -0.429247 -0.001255      0.756890   \n",
       " 1395                           0.503669     -0.429247 -0.034717      0.756890   \n",
       " 1413                           0.261706     -0.496539  0.006084      0.730597   \n",
       " 1431                           0.471677      0.330183 -0.606938     -0.494673   \n",
       " 1446                           0.599701      0.551283 -0.628673     -0.357947   \n",
       " 1461                           0.678809      0.455153 -0.610931     -0.352689   \n",
       " 1476                           0.379412      0.589735 -0.645288     -0.258033   \n",
       " 1491                           0.033883     -0.294665 -0.953150      0.483439   \n",
       " 1506                          -0.012277     -0.044726 -1.026297      0.409818   \n",
       " 1521                           0.174164     -0.131243 -1.180750      0.467663   \n",
       " 1536                           0.386946     -0.775317 -0.327291      0.283610   \n",
       " 1551                           0.127076     -0.765704 -0.446526      0.341455   \n",
       " 1566                           0.271123     -0.746478 -0.443676      0.194213   \n",
       " 1581                           0.287147     -1.044482 -0.223558      0.241541   \n",
       " 1596                           0.223107      0.243666 -0.573415     -0.484155   \n",
       " 1611                           0.585588     -1.102160 -0.263551      0.236282   \n",
       " 1626                           0.830391     -1.092547 -0.257714      0.120591   \n",
       " 1641                           0.287147     -0.621508 -0.330405      0.141626   \n",
       " 1656                           0.079060     -0.669573 -0.123171     -0.052945   \n",
       " 1671                           0.235364     -0.611895 -0.155004      0.252058   \n",
       " 1686                          -0.093241      0.435926 -0.683159     -0.331654   \n",
       " 1701                           0.215573      0.330183 -0.477974     -0.394758   \n",
       " 1716                           0.226874      0.359022 -0.886894     -0.357947   \n",
       " 1731                           0.031999      0.301344 -0.934109     -0.405275   \n",
       " 1746                           0.175091      0.493605 -0.624771     -0.294843   \n",
       " 1761                           0.317256      0.676253 -0.668473     -0.263291   \n",
       " 1776                           0.295609      0.560896 -0.694000     -0.336913   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1715        0.009771            8      0.066391   -0.127210  2019-08-23   \n",
       " 1730       -0.064198            8      0.150825   -0.065091  2019-08-23   \n",
       " 1745        0.106500            8      0.258455    0.041046  2019-08-23   \n",
       " 1760        0.231679            8      0.215538   -0.049634  2019-08-23   \n",
       " 1775        0.089430            8      0.324106    0.018829  2019-08-23   \n",
       " 1053       -0.764059            9      0.341144    0.041384  2019-08-24   \n",
       " 1071       -0.718540            9      0.204903    0.070784  2019-08-24   \n",
       " 1089       -0.701470            9      0.188896    0.057904  2019-08-24   \n",
       " 1107       -0.752679            9      0.441678    0.163818  2019-08-24   \n",
       " 1125       -0.758369            9      0.470030    0.166596  2019-08-24   \n",
       " 1143       -0.752679            9      0.339803    0.115158  2019-08-24   \n",
       " 1161       -0.735609            9      0.404891    0.111550  2019-08-24   \n",
       " 1179       -0.246275            9      0.458262    0.377919  2019-08-24   \n",
       " 1197       -0.786819            9      0.367152    0.125214  2019-08-24   \n",
       " 1215       -0.143857            9      0.291889    0.274952  2019-08-24   \n",
       " 1233       -0.172306            9      0.386476    0.847375  2019-08-24   \n",
       " 1251       -0.109717            9      0.073890    0.729169  2019-08-24   \n",
       " 1269       -0.018678            9     -0.552198    2.103969  2019-08-24   \n",
       " 1287       -0.012988            9     -0.592460    2.318085  2019-08-24   \n",
       " 1305       -0.729919            9      0.138683   -0.268117  2019-08-24   \n",
       " 1323       -0.724229            9      0.299561   -0.157156  2019-08-24   \n",
       " 1341       -0.781129            9      0.086573    0.223658  2019-08-24   \n",
       " 1359       -0.809578            9      0.457073    0.342823  2019-08-24   \n",
       " 1377       -0.786819            9      0.544694    0.172562  2019-08-24   \n",
       " 1395       -0.786819            9      0.447166    0.140213  2019-08-24   \n",
       " 1413       -0.741299            9      0.283965    0.111384  2019-08-24   \n",
       " 1431       -0.098337            9      0.161713    0.123075  2019-08-24   \n",
       " 1446        0.049601            9      0.188081    0.194821  2019-08-24   \n",
       " 1461        0.106500            9      0.218509    0.185740  2019-08-24   \n",
       " 1476        0.521865            9      0.187879    0.178910  2019-08-24   \n",
       " 1491        0.191849            9     -1.954190    2.062665  2019-08-24   \n",
       " 1506        0.078050            9     -1.886470    2.004612  2019-08-24   \n",
       " 1521        0.049601            9     -1.755428    1.959059  2019-08-24   \n",
       " 1536        0.055291            9     -1.545461    1.817593  2019-08-24   \n",
       " 1551        0.066671            9     -1.612092    1.766158  2019-08-24   \n",
       " 1566        0.089430            9     -1.565729    1.878449  2019-08-24   \n",
       " 1581        0.021151            9     -1.108265    1.593834  2019-08-24   \n",
       " 1596        0.112190            9      0.188470    0.147995  2019-08-24   \n",
       " 1611        0.049601            9     -1.499011    1.651130  2019-08-24   \n",
       " 1626        0.009771            9     -1.055765    1.644163  2019-08-24   \n",
       " 1641        0.026841            9     -1.283362    1.901393  2019-08-24   \n",
       " 1656        0.021151            9     -1.188242    1.808027  2019-08-24   \n",
       " 1671        0.066671            9     -1.264529    1.827536  2019-08-24   \n",
       " 1686        0.538935            9     -0.358901   -0.035377  2019-08-24   \n",
       " 1701       -0.115407            9     -0.141435    0.025488  2019-08-24   \n",
       " 1716        0.009771            9     -0.230613    0.007525  2019-08-24   \n",
       " 1731       -0.064198            9      0.019487    0.079791  2019-08-24   \n",
       " 1746        0.106500            9      0.141884    0.176796  2019-08-24   \n",
       " 1761        0.231679            9     -0.008179    0.082557  2019-08-24   \n",
       " 1776        0.089430            9      0.170192    0.164399  2019-08-24   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1715  0.007525         0.107635  \n",
       " 1730  0.079791         0.111963  \n",
       " 1745  0.176796         0.152706  \n",
       " 1760  0.082557         0.103606  \n",
       " 1775  0.164399         0.267485  \n",
       " 1053  0.319204         0.316611  \n",
       " 1071  0.263748         0.344733  \n",
       " 1089  0.242274         0.333107  \n",
       " 1107  0.402998         0.232092  \n",
       " 1125  0.395579         0.198309  \n",
       " 1143  0.331987         0.394242  \n",
       " 1161  0.325202         0.200346  \n",
       " 1179  0.656347         0.388324  \n",
       " 1197  0.358132         0.330493  \n",
       " 1215  0.541345         0.372426  \n",
       " 1233  1.044436         0.942628  \n",
       " 1251  0.954824         0.861001  \n",
       " 1269  2.290473         1.690932  \n",
       " 1287  2.375658         1.525962  \n",
       " 1305 -0.017222         0.307863  \n",
       " 1323  0.088476         0.270880  \n",
       " 1341  0.414745         0.528356  \n",
       " 1359  0.554943         0.344106  \n",
       " 1377  0.413047         0.025412  \n",
       " 1395  0.396417         0.252678  \n",
       " 1413  0.317412         0.332903  \n",
       " 1431  0.463056         0.230555  \n",
       " 1446  0.462957         0.219395  \n",
       " 1461  0.445898         0.216570  \n",
       " 1476  0.436442         0.150205  \n",
       " 1491  2.199653         1.611232  \n",
       " 1506  2.200036         1.720136  \n",
       " 1521  2.185010         1.741862  \n",
       " 1536  1.944844         1.804171  \n",
       " 1551  1.985031         1.525723  \n",
       " 1566  2.059226         1.744775  \n",
       " 1581  1.676520         1.532431  \n",
       " 1596  0.457727         0.281399  \n",
       " 1611  1.798624         1.806635  \n",
       " 1626  1.767805         1.624260  \n",
       " 1641  1.935429         1.702646  \n",
       " 1656  1.882733         1.388423  \n",
       " 1671  1.910416         1.621084  \n",
       " 1686  0.213637         0.550235  \n",
       " 1701  0.318604         0.591498  \n",
       " 1716  0.258796         0.547695  \n",
       " 1731  0.353786         0.129605  \n",
       " 1746  0.422625         0.196516  \n",
       " 1761  0.323712         0.274725  \n",
       " 1776  0.450143         0.231334  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1054       -1.225472  X5356_12     -0.534695   \n",
       " 1072       -1.279561  X5356_13     -0.456790   \n",
       " 1090       -0.907695  X5356_14     -0.500071   \n",
       " 1108       -1.320129  X5356_15     -0.603944   \n",
       " 1126       -1.353935  X5356_16     -0.586632   \n",
       " 1144       -1.374218  X5356_17     -0.517383   \n",
       " 1162       -1.211949  X5356_18     -0.500071   \n",
       " 1180        1.796789  X5356_19      0.599257   \n",
       " 1198       -1.205188   X5356_2     -0.552007   \n",
       " 1216        1.891446  X5356_20      0.651194   \n",
       " 1234        1.289698  X5356_21      0.504040   \n",
       " 1252        1.479012  X5356_22      0.504040   \n",
       " 1270        0.322845  X5356_23      2.027517   \n",
       " 1288        0.579771  X5356_24      2.287201   \n",
       " 1306       -0.163962   X5356_3     -0.430822   \n",
       " 1324       -0.468216   X5356_4     -0.396197   \n",
       " 1342       -1.435069   X5356_5     -0.647225   \n",
       " 1360       -1.556771   X5356_6     -0.577976   \n",
       " 1378       -1.509442   X5356_7     -0.534695   \n",
       " 1396       -1.550010   X5356_8     -0.500071   \n",
       " 1414       -1.218710   X5356_9     -0.491415   \n",
       " 1432        1.066578   X5363_1      0.010641   \n",
       " 1447        0.748802  X5363_10      0.486727   \n",
       " 1462        0.769085  X5363_11      0.443447   \n",
       " 1477        1.587192  X5363_12      0.478071   \n",
       " 1492       -0.481739  X5363_13      1.127281   \n",
       " 1507       -0.447933  X5363_14      1.014751   \n",
       " 1522       -0.393843  X5363_15      1.179217   \n",
       " 1537       -0.542589  X5363_16      1.014751   \n",
       " 1552       -0.454694  X5363_17      1.023407   \n",
       " 1567       -0.272141  X5363_18      0.936846   \n",
       " 1582       -0.975307  X5363_19      1.490838   \n",
       " 1597        0.836697   X5363_2      0.201075   \n",
       " 1612       -0.785993  X5363_20      1.490838   \n",
       " 1627       -0.975307  X5363_21      1.482182   \n",
       " 1642       -0.387082  X5363_22      1.032063   \n",
       " 1657       -0.529067  X5363_23      1.179217   \n",
       " 1672       -0.400604  X5363_24      1.058032   \n",
       " 1687        1.140952   X5363_3      0.564633   \n",
       " 1702        1.019250   X5363_4      0.443447   \n",
       " 1717        1.235609   X5363_5      1.006095   \n",
       " 1732        0.890787   X5363_6      1.127281   \n",
       " 1747        0.911071   X5363_7      0.486727   \n",
       " 1762        1.032772   X5363_8      0.651194   \n",
       " 1777        0.674428   X5363_9      0.504040   \n",
       " 1055       -1.475636  X5356_12     -0.759754   \n",
       " 1073       -1.475636  X5356_13     -0.638569   \n",
       " 1091       -1.198427  X5356_14     -0.681849   \n",
       " 1109       -1.550010  X5356_15     -0.725130   \n",
       " 1127       -1.550010  X5356_16     -0.751098   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1054                           0.305955     -0.304278  0.479743      0.399301   \n",
       " 1072                           0.019742     -0.573443  0.274687      0.451887   \n",
       " 1090                           0.001863     -0.486926  0.269990      0.436111   \n",
       " 1108                           0.280541     -0.611895  0.299321      0.394042   \n",
       " 1126                           0.214646     -0.592669  0.199793      0.357231   \n",
       " 1144                           0.308794     -0.515765  0.276168      0.341455   \n",
       " 1162                           0.280541     -0.515765  0.272585      0.362490   \n",
       " 1180                           0.808716     -0.410021 -0.002157     -0.221222   \n",
       " 1198                           0.273007     -0.554217  0.155411      0.273093   \n",
       " 1216                           0.532878     -0.294665 -0.132413     -0.946918   \n",
       " 1234                           1.363261     -1.025256  0.164470     -0.415793   \n",
       " 1252                           1.047868     -1.063708  0.287137     -1.204592   \n",
       " 1270                           0.971599     -1.275195  0.123233      0.304645   \n",
       " 1288                           1.272880     -1.284808 -0.254532      0.493957   \n",
       " 1306                          -0.210920     -0.227373  0.090310      0.415077   \n",
       " 1324                          -0.039575     -0.323504  0.000526      0.315162   \n",
       " 1342                           0.492396     -0.621508  0.303279      0.330938   \n",
       " 1360                           0.514042     -0.861834  0.258449      0.252058   \n",
       " 1378                           0.185465     -0.534991  0.189367      0.309903   \n",
       " 1396                           0.414243     -0.534991  0.240134      0.315162   \n",
       " 1414                           0.053646     -0.563830  0.290574      0.336197   \n",
       " 1432                           0.401986      0.157148 -0.415126     -1.530630   \n",
       " 1447                           0.325746      0.493605 -0.625535     -1.362352   \n",
       " 1462                           0.506508      0.359022 -0.419071     -1.362352   \n",
       " 1477                           0.414243      0.426313 -0.377665     -1.299248   \n",
       " 1492                          -0.003788     -0.486926 -0.884759      0.083781   \n",
       " 1507                           0.044228     -0.275439 -0.801411     -0.021393   \n",
       " 1522                          -0.204341     -0.352343 -0.984759      0.004901   \n",
       " 1537                           0.157212     -1.025256 -0.413546     -0.242257   \n",
       " 1552                           0.056457     -1.034869 -0.356313     -0.179153   \n",
       " 1567                           0.334208     -1.044482 -0.294791     -0.426310   \n",
       " 1582                           0.420822     -1.246356 -0.245159     -0.662950   \n",
       " 1597                           0.167557      0.070631 -0.292518     -1.493819   \n",
       " 1612                           0.465071     -1.265582 -0.385123     -0.662950   \n",
       " 1627                           0.777652     -1.265582 -0.383610     -0.862779   \n",
       " 1642                           0.519693     -1.150226 -0.182757     -0.710278   \n",
       " 1657                           0.428356     -1.179065 -0.113365     -0.789158   \n",
       " 1672                           1.047868     -1.140612 -0.187496     -0.589329   \n",
       " 1687                          -0.207152      0.310957 -0.632182     -1.167782   \n",
       " 1702                           0.006558      0.205213 -0.577278     -1.293990   \n",
       " 1717                          -0.103586      0.253279 -0.835746     -1.194075   \n",
       " 1732                          -0.209992      0.166761 -0.847037     -1.304507   \n",
       " 1747                           0.154373      0.464766 -0.667849     -1.215110   \n",
       " 1762                           0.150606      0.637800 -0.734447     -1.167782   \n",
       " 1777                           0.259822      0.512831 -0.565178     -1.325542   \n",
       " 1055                           0.393525     -0.515765  0.354299     -0.300102   \n",
       " 1073                           0.075293     -0.784930  0.377535     -0.342171   \n",
       " 1091                           0.039505     -0.640734  0.481135     -0.305361   \n",
       " 1109                           0.224991     -0.823382  0.331113     -0.436827   \n",
       " 1127                           0.242870     -0.794543  0.337385     -0.447345   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1054       -0.792509           10      0.037968    0.319204  2019-08-25   \n",
       " 1072       -0.746989           10     -0.232711    0.263748  2019-08-25   \n",
       " 1090       -0.729919           10     -0.203062    0.242274  2019-08-25   \n",
       " 1108       -0.803888           10      0.226772    0.402998  2019-08-25   \n",
       " 1126       -0.792509           10      0.218711    0.395579  2019-08-25   \n",
       " 1144       -0.781129           10      0.055489    0.331987  2019-08-25   \n",
       " 1162       -0.764059           10      0.048747    0.325202  2019-08-25   \n",
       " 1180       -0.069888           10      0.128033    0.656347  2019-08-25   \n",
       " 1198       -0.803888           10     -0.098288    0.358132  2019-08-25   \n",
       " 1216        0.021151           10      0.012089    0.541345  2019-08-25   \n",
       " 1234        0.049601           10      0.126692    1.044436  2019-08-25   \n",
       " 1252        0.089430           10     -0.197625    0.954824  2019-08-25   \n",
       " 1270       -0.001609           10     -0.785981    2.290473  2019-08-25   \n",
       " 1288        0.009771           10     -0.635687    2.375658  2019-08-25   \n",
       " 1306       -0.752679           10     -0.057181   -0.017222  2019-08-25   \n",
       " 1324       -0.746989           10      0.033959    0.088476  2019-08-25   \n",
       " 1342       -0.849408           10     -0.263175    0.414745  2019-08-25   \n",
       " 1360       -0.832338           10      0.204917    0.554943  2019-08-25   \n",
       " 1378       -0.820958           10      0.306144    0.413047  2019-08-25   \n",
       " 1396       -0.815268           10      0.192717    0.396417  2019-08-25   \n",
       " 1414       -0.769749           10     -0.142199    0.317412  2019-08-25   \n",
       " 1432        0.100810           10     -0.036256    0.463056  2019-08-25   \n",
       " 1447        0.049601           10     -0.233065    0.462957  2019-08-25   \n",
       " 1462        0.106500           10      0.031738    0.445898  2019-08-25   \n",
       " 1477        0.521865           10     -0.126560    0.436442  2019-08-25   \n",
       " 1492        0.191849           10     -2.533734    2.199653  2019-08-25   \n",
       " 1507        0.078050           10     -2.171209    2.200036  2019-08-25   \n",
       " 1522        0.049601           10     -2.294125    2.185010  2019-08-25   \n",
       " 1537        0.055291           10     -1.842897    1.944844  2019-08-25   \n",
       " 1552        0.066671           10     -2.116323    1.985031  2019-08-25   \n",
       " 1567        0.089430           10     -1.886542    2.059226  2019-08-25   \n",
       " 1582        0.021151           10     -1.266490    1.676520  2019-08-25   \n",
       " 1597        0.339787           10     -0.286494    0.457727  2019-08-25   \n",
       " 1612        0.049601           10     -1.677692    1.798624  2019-08-25   \n",
       " 1627        0.009771           10     -1.411917    1.767805  2019-08-25   \n",
       " 1642        0.026841           10     -1.476760    1.935429  2019-08-25   \n",
       " 1657        0.021151           10     -1.504916    1.882733  2019-08-25   \n",
       " 1672        0.066671           10     -1.714249    1.910416  2019-08-25   \n",
       " 1687        0.823431           10     -0.876810    0.213637  2019-08-25   \n",
       " 1702       -0.115407           10     -0.316013    0.318604  2019-08-25   \n",
       " 1717        0.009771           10     -0.632680    0.258796  2019-08-25   \n",
       " 1732       -0.064198           10     -0.410448    0.353786  2019-08-25   \n",
       " 1747        0.106500           10     -0.264322    0.422625  2019-08-25   \n",
       " 1762        0.231679           10     -0.548015    0.323712  2019-08-25   \n",
       " 1777        0.089430           10     -0.065415    0.450143  2019-08-25   \n",
       " 1055       -0.729919           11     -0.280473    0.539257  2019-08-26   \n",
       " 1073       -0.695780           11     -0.425128    0.434484  2019-08-26   \n",
       " 1091       -0.684400           11     -0.567181    0.419421  2019-08-26   \n",
       " 1109       -0.718540           11     -0.143735    0.599913  2019-08-26   \n",
       " 1127       -0.786819           11     -0.082389    0.583072  2019-08-26   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1054  0.539257         0.555196  \n",
       " 1072  0.434484         0.649855  \n",
       " 1090  0.419421         0.586639  \n",
       " 1108  0.599913         0.561593  \n",
       " 1126  0.583072         0.417909  \n",
       " 1144  0.533040         0.552282  \n",
       " 1162  0.501754         0.422083  \n",
       " 1180  0.884504         0.729491  \n",
       " 1198  0.525071         0.479230  \n",
       " 1216  0.693922         0.361866  \n",
       " 1234  1.278104         0.969330  \n",
       " 1252  1.102406         1.036648  \n",
       " 1270  2.357797         2.322487  \n",
       " 1288  2.518299         2.423438  \n",
       " 1306  0.221648         0.502043  \n",
       " 1324  0.332967         0.404429  \n",
       " 1342  0.552616         0.629789  \n",
       " 1360  0.655402         0.505216  \n",
       " 1378  0.612332         0.299905  \n",
       " 1396  0.604817         0.502840  \n",
       " 1414  0.486959         0.546554  \n",
       " 1432  0.554633         0.361516  \n",
       " 1447  0.504962         0.378368  \n",
       " 1462  0.504486         0.271224  \n",
       " 1477  0.467520         0.285372  \n",
       " 1492  2.199653         1.609105  \n",
       " 1507  2.200036         1.593654  \n",
       " 1522  2.185010         1.495246  \n",
       " 1537  1.944844         1.806124  \n",
       " 1552  1.985031         1.718735  \n",
       " 1567  2.059226         1.577640  \n",
       " 1582  1.751378         1.322769  \n",
       " 1597  0.581066         0.382348  \n",
       " 1612  1.910997         1.681786  \n",
       " 1627  1.828564         1.552495  \n",
       " 1642  2.034977         1.342976  \n",
       " 1657  1.956675         1.355721  \n",
       " 1672  2.001237         2.006611  \n",
       " 1687  0.319272         0.262344  \n",
       " 1702  0.422802         0.136382  \n",
       " 1717  0.345985         0.101325  \n",
       " 1732  0.444601         0.066973  \n",
       " 1747  0.444906         0.235210  \n",
       " 1762  0.349799         0.231376  \n",
       " 1777  0.466154         0.379875  \n",
       " 1055  0.739074         0.810024  \n",
       " 1073  0.535133         0.803647  \n",
       " 1091  0.488185         0.770079  \n",
       " 1109  0.705889         0.714465  \n",
       " 1127  0.690713         0.735041  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1145       -1.543249  X5356_17     -0.681849   \n",
       " 1163       -1.455353  X5356_18     -0.690505   \n",
       " 1181        1.012489  X5356_19      0.538664   \n",
       " 1199       -1.347173   X5356_2     -0.759754   \n",
       " 1217        0.971922  X5356_20      0.607913   \n",
       " 1235        0.660906  X5356_21      0.832972   \n",
       " 1253        0.687951  X5356_22      0.677162   \n",
       " 1271        0.005069  X5356_23      2.512260   \n",
       " 1289        0.126770  X5356_24      2.702695   \n",
       " 1307       -0.549351   X5356_3     -0.699162   \n",
       " 1325       -0.833321   X5356_4     -0.681849   \n",
       " 1343       -1.543249   X5356_5     -0.716474   \n",
       " 1361       -1.577055   X5356_6     -0.638569   \n",
       " 1379       -1.563532   X5356_7     -0.742442   \n",
       " 1397       -1.577055   X5356_8     -0.716474   \n",
       " 1415       -1.367457   X5356_9     -0.751098   \n",
       " 1433        0.958399   X5363_1      0.443447   \n",
       " 1448        0.748802  X5363_10      1.283091   \n",
       " 1463        0.769085  X5363_11      1.144593   \n",
       " 1478        1.587192  X5363_12      1.248466   \n",
       " 1493       -0.481739  X5363_13      1.127281   \n",
       " 1508       -0.447933  X5363_14      1.014751   \n",
       " 1523       -0.393843  X5363_15      1.179217   \n",
       " 1538       -0.542589  X5363_16      1.014751   \n",
       " 1553       -0.454694  X5363_17      1.023407   \n",
       " 1568       -0.272141  X5363_18      0.936846   \n",
       " 1583       -0.975307  X5363_19      2.373762   \n",
       " 1598        0.755563   X5363_2      0.763723   \n",
       " 1613       -0.785993  X5363_20      2.399731   \n",
       " 1628       -0.975307  X5363_21      2.633446   \n",
       " 1643       -0.387082  X5363_22      1.837083   \n",
       " 1658       -0.529067  X5363_23      1.992893   \n",
       " 1673       -0.400604  X5363_24      1.741865   \n",
       " 1688        1.140952   X5363_3      1.187873   \n",
       " 1703        1.019250   X5363_4      1.058032   \n",
       " 1718        1.235609   X5363_5      1.412933   \n",
       " 1733        0.890787   X5363_6      1.594711   \n",
       " 1748        0.911071   X5363_7      1.343684   \n",
       " 1763        1.032772   X5363_8      1.464869   \n",
       " 1778        0.674428   X5363_9      1.326371   \n",
       " 1056       -1.556771  X5356_12     -0.829003   \n",
       " 1074       -1.482398  X5356_13     -0.716474   \n",
       " 1092       -1.245755  X5356_14     -0.742442   \n",
       " 1110       -1.536487  X5356_15     -0.707818   \n",
       " 1128       -1.522965  X5356_16     -0.716474   \n",
       " 1146       -1.543249  X5356_17     -0.725130   \n",
       " 1164       -1.489159  X5356_18     -0.725130   \n",
       " 1182        1.384355  X5356_19      0.729099   \n",
       " 1200       -1.394502   X5356_2     -0.794379   \n",
       " 1218        1.330266  X5356_20      0.772379   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1145                           0.295609     -0.669573  0.304669     -0.452603   \n",
       " 1163                           0.120497     -0.717639  0.374362     -0.442086   \n",
       " 1181                           0.738126     -0.727252  0.114866     -1.194075   \n",
       " 1199                           0.073409     -0.592669  0.320274     -0.236998   \n",
       " 1217                           0.389758     -0.515765 -0.193550      0.425594   \n",
       " 1235                           0.995158     -1.179065  0.161264     -1.504336   \n",
       " 1253                           0.908515     -1.063708  0.183676      0.383525   \n",
       " 1271                           0.688227     -1.255969 -0.119994     -0.079238   \n",
       " 1289                           1.085539     -1.217517 -0.375054     -0.205446   \n",
       " 1307                          -0.161976     -0.352343  0.284518     -0.016134   \n",
       " 1325                           0.012208     -0.429247  0.451851     -0.184411   \n",
       " 1343                           0.348320     -0.727252  0.432069     -0.347430   \n",
       " 1361                           0.494251     -0.832995  0.297478     -0.499931   \n",
       " 1379                           0.255127     -0.698413  0.366860     -0.421051   \n",
       " 1397                           0.240987     -0.717639  0.400059     -0.421051   \n",
       " 1415                           0.077176     -0.650347  0.270209     -0.342171   \n",
       " 1433                          -0.129956     -0.131243 -0.220136     -0.705019   \n",
       " 1448                          -0.004743      0.243666 -0.719007     -1.315024   \n",
       " 1463                          -0.122422      0.070631 -0.631871     -1.315024   \n",
       " 1478                          -0.257052      0.147535 -0.633251     -1.330800   \n",
       " 1493                          -0.003788     -0.486926 -0.884759      0.083781   \n",
       " 1508                           0.044228     -0.275439 -0.801411     -0.021393   \n",
       " 1523                          -0.204341     -0.352343 -0.984759      0.004901   \n",
       " 1538                           0.157212     -1.025256 -0.413546     -0.242257   \n",
       " 1553                           0.056457     -1.034869 -0.356313     -0.179153   \n",
       " 1568                           0.334208     -1.044482 -0.294791     -0.426310   \n",
       " 1583                           0.644906     -1.284808 -0.245159     -1.556923   \n",
       " 1598                          -0.154442     -0.160082 -0.255333     -0.973211   \n",
       " 1613                           0.299376     -1.304034 -0.385123     -1.525371   \n",
       " 1628                           0.377529     -1.313647 -0.383610     -1.730459   \n",
       " 1643                           0.344553     -1.265582 -0.422644     -1.551664   \n",
       " 1658                           0.255127     -1.284808 -0.371290     -1.656838   \n",
       " 1673                          -0.091358     -1.217517 -0.196443     -1.372870   \n",
       " 1688                          -0.366269      0.061018 -0.470577     -0.683985   \n",
       " 1703                          -0.376614     -0.035113 -0.577193     -0.715537   \n",
       " 1718                          -0.476413      0.012953 -0.883190     -0.852262   \n",
       " 1733                          -0.312602     -0.073565 -0.911485     -1.015280   \n",
       " 1748                          -0.129000      0.253279 -0.814353     -1.004763   \n",
       " 1763                          -0.322947      0.349409 -0.875379     -1.010022   \n",
       " 1778                          -0.157253      0.243666 -0.811022     -1.241403   \n",
       " 1056                           0.208995     -0.794543  0.629556     -0.825968   \n",
       " 1074                           2.773659     -0.900286  0.471253     -0.778641   \n",
       " 1092                          -0.140301     -0.746478  0.575099     -0.778641   \n",
       " 1110                           0.015975     -0.900286  0.675089     -0.957435   \n",
       " 1128                           0.099778     -0.861834  0.731414     -0.973211   \n",
       " 1146                           0.072481     -0.861834  0.530361     -0.962694   \n",
       " 1164                           0.091288     -0.842608  0.645651     -0.946918   \n",
       " 1182                           0.480139     -0.765704 -0.021915      0.546543   \n",
       " 1200                           0.150606     -0.746478  0.534198     -0.789158   \n",
       " 1218                           0.385063     -0.640734 -0.137964     -0.357947   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1145       -0.718540           11     -0.239446    0.533040  2019-08-26   \n",
       " 1163       -0.707160           11     -0.184841    0.501754  2019-08-26   \n",
       " 1181        0.021151           11     -0.016731    0.884504  2019-08-26   \n",
       " 1199       -0.741299           11     -0.335251    0.525071  2019-08-26   \n",
       " 1217        0.060981           11     -0.239583    0.693922  2019-08-26   \n",
       " 1235        0.112190           11     -0.139531    1.278104  2019-08-26   \n",
       " 1253        0.146330           11     -0.465262    1.102406  2019-08-26   \n",
       " 1271       -0.115407           11     -1.068629    2.357797  2019-08-26   \n",
       " 1289       -0.109717           11     -0.965585    2.518299  2019-08-26   \n",
       " 1307       -0.701470           11     -0.371548    0.221648  2019-08-26   \n",
       " 1325       -0.701470           11     -0.202233    0.332967  2019-08-26   \n",
       " 1343       -0.741299           11     -0.536443    0.552616  2019-08-26   \n",
       " 1361       -0.746989           11     -0.011128    0.655402  2019-08-26   \n",
       " 1379       -0.741299           11     -0.002166    0.612332  2019-08-26   \n",
       " 1397       -0.735609           11     -0.140562    0.604817  2019-08-26   \n",
       " 1415       -0.724229           11     -0.300525    0.486959  2019-08-26   \n",
       " 1433        0.191849           11     -0.480843    0.554633  2019-08-26   \n",
       " 1448        0.049601           11     -0.597400    0.504962  2019-08-26   \n",
       " 1463        0.106500           11     -0.428525    0.504486  2019-08-26   \n",
       " 1478        0.521865           11     -0.527278    0.467520  2019-08-26   \n",
       " 1493        0.191849           11     -2.533734    2.199653  2019-08-26   \n",
       " 1508        0.078050           11     -2.171209    2.200036  2019-08-26   \n",
       " 1523        0.049601           11     -2.294125    2.185010  2019-08-26   \n",
       " 1538        0.055291           11     -1.842897    1.944844  2019-08-26   \n",
       " 1553        0.066671           11     -2.116323    1.985031  2019-08-26   \n",
       " 1568        0.089430           11     -1.886542    2.059226  2019-08-26   \n",
       " 1583        0.021151           11     -1.576732    1.751378  2019-08-26   \n",
       " 1598        0.459276           11     -0.624475    0.581066  2019-08-26   \n",
       " 1613        0.049601           11     -1.963564    1.910997  2019-08-26   \n",
       " 1628        0.009771           11     -1.660921    1.828564  2019-08-26   \n",
       " 1643        0.026841           11     -1.820646    2.034977  2019-08-26   \n",
       " 1658        0.021151           11     -1.823119    1.956675  2019-08-26   \n",
       " 1673        0.066671           11     -2.008059    2.001237  2019-08-26   \n",
       " 1688        0.823431           11     -1.222917    0.319272  2019-08-26   \n",
       " 1703       -0.115407           11     -0.856816    0.422802  2019-08-26   \n",
       " 1718        0.009771           11     -1.227856    0.345985  2019-08-26   \n",
       " 1733       -0.064198           11     -0.843383    0.444601  2019-08-26   \n",
       " 1748        0.106500           11     -0.733864    0.444906  2019-08-26   \n",
       " 1763        0.231679           11     -0.905674    0.349799  2019-08-26   \n",
       " 1778        0.089430           11     -0.647916    0.466154  2019-08-26   \n",
       " 1056       -0.746989           12     -0.479531    0.739074  2019-08-27   \n",
       " 1074       -0.712850           12      0.134580    0.535133  2019-08-27   \n",
       " 1092       -0.712850           12     -0.809523    0.488185  2019-08-27   \n",
       " 1110       -0.741299           12     -0.350948    0.705889  2019-08-27   \n",
       " 1128       -0.741299           12     -0.445556    0.690713  2019-08-27   \n",
       " 1146       -0.729919           12     -0.577441    0.637199  2019-08-27   \n",
       " 1164       -0.724229           12     -0.524632    0.640340  2019-08-27   \n",
       " 1182        0.032531           12     -0.357235    1.002607  2019-08-27   \n",
       " 1200       -0.769749           12     -0.611244    0.633784  2019-08-27   \n",
       " 1218        0.043911           12     -0.474491    0.877084  2019-08-27   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1145  0.637199         0.796110  \n",
       " 1163  0.640340         0.657879  \n",
       " 1181  1.002607         0.668730  \n",
       " 1199  0.633784         0.624877  \n",
       " 1217  0.877084         0.971028  \n",
       " 1235  1.313864         1.375973  \n",
       " 1253  1.174629         1.664750  \n",
       " 1271  2.347447         2.023565  \n",
       " 1289  2.518291         2.313433  \n",
       " 1307  0.404972         0.586854  \n",
       " 1325  0.522810         0.535334  \n",
       " 1343  0.640368         0.742959  \n",
       " 1361  0.759435         0.724413  \n",
       " 1379  0.755998         0.653493  \n",
       " 1397  0.743119         0.685828  \n",
       " 1415  0.603087         0.584227  \n",
       " 1433  0.846328         0.567613  \n",
       " 1448  0.733708         0.479197  \n",
       " 1463  0.752762         0.550464  \n",
       " 1478  0.705583         0.410229  \n",
       " 1493  2.199653         1.033057  \n",
       " 1508  2.200036         0.913831  \n",
       " 1523  2.185010         1.161265  \n",
       " 1538  1.944844         1.528051  \n",
       " 1553  1.985031         1.203413  \n",
       " 1568  2.059226         1.403339  \n",
       " 1583  1.751378         1.879630  \n",
       " 1598  0.859552         0.553873  \n",
       " 1613  1.910997         1.801906  \n",
       " 1628  1.828564         1.838445  \n",
       " 1643  2.034977         1.624783  \n",
       " 1658  1.956675         1.623864  \n",
       " 1673  2.001237         1.374952  \n",
       " 1688  0.559979         0.256387  \n",
       " 1703  0.674006         0.408903  \n",
       " 1718  0.546243        -0.101270  \n",
       " 1733  0.672380         0.430147  \n",
       " 1748  0.658073         0.507659  \n",
       " 1763  0.572043         0.345028  \n",
       " 1778  0.716187         0.621810  \n",
       " 1056  0.739074         0.765045  \n",
       " 1074  0.535133         0.902464  \n",
       " 1092  0.488185         0.591094  \n",
       " 1110  0.705889         0.612509  \n",
       " 1128  0.690713         0.836221  \n",
       " 1146  0.637199         0.646492  \n",
       " 1164  0.640340         0.713659  \n",
       " 1182  1.164525         1.031743  \n",
       " 1200  0.633784         0.636141  \n",
       " 1218  1.036682         1.009302  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1236        1.019250  X5356_21      0.997439   \n",
       " 1254        1.080101  X5356_22      1.118624   \n",
       " 1272        0.255233  X5356_23      2.815225   \n",
       " 1290        0.390457  X5356_24      3.161470   \n",
       " 1308       -0.758948   X5356_3     -0.785723   \n",
       " 1326       -1.042919   X5356_4     -0.751098   \n",
       " 1344       -1.509442   X5356_5     -0.664537   \n",
       " 1362       -1.556771   X5356_6     -0.638569   \n",
       " 1380       -1.556771   X5356_7     -0.751098   \n",
       " 1398       -1.563532   X5356_8     -0.742442   \n",
       " 1416       -1.441830   X5356_9     -0.725130   \n",
       " 1434        0.721757   X5363_1      0.434791   \n",
       " 1449        0.748802  X5363_10      1.456213   \n",
       " 1464        0.769085  X5363_11      1.309059   \n",
       " 1479        1.587192  X5363_12      1.404277   \n",
       " 1494       -0.481739  X5363_13      1.127281   \n",
       " 1509       -0.447933  X5363_14      1.014751   \n",
       " 1524       -0.393843  X5363_15      1.179217   \n",
       " 1539       -0.542589  X5363_16      1.014751   \n",
       " 1554       -0.454694  X5363_17      1.023407   \n",
       " 1569       -0.272141  X5363_18      0.936846   \n",
       " 1584       -0.975307  X5363_19      2.373762   \n",
       " 1599        0.545965   X5363_2      0.711787   \n",
       " 1614       -0.785993  X5363_20      2.399731   \n",
       " 1629       -0.975307  X5363_21      2.633446   \n",
       " 1644       -0.387082  X5363_22      1.837083   \n",
       " 1659       -0.529067  X5363_23      1.992893   \n",
       " 1674       -0.400604  X5363_24      1.741865   \n",
       " 1689        0.890787   X5363_3      1.291747   \n",
       " 1704        1.019250   X5363_4      0.547320   \n",
       " 1719        1.235609   X5363_5      1.871707   \n",
       " 1734        0.890787   X5363_6      1.750521   \n",
       " 1749        0.911071   X5363_7      1.620680   \n",
       " 1764        1.032772   X5363_8      1.733209   \n",
       " 1779        0.674428   X5363_9      1.508150   \n",
       " 1057       -1.556771  X5356_12     -0.829003   \n",
       " 1075       -1.482398  X5356_13     -0.716474   \n",
       " 1093       -1.245755  X5356_14     -0.742442   \n",
       " 1111       -1.536487  X5356_15     -0.707818   \n",
       " 1129       -1.522965  X5356_16     -0.716474   \n",
       " 1147       -1.543249  X5356_17     -0.725130   \n",
       " 1165       -1.489159  X5356_18     -0.725130   \n",
       " 1183        1.384355  X5356_19      0.729099   \n",
       " 1201       -1.394502   X5356_2     -0.794379   \n",
       " 1219        1.330266  X5356_20      0.772379   \n",
       " 1237        1.019250  X5356_21      0.997439   \n",
       " 1255        1.080101  X5356_22      1.118624   \n",
       " 1273        0.255233  X5356_23      2.815225   \n",
       " 1291        0.390457  X5356_24      3.161470   \n",
       " 1309       -0.758948   X5356_3     -0.785723   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1236                           0.831319     -1.063708 -0.137035      0.504474   \n",
       " 1254                           0.564870     -1.082934  0.041516     -0.484155   \n",
       " 1272                           0.721174      0.291731 -0.344696      3.344154   \n",
       " 1290                           0.817206     -1.140612 -0.463105      0.667493   \n",
       " 1308                          -0.315441     -0.563830  0.733609     -0.505190   \n",
       " 1326                          -0.101703     -0.640734  0.487302     -0.683985   \n",
       " 1344                           0.169441     -0.746478  0.654382     -0.910107   \n",
       " 1362                           0.313489     -0.823382  0.625238     -1.057350   \n",
       " 1380                           0.230642     -0.861834  0.451645     -0.978470   \n",
       " 1398                           0.224991     -0.861834  0.540169     -0.983728   \n",
       " 1416                           0.016931     -0.823382  0.462244     -0.883814   \n",
       " 1434                          -0.012277     -0.256213 -0.257946     -1.041574   \n",
       " 1449                          -0.375686      0.022566 -0.354979     -1.819856   \n",
       " 1464                          -0.255168     -0.208147 -0.384186     -1.830374   \n",
       " 1479                          -0.306951     -0.112017 -0.405966     -1.830374   \n",
       " 1494                          -0.003788     -0.486926 -0.884759      0.083781   \n",
       " 1509                           0.044228     -0.275439 -0.801411     -0.021393   \n",
       " 1524                          -0.204341     -0.352343 -0.984759      0.004901   \n",
       " 1539                           0.157212     -1.025256 -0.413546     -0.242257   \n",
       " 1554                           0.056457     -1.034869 -0.356313     -0.179153   \n",
       " 1569                           0.334208     -1.044482 -0.294791     -0.426310   \n",
       " 1584                           0.644906     -1.284808 -0.245159     -1.556923   \n",
       " 1599                          -0.229755     -0.323504 -0.187706     -1.346576   \n",
       " 1614                           0.299376     -1.304034 -0.385123     -1.525371   \n",
       " 1629                           0.377529     -1.313647 -0.383610     -1.730459   \n",
       " 1644                           0.344553     -1.265582 -0.422644     -1.551664   \n",
       " 1659                           0.255127     -1.284808 -0.371290     -1.656838   \n",
       " 1674                          -0.091358     -1.217517 -0.196443     -1.372870   \n",
       " 1689                          -0.599770     -0.035113 -0.394933     -0.941659   \n",
       " 1704                          -0.467951     -0.150469 -0.430069     -1.104678   \n",
       " 1719                          -0.558332     -0.169695 -0.782588     -1.194075   \n",
       " 1734                          -0.469835     -0.275439 -0.785022     -1.414939   \n",
       " 1749                          -0.464184      0.109083 -0.632141     -1.467526   \n",
       " 1764                          -0.419935      0.185987 -0.729346     -1.504336   \n",
       " 1779                          -0.191157      0.061018 -0.619790     -1.740976   \n",
       " 1057                           0.208995     -0.794543  0.629556     -0.825968   \n",
       " 1075                           2.773659     -0.900286  0.471253     -0.778641   \n",
       " 1093                          -0.140301     -0.746478  0.575099     -0.778641   \n",
       " 1111                           0.015975     -0.900286  0.675089     -0.957435   \n",
       " 1129                           0.099778     -0.861834  0.731414     -0.973211   \n",
       " 1147                           0.072481     -0.861834  0.530361     -0.962694   \n",
       " 1165                           0.091288     -0.842608  0.645651     -0.946918   \n",
       " 1183                           0.586544     -0.765704 -0.246681      0.546543   \n",
       " 1201                           0.150606     -0.746478  0.534198     -0.789158   \n",
       " 1219                           0.268312     -0.640734 -0.138240     -0.357947   \n",
       " 1237                           0.792720     -1.063708 -0.090156      0.504474   \n",
       " 1255                           0.504625     -1.082934  0.151946     -0.484155   \n",
       " 1273                           0.469794      0.291731 -0.741539      3.344154   \n",
       " 1291                           0.702339     -1.140612 -0.761189      0.667493   \n",
       " 1309                          -0.315441     -0.563830  0.733609     -0.505190   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1236        0.106500           12     -0.327413    1.313864  2019-08-27   \n",
       " 1254        0.117880           12     -0.655119    1.174629  2019-08-27   \n",
       " 1272        2.046766           12     -1.149580    2.347447  2019-08-27   \n",
       " 1290       -0.177996           12     -1.160641    2.518291  2019-08-27   \n",
       " 1308       -0.735609           12     -0.614041    0.404972  2019-08-27   \n",
       " 1326       -0.724229           12     -0.511805    0.522810  2019-08-27   \n",
       " 1344       -0.769749           12     -0.948878    0.640368  2019-08-27   \n",
       " 1362       -0.769749           12     -0.440047    0.759435  2019-08-27   \n",
       " 1380       -0.752679           12     -0.237535    0.755998  2019-08-27   \n",
       " 1398       -0.752679           12     -0.395580    0.743119  2019-08-27   \n",
       " 1416       -0.729919           12     -0.584659    0.603087  2019-08-27   \n",
       " 1434        0.180469           12     -0.560475    0.846328  2019-08-27   \n",
       " 1449        0.049601           12     -1.083713    0.733708  2019-08-27   \n",
       " 1464        0.106500           12     -0.935179    0.752762  2019-08-27   \n",
       " 1479        0.521865           12     -0.930542    0.705583  2019-08-27   \n",
       " 1494        0.191849           12     -2.533734    2.199653  2019-08-27   \n",
       " 1509        0.078050           12     -2.171209    2.200036  2019-08-27   \n",
       " 1524        0.049601           12     -2.294125    2.185010  2019-08-27   \n",
       " 1539        0.055291           12     -1.842897    1.944844  2019-08-27   \n",
       " 1554        0.066671           12     -2.116323    1.985031  2019-08-27   \n",
       " 1569        0.089430           12     -1.886542    2.059226  2019-08-27   \n",
       " 1584        0.021151           12     -1.576732    1.751378  2019-08-27   \n",
       " 1599        0.442206           12     -0.885383    0.859552  2019-08-27   \n",
       " 1614        0.049601           12     -1.963564    1.910997  2019-08-27   \n",
       " 1629        0.009771           12     -1.660921    1.828564  2019-08-27   \n",
       " 1644        0.026841           12     -1.820646    2.034977  2019-08-27   \n",
       " 1659        0.021151           12     -1.823119    1.956675  2019-08-27   \n",
       " 1674        0.066671           12     -2.008059    2.001237  2019-08-27   \n",
       " 1689        0.886020           12     -1.574555    0.559979  2019-08-27   \n",
       " 1704       -0.115407           12     -1.087131    0.674006  2019-08-27   \n",
       " 1719        0.009771           12     -1.633060    0.546243  2019-08-27   \n",
       " 1734       -0.064198           12     -1.291279    0.672380  2019-08-27   \n",
       " 1749        0.106500           12     -1.097615    0.658073  2019-08-27   \n",
       " 1764        0.231679           12     -1.339538    0.572043  2019-08-27   \n",
       " 1779        0.089430           12     -1.013909    0.716187  2019-08-27   \n",
       " 1057       -0.746989           13     -0.479531    0.739074  2019-08-28   \n",
       " 1075       -0.712850           13      0.134580    0.535133  2019-08-28   \n",
       " 1093       -0.712850           13     -0.809523    0.488185  2019-08-28   \n",
       " 1111       -0.741299           13     -0.350948    0.705889  2019-08-28   \n",
       " 1129       -0.741299           13     -0.445556    0.690713  2019-08-28   \n",
       " 1147       -0.729919           13     -0.577441    0.637199  2019-08-28   \n",
       " 1165       -0.724229           13     -0.524632    0.640340  2019-08-28   \n",
       " 1183        0.032531           13     -0.448779    1.164525  2019-08-28   \n",
       " 1201       -0.769749           13     -0.611244    0.633784  2019-08-28   \n",
       " 1219        0.043911           13     -0.674032    1.036682  2019-08-28   \n",
       " 1237        0.106500           13     -0.576922    1.487517  2019-08-28   \n",
       " 1255        0.117880           13     -0.985961    1.295848  2019-08-28   \n",
       " 1273        2.046766           13     -1.491116    2.392013  2019-08-28   \n",
       " 1291       -0.177996           13     -1.465238    2.576531  2019-08-28   \n",
       " 1309       -0.735609           13     -0.614041    0.404972  2019-08-28   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1236  1.487517         1.833469  \n",
       " 1254  1.295848         1.532663  \n",
       " 1272  2.392013         0.908658  \n",
       " 1290  2.576531         2.109612  \n",
       " 1308  0.404972         0.641661  \n",
       " 1326  0.522810         0.560101  \n",
       " 1344  0.640368         0.753924  \n",
       " 1362  0.759435         0.700224  \n",
       " 1380  0.755998         0.700742  \n",
       " 1398  0.743119         0.732275  \n",
       " 1416  0.603087         0.547986  \n",
       " 1434  1.145045         0.760606  \n",
       " 1449  0.968417         0.813865  \n",
       " 1464  0.952848         0.848624  \n",
       " 1479  0.969027         0.666772  \n",
       " 1494  2.199653         0.762652  \n",
       " 1509  2.200036         0.595418  \n",
       " 1524  2.185010         0.786539  \n",
       " 1539  1.944844         1.284342  \n",
       " 1554  1.985031         1.157426  \n",
       " 1569  2.059226         1.380172  \n",
       " 1584  1.751378         1.561123  \n",
       " 1599  1.153759         0.768554  \n",
       " 1614  1.910997         1.418007  \n",
       " 1629  1.828564         1.489651  \n",
       " 1644  2.034977         1.265999  \n",
       " 1659  1.956675         1.180772  \n",
       " 1674  2.001237         1.188327  \n",
       " 1689  0.784811         0.325547  \n",
       " 1704  0.922034         0.354467  \n",
       " 1719  0.734051         0.413385  \n",
       " 1734  0.901725         0.444773  \n",
       " 1749  0.854149         0.505880  \n",
       " 1764  0.629218         0.426087  \n",
       " 1779  0.894923         0.863866  \n",
       " 1057  0.739074         0.733610  \n",
       " 1075  0.535133         0.666609  \n",
       " 1093  0.488185         0.577808  \n",
       " 1111  0.705889         0.638675  \n",
       " 1129  0.690713         0.684926  \n",
       " 1147  0.637199         0.632290  \n",
       " 1165  0.640340         0.654772  \n",
       " 1183  1.419456         1.101076  \n",
       " 1201  0.633784         0.633842  \n",
       " 1219  1.202531         1.043346  \n",
       " 1237  1.643876         1.890539  \n",
       " 1255  1.395016         1.578217  \n",
       " 1273  2.562769         0.747865  \n",
       " 1291  2.676313         1.959516  \n",
       " 1309  0.404972         0.641661  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1327       -1.042919   X5356_4     -0.751098   \n",
       " 1345       -1.509442   X5356_5     -0.664537   \n",
       " 1363       -1.556771   X5356_6     -0.638569   \n",
       " 1381       -1.556771   X5356_7     -0.751098   \n",
       " 1399       -1.563532   X5356_8     -0.742442   \n",
       " 1417       -1.441830   X5356_9     -0.725130   \n",
       " 1435        0.431025   X5363_1      0.434791   \n",
       " 1450        0.748802  X5363_10      1.750521   \n",
       " 1465        0.769085  X5363_11      1.707241   \n",
       " 1480        1.587192  X5363_12      1.698585   \n",
       " 1495       -0.481739  X5363_13      1.127281   \n",
       " 1510       -0.447933  X5363_14      1.014751   \n",
       " 1525       -0.393843  X5363_15      1.179217   \n",
       " 1540       -0.542589  X5363_16      1.014751   \n",
       " 1555       -0.454694  X5363_17      1.023407   \n",
       " 1570       -0.272141  X5363_18      0.936846   \n",
       " 1585       -0.975307  X5363_19      2.373762   \n",
       " 1600        0.336368   X5363_2      0.815660   \n",
       " 1615       -0.785993  X5363_20      2.399731   \n",
       " 1630       -0.975307  X5363_21      2.633446   \n",
       " 1645       -0.387082  X5363_22      1.837083   \n",
       " 1660       -0.529067  X5363_23      1.992893   \n",
       " 1675       -0.400604  X5363_24      1.741865   \n",
       " 1690        0.708234   X5363_3      1.205186   \n",
       " 1705        1.019250   X5363_4      1.049375   \n",
       " 1720        1.235609   X5363_5      2.243921   \n",
       " 1735        0.890787   X5363_6      1.958268   \n",
       " 1750        0.911071   X5363_7      1.828427   \n",
       " 1765        1.032772   X5363_8      1.932300   \n",
       " 1780        0.674428   X5363_9      1.646648   \n",
       " 1058       -1.556771  X5356_12     -0.829003   \n",
       " 1076       -1.482398  X5356_13     -0.716474   \n",
       " 1094       -1.245755  X5356_14     -0.742442   \n",
       " 1112       -1.536487  X5356_15     -0.707818   \n",
       " 1130       -1.522965  X5356_16     -0.716474   \n",
       " 1148       -1.543249  X5356_17     -0.725130   \n",
       " 1166       -1.489159  X5356_18     -0.725130   \n",
       " 1184        1.458729  X5356_19      0.417478   \n",
       " 1202       -1.394502   X5356_2     -0.794379   \n",
       " 1220        1.343788  X5356_20      0.486727   \n",
       " 1238        0.877265  X5356_21      1.006095   \n",
       " 1256        0.992205  X5356_22      1.144593   \n",
       " 1274        0.065919  X5356_23      2.572853   \n",
       " 1292        0.187621  X5356_24      2.849849   \n",
       " 1310       -0.758948   X5356_3     -0.785723   \n",
       " 1328       -1.042919   X5356_4     -0.751098   \n",
       " 1346       -1.509442   X5356_5     -0.664537   \n",
       " 1364       -1.556771   X5356_6     -0.638569   \n",
       " 1382       -1.556771   X5356_7     -0.751098   \n",
       " 1400       -1.563532   X5356_8     -0.742442   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1327                          -0.101703     -0.640734  0.487302     -0.683985   \n",
       " 1345                           0.169441     -0.746478  0.654382     -0.910107   \n",
       " 1363                           0.313489     -0.823382  0.625238     -1.057350   \n",
       " 1381                           0.230642     -0.861834  0.451645     -0.978470   \n",
       " 1399                           0.224991     -0.861834  0.540169     -0.983728   \n",
       " 1417                           0.016931     -0.823382  0.462244     -0.883814   \n",
       " 1435                          -0.357807     -0.650347  0.197666     -1.672614   \n",
       " 1450                          -0.518806     -0.583056  0.228895     -2.088048   \n",
       " 1465                          -0.414284     -0.871447  0.653309     -2.088048   \n",
       " 1480                          -0.426513     -0.746478  0.521894     -2.082790   \n",
       " 1495                          -0.003788     -0.486926 -0.884759      0.083781   \n",
       " 1510                           0.044228     -0.275439 -0.801411     -0.021393   \n",
       " 1525                          -0.204341     -0.352343 -0.984759      0.004901   \n",
       " 1540                           0.157212     -1.025256 -0.413546     -0.242257   \n",
       " 1555                           0.056457     -1.034869 -0.356313     -0.179153   \n",
       " 1570                           0.334208     -1.044482 -0.294791     -0.426310   \n",
       " 1585                           0.644906     -1.284808 -0.245159     -1.556923   \n",
       " 1600                          -0.350273     -0.736865  0.232983     -1.867184   \n",
       " 1615                           0.299376     -1.304034 -0.385123     -1.525371   \n",
       " 1630                           0.377529     -1.313647 -0.383610     -1.730459   \n",
       " 1645                           0.344553     -1.265582 -0.422644     -1.551664   \n",
       " 1660                           0.255127     -1.284808 -0.371290     -1.656838   \n",
       " 1675                          -0.091358     -1.217517 -0.196443     -1.372870   \n",
       " 1690                          -0.721215     -0.333117 -0.180459     -1.457008   \n",
       " 1705                          -0.488670     -0.486926 -0.066591     -1.656838   \n",
       " 1720                          -0.675083     -0.486926 -0.547024     -1.630544   \n",
       " 1735                          -0.430280     -0.659960 -0.475869     -1.851408   \n",
       " 1750                          -0.531035     -0.246600 -0.410820     -1.898736   \n",
       " 1765                          -0.622344     -0.198534 -0.406314     -1.925030   \n",
       " 1780                          -0.571517     -0.477313  0.017745     -2.067014   \n",
       " 1058                           0.208995     -0.794543  0.629556     -0.825968   \n",
       " 1076                           2.773659     -0.900286  0.471253     -0.778641   \n",
       " 1094                          -0.140301     -0.746478  0.575099     -0.778641   \n",
       " 1112                           0.015975     -0.900286  0.675089     -0.957435   \n",
       " 1130                           0.099778     -0.861834  0.731414     -0.973211   \n",
       " 1148                           0.072481     -0.861834  0.530361     -0.962694   \n",
       " 1166                           0.091288     -0.842608  0.645651     -0.946918   \n",
       " 1184                           0.595934     -0.948352 -0.214949     -0.636657   \n",
       " 1202                           0.150606     -0.746478  0.534198     -0.789158   \n",
       " 1220                           0.160979     -0.900286 -0.113664     -1.467526   \n",
       " 1238                           0.667508     -1.198291 -0.258387     -0.820710   \n",
       " 1256                           0.500858     -1.217517 -0.132410     -1.688390   \n",
       " 1274                           0.580894     -1.227130 -0.668162      2.350266   \n",
       " 1292                           0.623259     -1.217517  1.620467      0.241541   \n",
       " 1310                          -0.315441     -0.563830  0.733609     -0.505190   \n",
       " 1328                          -0.101703     -0.640734  0.487302     -0.683985   \n",
       " 1346                           0.169441     -0.746478  0.654382     -0.910107   \n",
       " 1364                           0.313489     -0.823382  0.625238     -1.057350   \n",
       " 1382                           0.230642     -0.861834  0.451645     -0.978470   \n",
       " 1400                           0.224991     -0.861834  0.540169     -0.983728   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1327       -0.724229           13     -0.511805    0.522810  2019-08-28   \n",
       " 1345       -0.769749           13     -0.948878    0.640368  2019-08-28   \n",
       " 1363       -0.769749           13     -0.440047    0.759435  2019-08-28   \n",
       " 1381       -0.752679           13     -0.237535    0.755998  2019-08-28   \n",
       " 1399       -0.752679           13     -0.395580    0.743119  2019-08-28   \n",
       " 1417       -0.729919           13     -0.584659    0.603087  2019-08-28   \n",
       " 1435        0.015461           13     -1.181479    1.145045  2019-08-28   \n",
       " 1450        0.049601           13     -1.456549    0.968417  2019-08-28   \n",
       " 1465        0.106500           13     -1.543088    0.952848  2019-08-28   \n",
       " 1480        0.521865           13     -1.484014    0.969027  2019-08-28   \n",
       " 1495        0.191849           13     -2.533734    2.199653  2019-08-28   \n",
       " 1510        0.078050           13     -2.171209    2.200036  2019-08-28   \n",
       " 1525        0.049601           13     -2.294125    2.185010  2019-08-28   \n",
       " 1540        0.055291           13     -1.842897    1.944844  2019-08-28   \n",
       " 1555        0.066671           13     -2.116323    1.985031  2019-08-28   \n",
       " 1570        0.089430           13     -1.886542    2.059226  2019-08-28   \n",
       " 1585        0.021151           13     -1.576732    1.751378  2019-08-28   \n",
       " 1600        0.271508           13     -1.240215    1.153759  2019-08-28   \n",
       " 1615        0.049601           13     -1.963564    1.910997  2019-08-28   \n",
       " 1630        0.009771           13     -1.660921    1.828564  2019-08-28   \n",
       " 1645        0.026841           13     -1.820646    2.034977  2019-08-28   \n",
       " 1660        0.021151           13     -1.823119    1.956675  2019-08-28   \n",
       " 1675        0.066671           13     -2.008059    2.001237  2019-08-28   \n",
       " 1690        0.755152           13     -1.906818    0.784811  2019-08-28   \n",
       " 1705       -0.115407           13     -1.536015    0.922034  2019-08-28   \n",
       " 1720        0.009771           13     -2.081144    0.734051  2019-08-28   \n",
       " 1735       -0.064198           13     -1.799253    0.901725  2019-08-28   \n",
       " 1750        0.106500           13     -1.434319    0.854149  2019-08-28   \n",
       " 1765        0.231679           13     -1.921671    0.629218  2019-08-28   \n",
       " 1780        0.089430           13     -1.530369    0.894923  2019-08-28   \n",
       " 1058       -0.746989           14     -0.479531    0.739074  2019-08-29   \n",
       " 1076       -0.712850           14      0.134580    0.535133  2019-08-29   \n",
       " 1094       -0.712850           14     -0.809523    0.488185  2019-08-29   \n",
       " 1112       -0.741299           14     -0.350948    0.705889  2019-08-29   \n",
       " 1130       -0.741299           14     -0.445556    0.690713  2019-08-29   \n",
       " 1148       -0.729919           14     -0.577441    0.637199  2019-08-29   \n",
       " 1166       -0.724229           14     -0.524632    0.640340  2019-08-29   \n",
       " 1184        0.032531           14     -0.558961    1.419456  2019-08-29   \n",
       " 1202       -0.769749           14     -0.611244    0.633784  2019-08-29   \n",
       " 1220        0.043911           14     -0.848747    1.202531  2019-08-29   \n",
       " 1238        0.106500           14     -0.836468    1.643876  2019-08-29   \n",
       " 1256        0.117880           14     -1.264586    1.395016  2019-08-29   \n",
       " 1274        2.046766           14     -1.574634    2.562769  2019-08-29   \n",
       " 1292       -0.177996           14     -1.611176    2.676313  2019-08-29   \n",
       " 1310       -0.735609           14     -0.614041    0.404972  2019-08-29   \n",
       " 1328       -0.724229           14     -0.511805    0.522810  2019-08-29   \n",
       " 1346       -0.769749           14     -0.948878    0.640368  2019-08-29   \n",
       " 1364       -0.769749           14     -0.440047    0.759435  2019-08-29   \n",
       " 1382       -0.752679           14     -0.237535    0.755998  2019-08-29   \n",
       " 1400       -0.752679           14     -0.395580    0.743119  2019-08-29   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1327  0.522810         0.625140  \n",
       " 1345  0.640368         0.799365  \n",
       " 1363  0.759435         0.712703  \n",
       " 1381  0.755998         0.674248  \n",
       " 1399  0.743119         0.715590  \n",
       " 1417  0.603087         0.653212  \n",
       " 1435  1.417075         0.821181  \n",
       " 1450  1.194161         1.034211  \n",
       " 1465  1.236624         1.140531  \n",
       " 1480  1.148423         1.051947  \n",
       " 1495  2.199653         1.342538  \n",
       " 1510  2.200036         1.369418  \n",
       " 1525  2.185010         1.285270  \n",
       " 1540  1.944844         1.552199  \n",
       " 1555  1.985031         1.517230  \n",
       " 1570  2.059226         1.599032  \n",
       " 1585  1.751378         1.632291  \n",
       " 1600  1.407667         0.912416  \n",
       " 1615  1.910997         1.492910  \n",
       " 1630  1.828564         1.490477  \n",
       " 1645  2.034977         1.385366  \n",
       " 1660  1.956675         1.336062  \n",
       " 1675  2.001237         1.198577  \n",
       " 1690  0.972080         0.585493  \n",
       " 1705  0.718072         0.879284  \n",
       " 1720  0.565160         0.694170  \n",
       " 1735  1.076554         0.988738  \n",
       " 1750  1.034076         0.914986  \n",
       " 1765  0.966515         0.747612  \n",
       " 1780  1.162378         1.061037  \n",
       " 1058  0.739074         0.758997  \n",
       " 1076  0.535133         0.713135  \n",
       " 1094  0.488185         0.723250  \n",
       " 1112  0.705889         0.644575  \n",
       " 1130  0.690713         0.749503  \n",
       " 1148  0.637199         0.711517  \n",
       " 1166  0.640340         0.740950  \n",
       " 1184  1.419456         1.249489  \n",
       " 1202  0.633784         0.779104  \n",
       " 1220  1.202531         0.981688  \n",
       " 1238  1.643876         1.564668  \n",
       " 1256  1.395016         1.260256  \n",
       " 1274  2.562769         2.716232  \n",
       " 1292  2.676313         1.980490  \n",
       " 1310  0.404972         0.606957  \n",
       " 1328  0.522810         0.625140  \n",
       " 1346  0.640368         0.799365  \n",
       " 1364  0.759435         0.712703  \n",
       " 1382  0.755998         0.674248  \n",
       " 1400  0.743119         0.715590  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1418       -1.441830   X5356_9     -0.725130   \n",
       " 1436        0.187621   X5363_1      0.348229   \n",
       " 1451        0.748802  X5363_10      1.499494   \n",
       " 1466        1.174758  X5363_11      1.109968   \n",
       " 1481        1.587192  X5363_12      1.464869   \n",
       " 1496       -0.481739  X5363_13      1.127281   \n",
       " 1511       -0.447933  X5363_14      1.014751   \n",
       " 1526       -0.393843  X5363_15      1.179217   \n",
       " 1541       -0.542589  X5363_16      1.014751   \n",
       " 1556       -0.454694  X5363_17      1.023407   \n",
       " 1571       -0.272141  X5363_18      0.936846   \n",
       " 1586       -0.975307  X5363_19      2.373762   \n",
       " 1601        0.174099   X5363_2      0.824316   \n",
       " 1616       -0.785993  X5363_20      2.399731   \n",
       " 1631       -0.975307  X5363_21      2.633446   \n",
       " 1646       -0.387082  X5363_22      1.837083   \n",
       " 1661       -0.529067  X5363_23      1.992893   \n",
       " 1676       -0.400604  X5363_24      1.741865   \n",
       " 1691        0.559488   X5363_3      1.092656   \n",
       " 1706        1.019250   X5363_4      0.988783   \n",
       " 1721        1.235609   X5363_5      1.889019   \n",
       " 1736        0.890787   X5363_6      1.655304   \n",
       " 1751        0.911071   X5363_7      1.612024   \n",
       " 1766        1.032772   X5363_8      1.698585   \n",
       " 1781        0.674428   X5363_9      1.594711   \n",
       " 1059       -1.556771  X5356_12     -0.829003   \n",
       " 1077       -1.482398  X5356_13     -0.716474   \n",
       " 1095       -1.245755  X5356_14     -0.742442   \n",
       " 1113       -1.536487  X5356_15     -0.707818   \n",
       " 1131       -1.522965  X5356_16     -0.716474   \n",
       " 1149       -1.543249  X5356_17     -0.725130   \n",
       " 1167       -1.489159  X5356_18     -0.725130   \n",
       " 1185        1.458729  X5356_19      0.417478   \n",
       " 1203       -1.394502   X5356_2     -0.794379   \n",
       " 1221        1.343788  X5356_20      0.486727   \n",
       " 1239        0.877265  X5356_21      1.006095   \n",
       " 1257        0.992205  X5356_22      1.144593   \n",
       " 1275        0.065919  X5356_23      2.572853   \n",
       " 1293        0.187621  X5356_24      2.849849   \n",
       " 1311       -0.758948   X5356_3     -0.785723   \n",
       " 1329       -1.042919   X5356_4     -0.751098   \n",
       " 1347       -1.509442   X5356_5     -0.664537   \n",
       " 1365       -1.556771   X5356_6     -0.638569   \n",
       " 1383       -1.556771   X5356_7     -0.751098   \n",
       " 1401       -1.563532   X5356_8     -0.742442   \n",
       " 1419       -1.441830   X5356_9     -0.725130   \n",
       " 1060       -1.556771  X5356_12     -0.829003   \n",
       " 1078       -1.482398  X5356_13     -0.716474   \n",
       " 1096       -1.245755  X5356_14     -0.742442   \n",
       " 1114       -1.536487  X5356_15     -0.707818   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1418                           0.016931     -0.823382  0.462244     -0.883814   \n",
       " 1436                          -0.513156     -0.650347  0.161389     -0.615622   \n",
       " 1451                          -0.644947     -0.756091 -0.070505      0.031194   \n",
       " 1466                          -0.750396     -1.006030  0.065477      0.146885   \n",
       " 1481                          -0.589396     -0.900286  0.023702      0.278351   \n",
       " 1496                          -0.003788     -0.486926 -0.884759      0.083781   \n",
       " 1511                           0.044228     -0.275439 -0.801411     -0.021393   \n",
       " 1526                          -0.204341     -0.352343 -0.984759      0.004901   \n",
       " 1541                           0.157212     -1.025256 -0.413546     -0.242257   \n",
       " 1556                           0.056457     -1.034869 -0.356313     -0.179153   \n",
       " 1571                           0.334208     -1.044482 -0.294791     -0.426310   \n",
       " 1586                           0.644906     -1.284808 -0.245159     -1.556923   \n",
       " 1601                          -0.548915     -0.957965  0.370386     -0.489414   \n",
       " 1616                           0.299376     -1.304034 -0.385123     -1.525371   \n",
       " 1631                           0.377529     -1.313647 -0.383610     -1.730459   \n",
       " 1646                           0.344553     -1.265582 -0.422644     -1.551664   \n",
       " 1661                           0.255127     -1.284808 -0.371290     -1.656838   \n",
       " 1676                          -0.091358     -1.217517 -0.196443     -1.372870   \n",
       " 1691                          -0.795601     -0.486926 -0.299066      0.194213   \n",
       " 1706                          -0.675083     -0.640734  0.085850     -0.031910   \n",
       " 1721                          -0.735328     -0.669573 -0.377245      0.388783   \n",
       " 1736                          -0.655320     -0.842608 -0.547805      0.183695   \n",
       " 1751                          -0.667549     -0.371569 -0.479885      0.115333   \n",
       " 1766                          -0.679778     -0.361956 -0.480068      0.136367   \n",
       " 1781                          -0.579051     -0.708026 -0.020064      0.041711   \n",
       " 1059                           0.208995     -0.794543  0.629556     -0.825968   \n",
       " 1077                           2.773659     -0.900286  0.471253     -0.778641   \n",
       " 1095                          -0.140301     -0.746478  0.575099     -0.778641   \n",
       " 1113                           0.015975     -0.900286  0.675089     -0.957435   \n",
       " 1131                           0.099778     -0.861834  0.731414     -0.973211   \n",
       " 1149                           0.072481     -0.861834  0.530361     -0.962694   \n",
       " 1167                           0.091288     -0.842608  0.645651     -0.946918   \n",
       " 1185                           0.595934     -0.948352 -0.214949     -0.636657   \n",
       " 1203                           0.150606     -0.746478  0.534198     -0.789158   \n",
       " 1221                           0.160979     -0.900286 -0.113664     -1.467526   \n",
       " 1239                           0.667508     -1.198291 -0.258387     -0.820710   \n",
       " 1257                           0.500858     -1.217517 -0.132410     -1.688390   \n",
       " 1275                           0.580894     -1.227130 -0.668162      2.350266   \n",
       " 1293                           0.623259     -1.217517  1.620467      0.241541   \n",
       " 1311                          -0.315441     -0.563830  0.733609     -0.505190   \n",
       " 1329                          -0.101703     -0.640734  0.487302     -0.683985   \n",
       " 1347                           0.169441     -0.746478  0.654382     -0.910107   \n",
       " 1365                           0.313489     -0.823382  0.625238     -1.057350   \n",
       " 1383                           0.230642     -0.861834  0.451645     -0.978470   \n",
       " 1401                           0.224991     -0.861834  0.540169     -0.983728   \n",
       " 1419                           0.016931     -0.823382  0.462244     -0.883814   \n",
       " 1060                           0.208995     -0.794543  0.629556     -0.825968   \n",
       " 1078                           2.773659     -0.900286  0.471253     -0.778641   \n",
       " 1096                          -0.140301     -0.746478  0.575099     -0.778641   \n",
       " 1114                           0.015975     -0.900286  0.675089     -0.957435   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1418       -0.729919           14     -0.584659    0.603087  2019-08-29   \n",
       " 1436       -0.092647           14     -1.509827    1.417075  2019-08-29   \n",
       " 1451        0.049601           14     -1.750179    1.194161  2019-08-29   \n",
       " 1466        1.090858           14     -1.701761    1.236624  2019-08-29   \n",
       " 1481        0.521865           14     -1.459202    1.148423  2019-08-29   \n",
       " 1496        0.191849           14     -2.533734    2.199653  2019-08-29   \n",
       " 1511        0.078050           14     -2.171209    2.200036  2019-08-29   \n",
       " 1526        0.049601           14     -2.294125    2.185010  2019-08-29   \n",
       " 1541        0.055291           14     -1.842897    1.944844  2019-08-29   \n",
       " 1556        0.066671           14     -2.116323    1.985031  2019-08-29   \n",
       " 1571        0.089430           14     -1.886542    2.059226  2019-08-29   \n",
       " 1586        0.021151           14     -1.576732    1.751378  2019-08-29   \n",
       " 1601        0.134950           14     -1.550984    1.407667  2019-08-29   \n",
       " 1616        0.049601           14     -1.963564    1.910997  2019-08-29   \n",
       " 1631        0.009771           14     -1.660921    1.828564  2019-08-29   \n",
       " 1646        0.026841           14     -1.820646    2.034977  2019-08-29   \n",
       " 1661        0.021151           14     -1.823119    1.956675  2019-08-29   \n",
       " 1676        0.066671           14     -2.008059    2.001237  2019-08-29   \n",
       " 1691        0.601524           14     -2.270612    0.972080  2019-08-29   \n",
       " 1706       -0.115407           14     -1.873744    0.718072  2019-08-29   \n",
       " 1721        0.009771           14     -2.464190    0.565160  2019-08-29   \n",
       " 1736       -0.064198           14     -2.147444    1.076554  2019-08-29   \n",
       " 1751        0.106500           14     -1.841881    1.034076  2019-08-29   \n",
       " 1766        0.231679           14     -2.000805    0.966515  2019-08-29   \n",
       " 1781        0.089430           14     -1.734756    1.162378  2019-08-29   \n",
       " 1059       -0.746989           15     -0.479531    0.739074  2019-08-30   \n",
       " 1077       -0.712850           15      0.134580    0.535133  2019-08-30   \n",
       " 1095       -0.712850           15     -0.809523    0.488185  2019-08-30   \n",
       " 1113       -0.741299           15     -0.350948    0.705889  2019-08-30   \n",
       " 1131       -0.741299           15     -0.445556    0.690713  2019-08-30   \n",
       " 1149       -0.729919           15     -0.577441    0.637199  2019-08-30   \n",
       " 1167       -0.724229           15     -0.524632    0.640340  2019-08-30   \n",
       " 1185        0.032531           15     -0.558961    1.419456  2019-08-30   \n",
       " 1203       -0.769749           15     -0.611244    0.633784  2019-08-30   \n",
       " 1221        0.043911           15     -0.848747    1.202531  2019-08-30   \n",
       " 1239        0.106500           15     -0.836468    1.643876  2019-08-30   \n",
       " 1257        0.117880           15     -1.264586    1.395016  2019-08-30   \n",
       " 1275        2.046766           15     -1.574634    2.562769  2019-08-30   \n",
       " 1293       -0.177996           15     -1.611176    2.676313  2019-08-30   \n",
       " 1311       -0.735609           15     -0.614041    0.404972  2019-08-30   \n",
       " 1329       -0.724229           15     -0.511805    0.522810  2019-08-30   \n",
       " 1347       -0.769749           15     -0.948878    0.640368  2019-08-30   \n",
       " 1365       -0.769749           15     -0.440047    0.759435  2019-08-30   \n",
       " 1383       -0.752679           15     -0.237535    0.755998  2019-08-30   \n",
       " 1401       -0.752679           15     -0.395580    0.743119  2019-08-30   \n",
       " 1419       -0.729919           15     -0.584659    0.603087  2019-08-30   \n",
       " 1060       -0.746989           16     -0.479531    0.739074  2019-08-31   \n",
       " 1078       -0.712850           16      0.134580    0.535133  2019-08-31   \n",
       " 1096       -0.712850           16     -0.809523    0.488185  2019-08-31   \n",
       " 1114       -0.741299           16     -0.350948    0.705889  2019-08-31   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1418  0.603087         0.622776  \n",
       " 1436  1.417075         1.054324  \n",
       " 1451  1.194161         1.101843  \n",
       " 1466  1.236624         0.663196  \n",
       " 1481  1.148423         0.914961  \n",
       " 1496  2.199653         0.808049  \n",
       " 1511  2.200036         0.877277  \n",
       " 1526  2.185010         0.746563  \n",
       " 1541  1.944844         1.464804  \n",
       " 1556  1.985031         1.408057  \n",
       " 1571  2.059226         1.582054  \n",
       " 1586  1.751378         1.474166  \n",
       " 1601  1.407667         1.044757  \n",
       " 1616  1.910997         1.360602  \n",
       " 1631  1.828564         1.395528  \n",
       " 1646  2.034977         1.363317  \n",
       " 1661  1.956675         1.388785  \n",
       " 1676  2.001237         1.265448  \n",
       " 1691  0.972080         0.996626  \n",
       " 1706  0.718072         0.709282  \n",
       " 1721  0.565160         0.899058  \n",
       " 1736  1.076554         0.933701  \n",
       " 1751  1.034076         0.793336  \n",
       " 1766  0.966515         0.795529  \n",
       " 1781  1.162378         1.166623  \n",
       " 1059  0.739074         0.740335  \n",
       " 1077  0.535133         0.542968  \n",
       " 1095  0.488185         0.656310  \n",
       " 1113  0.705889         0.679514  \n",
       " 1131  0.690713         0.682063  \n",
       " 1149  0.637199         0.684829  \n",
       " 1167  0.640340         0.640764  \n",
       " 1185  1.419456         1.261714  \n",
       " 1203  0.633784         0.657794  \n",
       " 1221  1.202531         1.039220  \n",
       " 1239  1.643876         1.289368  \n",
       " 1257  1.395016         1.159333  \n",
       " 1275  2.562769         2.566961  \n",
       " 1293  2.676313         1.490580  \n",
       " 1311  0.404972         0.631037  \n",
       " 1329  0.522810         0.632387  \n",
       " 1347  0.640368         0.734856  \n",
       " 1365  0.759435         0.755228  \n",
       " 1383  0.755998         0.755756  \n",
       " 1401  0.743119         0.743996  \n",
       " 1419  0.603087         0.622776  \n",
       " 1060  0.739074         0.740335  \n",
       " 1078  0.535133         0.542968  \n",
       " 1096  0.488185         0.656310  \n",
       " 1114  0.705889         0.679514  ,\n",
       "       glutamate(g/l)       UID  ammonia(g/l)  \\\n",
       " 1132       -1.522965  X5356_16     -0.716474   \n",
       " 1150       -1.543249  X5356_17     -0.725130   \n",
       " 1168       -1.489159  X5356_18     -0.725130   \n",
       " 1186        1.458729  X5356_19      0.417478   \n",
       " 1204       -1.394502   X5356_2     -0.794379   \n",
       " 1222        1.343788  X5356_20      0.486727   \n",
       " 1240        0.877265  X5356_21      1.006095   \n",
       " 1258        0.992205  X5356_22      1.144593   \n",
       " 1276        0.065919  X5356_23      2.572853   \n",
       " 1294        0.187621  X5356_24      2.849849   \n",
       " 1312       -0.758948   X5356_3     -0.785723   \n",
       " 1330       -1.042919   X5356_4     -0.751098   \n",
       " 1348       -1.509442   X5356_5     -0.664537   \n",
       " 1366       -1.556771   X5356_6     -0.638569   \n",
       " 1384       -1.556771   X5356_7     -0.751098   \n",
       " 1402       -1.563532   X5356_8     -0.742442   \n",
       " 1420       -1.441830   X5356_9     -0.725130   \n",
       " 1061       -1.556771  X5356_12     -0.829003   \n",
       " 1079       -1.482398  X5356_13     -0.716474   \n",
       " 1097       -1.245755  X5356_14     -0.742442   \n",
       " 1115       -1.536487  X5356_15     -0.707818   \n",
       " 1133       -1.522965  X5356_16     -0.716474   \n",
       " 1151       -1.543249  X5356_17     -0.725130   \n",
       " 1169       -1.489159  X5356_18     -0.725130   \n",
       " 1187        1.458729  X5356_19      0.417478   \n",
       " 1205       -1.394502   X5356_2     -0.794379   \n",
       " 1223        1.343788  X5356_20      0.486727   \n",
       " 1241        0.877265  X5356_21      1.006095   \n",
       " 1259        0.992205  X5356_22      1.144593   \n",
       " 1277        0.065919  X5356_23      2.572853   \n",
       " 1295        0.187621  X5356_24      2.849849   \n",
       " 1313       -0.758948   X5356_3     -0.785723   \n",
       " 1331       -1.042919   X5356_4     -0.751098   \n",
       " 1349       -1.509442   X5356_5     -0.664537   \n",
       " 1367       -1.556771   X5356_6     -0.638569   \n",
       " 1385       -1.556771   X5356_7     -0.751098   \n",
       " 1403       -1.563532   X5356_8     -0.742442   \n",
       " 1421       -1.441830   X5356_9     -0.725130   \n",
       " \n",
       "       viable cell density(1e6 cells/ml)  lactate(g/l)        ph  glucose(g/l)  \\\n",
       " 1132                           0.099778     -0.861834  0.731414     -0.973211   \n",
       " 1150                           0.072481     -0.861834  0.530361     -0.962694   \n",
       " 1168                           0.091288     -0.842608  0.645651     -0.946918   \n",
       " 1186                           0.595934     -0.948352 -0.214949     -0.636657   \n",
       " 1204                           0.150606     -0.746478  0.534198     -0.789158   \n",
       " 1222                           0.160979     -0.900286 -0.113664     -1.467526   \n",
       " 1240                           0.667508     -1.198291 -0.258387     -0.820710   \n",
       " 1258                           0.500858     -1.217517 -0.132410     -1.688390   \n",
       " 1276                           0.580894     -1.227130 -0.668162      2.350266   \n",
       " 1294                           0.623259     -1.217517  1.620467      0.241541   \n",
       " 1312                          -0.315441     -0.563830  0.733609     -0.505190   \n",
       " 1330                          -0.101703     -0.640734  0.487302     -0.683985   \n",
       " 1348                           0.169441     -0.746478  0.654382     -0.910107   \n",
       " 1366                           0.313489     -0.823382  0.625238     -1.057350   \n",
       " 1384                           0.230642     -0.861834  0.451645     -0.978470   \n",
       " 1402                           0.224991     -0.861834  0.540169     -0.983728   \n",
       " 1420                           0.016931     -0.823382  0.462244     -0.883814   \n",
       " 1061                           0.208995     -0.794543  0.629556     -0.825968   \n",
       " 1079                           2.773659     -0.900286  0.471253     -0.778641   \n",
       " 1097                          -0.140301     -0.746478  0.575099     -0.778641   \n",
       " 1115                           0.015975     -0.900286  0.675089     -0.957435   \n",
       " 1133                           0.099778     -0.861834  0.731414     -0.973211   \n",
       " 1151                           0.072481     -0.861834  0.530361     -0.962694   \n",
       " 1169                           0.091288     -0.842608  0.645651     -0.946918   \n",
       " 1187                           0.595934     -0.948352 -0.214949     -0.636657   \n",
       " 1205                           0.150606     -0.746478  0.534198     -0.789158   \n",
       " 1223                           0.160979     -0.900286 -0.113664     -1.467526   \n",
       " 1241                           0.667508     -1.198291 -0.258387     -0.820710   \n",
       " 1259                           0.500858     -1.217517 -0.132410     -1.688390   \n",
       " 1277                           0.580894     -1.227130 -0.668162      2.350266   \n",
       " 1295                           0.623259     -1.217517  1.620467      0.241541   \n",
       " 1313                          -0.315441     -0.563830  0.733609     -0.505190   \n",
       " 1331                          -0.101703     -0.640734  0.487302     -0.683985   \n",
       " 1349                           0.169441     -0.746478  0.654382     -0.910107   \n",
       " 1367                           0.313489     -0.823382  0.625238     -1.057350   \n",
       " 1385                           0.230642     -0.861834  0.451645     -0.978470   \n",
       " 1403                           0.224991     -0.861834  0.540169     -0.983728   \n",
       " 1421                           0.016931     -0.823382  0.462244     -0.883814   \n",
       " \n",
       "       glutamine(g/l)  working day  viability(%)  titre(g/l)   timestamp  \\\n",
       " 1132       -0.741299           16     -0.445556    0.690713  2019-08-31   \n",
       " 1150       -0.729919           16     -0.577441    0.637199  2019-08-31   \n",
       " 1168       -0.724229           16     -0.524632    0.640340  2019-08-31   \n",
       " 1186        0.032531           16     -0.558961    1.419456  2019-08-31   \n",
       " 1204       -0.769749           16     -0.611244    0.633784  2019-08-31   \n",
       " 1222        0.043911           16     -0.848747    1.202531  2019-08-31   \n",
       " 1240        0.106500           16     -0.836468    1.643876  2019-08-31   \n",
       " 1258        0.117880           16     -1.264586    1.395016  2019-08-31   \n",
       " 1276        2.046766           16     -1.574634    2.562769  2019-08-31   \n",
       " 1294       -0.177996           16     -1.611176    2.676313  2019-08-31   \n",
       " 1312       -0.735609           16     -0.614041    0.404972  2019-08-31   \n",
       " 1330       -0.724229           16     -0.511805    0.522810  2019-08-31   \n",
       " 1348       -0.769749           16     -0.948878    0.640368  2019-08-31   \n",
       " 1366       -0.769749           16     -0.440047    0.759435  2019-08-31   \n",
       " 1384       -0.752679           16     -0.237535    0.755998  2019-08-31   \n",
       " 1402       -0.752679           16     -0.395580    0.743119  2019-08-31   \n",
       " 1420       -0.729919           16     -0.584659    0.603087  2019-08-31   \n",
       " 1061       -0.746989           17     -0.479531    0.739074  2019-09-01   \n",
       " 1079       -0.712850           17      0.134580    0.535133  2019-09-01   \n",
       " 1097       -0.712850           17     -0.809523    0.488185  2019-09-01   \n",
       " 1115       -0.741299           17     -0.350948    0.705889  2019-09-01   \n",
       " 1133       -0.741299           17     -0.445556    0.690713  2019-09-01   \n",
       " 1151       -0.729919           17     -0.577441    0.637199  2019-09-01   \n",
       " 1169       -0.724229           17     -0.524632    0.640340  2019-09-01   \n",
       " 1187        0.032531           17     -0.558961    1.419456  2019-09-01   \n",
       " 1205       -0.769749           17     -0.611244    0.633784  2019-09-01   \n",
       " 1223        0.043911           17     -0.848747    1.202531  2019-09-01   \n",
       " 1241        0.106500           17     -0.836468    1.643876  2019-09-01   \n",
       " 1259        0.117880           17     -1.264586    1.395016  2019-09-01   \n",
       " 1277        2.046766           17     -1.574634    2.562769  2019-09-01   \n",
       " 1295       -0.177996           17     -1.611176    2.676313  2019-09-01   \n",
       " 1313       -0.735609           17     -0.614041    0.404972  2019-09-01   \n",
       " 1331       -0.724229           17     -0.511805    0.522810  2019-09-01   \n",
       " 1349       -0.769749           17     -0.948878    0.640368  2019-09-01   \n",
       " 1367       -0.769749           17     -0.440047    0.759435  2019-09-01   \n",
       " 1385       -0.752679           17     -0.237535    0.755998  2019-09-01   \n",
       " 1403       -0.752679           17     -0.395580    0.743119  2019-09-01   \n",
       " 1421       -0.729919           17     -0.584659    0.603087  2019-09-01   \n",
       " \n",
       "         Target  predicted_value  \n",
       " 1132  0.690713         0.686724  \n",
       " 1150  0.637199         0.702595  \n",
       " 1168  0.640340         0.672745  \n",
       " 1186  1.419456         0.955209  \n",
       " 1204  0.633784         0.644157  \n",
       " 1222  1.202531         0.899977  \n",
       " 1240  1.643876         1.181027  \n",
       " 1258  1.395016         1.150866  \n",
       " 1276  2.562769         2.562762  \n",
       " 1294  2.676313         1.929526  \n",
       " 1312  0.404972         0.710929  \n",
       " 1330  0.522810         0.599150  \n",
       " 1348  0.640368         0.749427  \n",
       " 1366  0.759435         0.753519  \n",
       " 1384  0.755998         0.704729  \n",
       " 1402  0.743119         0.737517  \n",
       " 1420  0.603087         0.611894  \n",
       " 1061  0.739074         0.762276  \n",
       " 1079  0.535133         0.613870  \n",
       " 1097  0.488185         0.602930  \n",
       " 1115  0.705889         0.691494  \n",
       " 1133  0.690713         0.686724  \n",
       " 1151  0.637199         0.702595  \n",
       " 1169  0.640340         0.672745  \n",
       " 1187  1.419456         0.955209  \n",
       " 1205  0.633784         0.644157  \n",
       " 1223  1.202531         0.899977  \n",
       " 1241  1.643876         1.181027  \n",
       " 1259  1.395016         1.150866  \n",
       " 1277  2.562769         2.562762  \n",
       " 1295  2.676313         1.929526  \n",
       " 1313  0.404972         0.710929  \n",
       " 1331  0.522810         0.599150  \n",
       " 1349  0.640368         0.749427  \n",
       " 1367  0.759435         0.753519  \n",
       " 1385  0.755998         0.704729  \n",
       " 1403  0.743119         0.737517  \n",
       " 1421  0.603087         0.611894  ]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba47bff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.25137150042578793\n",
      "MSE: 0.12488481023715871\n",
      "RMSE: 0.35339045012161646\n",
      "R2: 0.895265661936742\n",
      "MAPE: 0.7176649660511947\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.concat(results)\n",
    "\n",
    "# Calculate metrics\n",
    "true_values = results_df[target_col]\n",
    "predicted_values = results_df['predicted_value']\n",
    "\n",
    "MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "RMSE_t = math.sqrt(MSE_t)\n",
    "r2_t = r2_score(true_values, predicted_values)\n",
    "mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "# Save results to a CSV file\n",
    "# results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"MAE: {MAE_t}\")\n",
    "print(f\"MSE: {MSE_t}\")\n",
    "print(f\"RMSE: {RMSE_t}\")\n",
    "print(f\"R2: {r2_t}\")\n",
    "print(f\"MAPE: {mape_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b7ba1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'results/AMBR/AMBR_{method}_{config}_{num_nearest_neighbors}_{distance_metric}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115405aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_400 = pd.read_csv('results/New_Catboost_no_encoding_no_bucketing_400_dtw.csv')\n",
    "results_df_300 = pd.read_csv('results/New_Catboost_no_encoding_no_bucketing_300_dtw.csv')\n",
    "results_df_200 = pd.read_csv('results/New_Catboost_no_encoding_no_bucketing_200_dtw.csv')\n",
    "results_df_100 = pd.read_csv('results/New_Catboost_no_encoding_no_bucketing_100_dtw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fa36082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05d93456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_avg_mae(df, true_col, pred_col, window_size=5):\n",
    "    true_values = df[true_col].to_numpy()\n",
    "    predicted_values = df[pred_col].to_numpy()\n",
    "\n",
    "    num_rows_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    for i in range(2, len(true_values) + 1):\n",
    "        num_rows_list.append(i)\n",
    "        mae = mean_absolute_error(true_values[:i], predicted_values[:i])\n",
    "        mae_list.append(mae)\n",
    "\n",
    "    mae_df = pd.DataFrame({'num_rows': num_rows_list, 'mae': mae_list})\n",
    "    mae_df['moving_avg_mae'] = mae_df['mae'].rolling(window=window_size).mean()\n",
    "    \n",
    "    return mae_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ae39ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate MAE\n",
    "def calculate_mae(df, target_col, predicted_col):\n",
    "    return np.mean(np.abs(df[target_col] - df[predicted_col]))\n",
    "\n",
    "# List to store MAE values and corresponding file names\n",
    "mae_list = []\n",
    "\n",
    "results_folder = 'results/AMBR'  # Replace with the path to your results folder\n",
    "target_col = \"Target\"\n",
    "# target_col = \"Product Content pre clean up (g/L)\"\n",
    "\n",
    "# Get the list of files in the results folder\n",
    "files = os.scandir(results_folder)\n",
    "\n",
    "\n",
    "# Loop through each file\n",
    "for file in files:\n",
    "    if not file.name.startswith('.') and file.is_file():\n",
    "        df = pd.read_csv(file.path)\n",
    "        # df = df.tail(722)\n",
    "        \n",
    "        # Calculate the MAE for the file\n",
    "        # mae = calculate_mae(df, target_col, 'predicted_value')\n",
    "        mae = mean_absolute_error(df[target_col], df['predicted_value'])\n",
    "        \n",
    "        # Append the MAE and file name to the list\n",
    "        mae_list.append((mae, file.name))\n",
    "\n",
    "mae_list.sort(key=lambda x: x[0], reverse=False)\n",
    "\n",
    "# Extract the top 4 file names with the lowest MAE\n",
    "top_4_files = [file_name for _, file_name in mae_list[:4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c81c69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMBR_Catboost_no_encoding_no_bucketing_300_cosine.csv',\n",
       " 'AMBR_Catboost_no_encoding_no_bucketing_200_chebyshev.csv',\n",
       " 'AMBR_Catboost_no_encoding_no_bucketing_400_cosine.csv',\n",
       " 'AMBR_Catboost_no_encoding_no_bucketing_200_euclidean.csv']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_4_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d52ad095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of filenames to desired labels\n",
    "filename_to_label = {\n",
    "    'Astra_Catboost_no_encoding_no_bucketing_400_chebyshev.csv': 'Chebyshev with 400 neighbors',\n",
    "    'Astra_Catboost_no_encoding_no_bucketing_100_cosine.csv': 'Cosine with 100 neighbors',\n",
    "    'Astra_Catboost_no_encoding_no_bucketing_400_euclidean.csv': 'Euclidean with 400 neighbors',\n",
    "    'Astra_Catboost_no_encoding_no_bucketing_300_cosine.csv': 'Cosine with 300 neighbors',\n",
    "    'CSL312_Catboost_no_encoding_no_bucketing_100_cosine.csv': 'Cosine with 100 neighbors',\n",
    "    'CSL312_Catboost_no_encoding_no_bucketing_300_euclidean.csv': 'Euclidean with 300 neighbors',\n",
    "    'CSL312_Catboost_no_encoding_no_bucketing_300_chebyshev.csv': 'Chebyshev with 300 neighbors',\n",
    "    'CSL312_Catboost_no_encoding_no_bucketing_400_euclidean.csv': 'Euclidean with 400 neighbors',\n",
    "    'New_Catboost_no_encoding_no_bucketing_400_chebyshev.csv' : 'Chebyshev with 400 neighbors',\n",
    "    'New_Catboost_no_encoding_no_bucketing_300_chebyshev.csv' : 'Chebyshev with 300 neighbors',\n",
    "    'New_Catboost_no_encoding_no_bucketing_400_euclidean.csv' : 'Euclidean with 400 neighbors',\n",
    "    'New_Catboost_no_encoding_no_bucketing_200_chebyshev.csv': 'Chebyshev with 200 neighbors',\n",
    "    'AMBR_Catboost_no_encoding_no_bucketing_300_cosine.csv': 'Cosine with 300 neighbors',\n",
    "    'AMBR_Catboost_no_encoding_no_bucketing_200_chebyshev.csv': 'Chebyshev with 200 neighbors',\n",
    "    'AMBR_Catboost_no_encoding_no_bucketing_400_cosine.csv': 'Cosine with 400 neighbors',\n",
    "    'AMBR_Catboost_no_encoding_no_bucketing_200_euclidean.csv': 'Euclidean with 200 neighbors',\n",
    "    # Add more mappings as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_4_files = ['New_Catboost_no_encoding_no_bucketing_100_cosine.csv', 'New_Catboost_no_encoding_no_bucketing_300_cosine.csv', 'New_Catboost_no_encoding_no_bucketing_400_euclidean.csv', 'New_Catboost_no_encoding_no_bucketing_400_cosine.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4c110146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMBR_Catboost_no_encoding_no_bucketing_200_cosine.csv', 'AMBR_Catboost_no_encoding_no_bucketing_400_cosine.csv', 'AMBR_Catboost_no_encoding_no_bucketing_300_cosine.csv', 'AMBR_Catboost_no_encoding_no_bucketing_200_chebyshev.csv', 'AMBR_Catboost_no_encoding_no_bucketing_100_euclidean.csv', 'AMBR_Catboost_no_encoding_no_bucketing_300_chebyshev.csv', 'AMBR_Catboost_no_encoding_no_bucketing_400_chebyshev.csv', 'baseline_Catboost_no_encoding_no_bucketing_400_cosine_expotential.csv', 'AMBR_Catboost_no_encoding_no_bucketing_300_euclidean.csv', 'AMBR_Catboost_no_encoding_no_bucketing_100_chebyshev.csv', 'AMBR_Catboost_no_encoding_no_bucketing_400_euclidean.csv', 'AMBR_Catboost_no_encoding_no_bucketing_400_cosine_expotential.csv', 'AMBR_Catboost_no_encoding_no_bucketing_100_cosine.csv', 'AMBR_Catboost_no_encoding_no_bucketing_200_euclidean.csv']\n",
      "AMBR_Catboost_no_encoding_no_bucketing_300_cosine.csv\n",
      "(737, 3)\n",
      "AMBR_Catboost_no_encoding_no_bucketing_200_chebyshev.csv\n",
      "(737, 3)\n",
      "AMBR_Catboost_no_encoding_no_bucketing_400_cosine.csv\n",
      "(737, 3)\n",
      "AMBR_Catboost_no_encoding_no_bucketing_200_euclidean.csv\n",
      "(737, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_folder = 'results/AMBR'  # Replace with the path to your results folder\n",
    "\n",
    "# Get the list of files in the results folder\n",
    "files = os.scandir(results_folder)\n",
    "# Get scandir object\n",
    "with os.scandir(results_folder) as entries:\n",
    "    # Extract file names\n",
    "    file_names = [entry.name for entry in entries if entry.is_file() & entry.name.endswith('.csv')]\n",
    "\n",
    "# Print the file names as a string\n",
    "print(file_names)\n",
    "\n",
    "# Create a figure to display all the plots\n",
    "# fig, ax = plt.subplots()\n",
    "plt.figure()\n",
    "\n",
    "# Loop through each file\n",
    "for file in top_4_files:\n",
    "    print(str(file))\n",
    "    df = pd.read_csv(results_folder+\"/\"+file)\n",
    "    # df = df.tail(1041)\n",
    "    df = df.sort_values(timestamp_col)\n",
    "    \n",
    "    # Plot the moving average MAE\n",
    "    # Calculate the moving average\n",
    "    window_size = 5\n",
    "    moving_avg = calculate_moving_avg_mae(df, target_col, 'predicted_value')\n",
    "    \n",
    "    print(moving_avg.shape)\n",
    "    # Plot the original values and the moving average\n",
    "    label = filename_to_label.get(file, file)  # Get the custom label or default to filename\n",
    "    if label == 'Chebyshev with 200 neighbors':\n",
    "        plt.plot(moving_avg['moving_avg_mae'], label=label, color='red')\n",
    "    elif label == 'Cosine with 400 neighbors':\n",
    "        plt.plot(moving_avg['moving_avg_mae'], label=label, color='gray')\n",
    "    elif label == 'Cosine with 300 neighbors':\n",
    "        plt.plot(moving_avg['moving_avg_mae'], label=label, color='magenta')\n",
    "    elif label == 'Euclidean with 200 neighbors':\n",
    "        plt.plot(moving_avg['moving_avg_mae'], label=label, color='olive')\n",
    "    else:\n",
    "        plt.plot(moving_avg['moving_avg_mae'], label=label)\n",
    "    # plt.legend(fontsize='small')\n",
    "  \n",
    "\n",
    "    # Set the labels and title for the plot\n",
    "    # ax.set_xlabel('Time')\n",
    "    # ax.set_ylabel('Moving Average MAE')\n",
    "    # ax.set_title('Moving Average MAE for Each File')\n",
    "    # ax.legend()\n",
    "\n",
    "    # Display the plot\n",
    "baseline_results = baseline_results.sort_values(timestamp_col)\n",
    "moving_avg_baseline = calculate_moving_avg_mae(baseline_results, target_col, 'predicted_value', window_size=5)\n",
    "plt.plot(moving_avg_baseline['moving_avg_mae'], label='baseline', color='purple')\n",
    "plt.legend(fontsize='medium')\n",
    "\n",
    "# Set labels\n",
    "plt.xlabel(\"Prefixes Ordered by Time\", fontsize=16)\n",
    "plt.ylabel(\"Moving Average MAE\", fontsize=16)\n",
    "plt.title(\"AMBR Dataset\", fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# Save the figure in high quality\n",
    "# plt.savefig('figure.png', dpi=400)\n",
    "# plt.savefig('AMBR.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in top_4_files:\n",
    "    tmp = pd.read_csv(f'results/{file}')\n",
    "    # Calculate metrics\n",
    "    true_values = tmp[target_col]\n",
    "    predicted_values = tmp['predicted_value']\n",
    "\n",
    "    MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "    MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "    RMSE_t = math.sqrt(MSE_t)\n",
    "    r2_t = r2_score(true_values, predicted_values)\n",
    "    mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    # results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"MAE: {MAE_t}\")\n",
    "    print(f\"MSE: {MSE_t}\")\n",
    "    print(f\"RMSE: {RMSE_t}\")\n",
    "    print(f\"R2: {r2_t}\")\n",
    "    print(f\"MAPE: {mape_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02233a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.tail(1041)[work_day_col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31c4c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('results/New_Catboost_no_encoding_no_bucketing_300_cosine.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0619393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.24705038672885973\n",
      "MSE: 0.27228320401853867\n",
      "RMSE: 0.5218076312383124\n",
      "R2: 0.7686180237981541\n",
      "MAPE: 0.6401030765186212\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "true_values = tmp[target_col]\n",
    "predicted_values = tmp['predicted_value']\n",
    "\n",
    "MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "RMSE_t = math.sqrt(MSE_t)\n",
    "r2_t = r2_score(true_values, predicted_values)\n",
    "mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "# Save results to a CSV file\n",
    "# results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"MAE: {MAE_t}\")\n",
    "print(f\"MSE: {MSE_t}\")\n",
    "print(f\"RMSE: {RMSE_t}\")\n",
    "print(f\"R2: {r2_t}\")\n",
    "print(f\"MAPE: {mape_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48813aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: lag\n",
      "MAE: 0.04466220332919408\n",
      "MSE: 0.008302472688910772\n",
      "RMSE: 0.09111790542429503\n",
      "\n",
      "Phase: Exponential\n",
      "MAE: 0.12023659393863242\n",
      "MSE: 0.046451889361347955\n",
      "RMSE: 0.21552700378687575\n",
      "\n",
      "Phase: plateau\n",
      "MAE: 0.3408952939685124\n",
      "MSE: 0.4119128822862743\n",
      "RMSE: 0.6418043956582677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "work_day_values = tmp['Work_Day_Index'].unique()\n",
    "phases = ['lag', 'Exponential', 'plateau']\n",
    "dat = pd.DataFrame(columns=['Working Day', 'MAE', 'MSE', 'RMSE'])\n",
    "for phase in phases:\n",
    "    if phase == 'lag':\n",
    "        work_day_phase = work_day_values[:3]\n",
    "    elif phase == 'Exponential':\n",
    "        work_day_phase = work_day_values[3:6]\n",
    "    else:\n",
    "        work_day_phase = work_day_values[6:]\n",
    "    work_day_data = tmp[tmp['Work_Day_Index'].isin(work_day_phase)]\n",
    "    predicted_values = work_day_data['predicted_value']\n",
    "    target_values = work_day_data['Target']\n",
    "    \n",
    "    mae = np.mean(np.abs(predicted_values - target_values))\n",
    "    mse = np.mean((predicted_values - target_values) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    new_row = pd.DataFrame({'Working Day': [phase], 'MAE': [mae], 'MSE': [mse], 'RMSE': [rmse]})\n",
    "    dat = pd.concat([dat, new_row], ignore_index=True)\n",
    "    \n",
    "    print(f\"Phase: {phase}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf6391e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: lag\n",
      "MAE: 0.06448978247836294\n",
      "MSE: 0.01439299100835569\n",
      "RMSE: 0.11997079231361144\n",
      "\n",
      "Phase: Exponential\n",
      "MAE: 0.28598330639663705\n",
      "MSE: 0.18154888982193002\n",
      "RMSE: 0.4260855428454831\n",
      "\n",
      "Phase: plateau\n",
      "MAE: 0.5157306095652668\n",
      "MSE: 0.5325550518770829\n",
      "RMSE: 0.7297636959160704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "work_day_values = baseline_results[work_day_col].unique()\n",
    "phases = ['lag', 'Exponential', 'plateau']\n",
    "dat2 = pd.DataFrame(columns=['Working Day', 'MAE', 'MSE', 'RMSE'])\n",
    "for phase in phases:\n",
    "    if phase == 'lag':\n",
    "        work_day_phase = work_day_values[:3]\n",
    "    elif phase == 'Exponential':\n",
    "        work_day_phase = work_day_values[3:6]\n",
    "    else:\n",
    "        work_day_phase = work_day_values[6:]\n",
    "    work_day_data = baseline_results[baseline_results[work_day_col].isin(work_day_phase)]\n",
    "    predicted_values = work_day_data['predicted_value']\n",
    "    target_values = work_day_data['Target']\n",
    "    \n",
    "    mae = np.mean(np.abs(predicted_values - target_values))\n",
    "    mse = np.mean((predicted_values - target_values) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    new_row = pd.DataFrame({'Working Day': [phase], 'MAE': [mae], 'MSE': [mse], 'RMSE': [rmse]})\n",
    "    dat2 = pd.concat([dat2, new_row], ignore_index=True)\n",
    "    \n",
    "    print(f\"Phase: {phase}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7848a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Working Day</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lag</td>\n",
       "      <td>0.044662</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.091118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>0.120237</td>\n",
       "      <td>0.046452</td>\n",
       "      <td>0.215527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plateau</td>\n",
       "      <td>0.340895</td>\n",
       "      <td>0.411913</td>\n",
       "      <td>0.641804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Working Day       MAE       MSE      RMSE\n",
       "0          lag  0.044662  0.008302  0.091118\n",
       "1  Exponential  0.120237  0.046452  0.215527\n",
       "2      plateau  0.340895  0.411913  0.641804"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "919ec0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Working Day</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lag</td>\n",
       "      <td>0.064490</td>\n",
       "      <td>0.014393</td>\n",
       "      <td>0.119971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>0.285983</td>\n",
       "      <td>0.181549</td>\n",
       "      <td>0.426086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plateau</td>\n",
       "      <td>0.515731</td>\n",
       "      <td>0.532555</td>\n",
       "      <td>0.729764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Working Day       MAE       MSE      RMSE\n",
       "0          lag  0.064490  0.014393  0.119971\n",
       "1  Exponential  0.285983  0.181549  0.426086\n",
       "2      plateau  0.515731  0.532555  0.729764"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row_data column\n",
    "row_data_df = pd.json_normalize(results_df_400['row_data'])\n",
    "\n",
    "# Drop the original row_data column from results_df_baseline\n",
    "tmp = results_df_400.drop(columns=['row_data'])\n",
    "\n",
    "# Concatenate the normalized row_data DataFrame with the original DataFrame\n",
    "tmp = pd.concat([tmp, row_data_df], axis=1)\n",
    "\n",
    "# Retain true_value and predicted_value columns\n",
    "tmp = tmp[['true_value', 'predicted_value'] + list(row_data_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1bd29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row_data column\n",
    "row_data_df = pd.json_normalize(results_df_300['row_data'])\n",
    "\n",
    "# Drop the original row_data column from results_df_baseline\n",
    "tmp2 = results_df_300.drop(columns=['row_data'])\n",
    "\n",
    "# Concatenate the normalized row_data DataFrame with the original DataFrame\n",
    "tmp2 = pd.concat([tmp2, row_data_df], axis=1)\n",
    "\n",
    "# Retain true_value and predicted_value columns\n",
    "tmp2 = tmp2[['true_value', 'predicted_value'] + list(row_data_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb69399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row_data column\n",
    "row_data_df = pd.json_normalize(results_df_200['row_data'])\n",
    "\n",
    "# Drop the original row_data column from results_df_baseline\n",
    "tmp3 = results_df_200.drop(columns=['row_data'])\n",
    "\n",
    "# Concatenate the normalized row_data DataFrame with the original DataFrame\n",
    "tmp3 = pd.concat([tmp3, row_data_df], axis=1)\n",
    "\n",
    "# Retain true_value and predicted_value columns\n",
    "tmp3 = tmp3[['true_value', 'predicted_value'] + list(row_data_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row_data column\n",
    "row_data_df = pd.json_normalize(results_df_100['row_data'])\n",
    "\n",
    "# Drop the original row_data column from results_df_baseline\n",
    "tmp4 = results_df_100.drop(columns=['row_data'])\n",
    "\n",
    "# Concatenate the normalized row_data DataFrame with the original DataFrame\n",
    "tmp4 = pd.concat([tmp4, row_data_df], axis=1)\n",
    "\n",
    "# Retain true_value and predicted_value columns\n",
    "tmp4 = tmp4[['true_value', 'predicted_value'] + list(row_data_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a9d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_avg_mae(df, true_col, pred_col, window_size=5):\n",
    "    true_values = df[true_col].to_numpy()\n",
    "    predicted_values = df[pred_col].to_numpy()\n",
    "\n",
    "    num_rows_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    for i in range(2, len(true_values) + 1):\n",
    "        num_rows_list.append(i)\n",
    "        mae = mean_absolute_error(true_values[:i], predicted_values[:i])\n",
    "        mae_list.append(mae)\n",
    "\n",
    "    mae_df = pd.DataFrame({'num_rows': num_rows_list, 'mae': mae_list})\n",
    "    mae_df['moving_avg_mae'] = mae_df['mae'].rolling(window=window_size).mean()\n",
    "    \n",
    "    return mae_df\n",
    "\n",
    "# Calculate moving average MAE for tmp\n",
    "mae_df_tmp = calculate_moving_avg_mae(results_df_400, target_col, 'predicted_value')\n",
    "\n",
    "# Calculate moving average MAE for tmp2\n",
    "mae_df_tmp2 = calculate_moving_avg_mae(results_df_300, target_col, 'predicted_value')\n",
    "\n",
    "# Calculate moving average MAE for tmp2\n",
    "mae_df_tmp3 = calculate_moving_avg_mae(results_df_200, target_col, 'predicted_value')\n",
    "\n",
    "# Calculate moving average MAE for tmp2\n",
    "mae_df_tmp4 = calculate_moving_avg_mae(results_df_100, target_col, 'predicted_value')\n",
    "\n",
    "# Plot the moving average MAE for both DataFrames\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mae_df_tmp['num_rows'], mae_df_tmp['moving_avg_mae'], label='400', color='blue')\n",
    "plt.plot(mae_df_tmp2['num_rows'], mae_df_tmp2['moving_avg_mae'], label='300', color='red')\n",
    "# plt.plot(mae_df_tmp3['num_rows'], mae_df_tmp3['moving_avg_mae'], label='200', color='green')\n",
    "# plt.plot(mae_df_tmp4['num_rows'], mae_df_tmp4['moving_avg_mae'], label='100', color='black')\n",
    "plt.xlabel('Number of Observed Rows')\n",
    "plt.xlabel('Number of Observed Rows')\n",
    "plt.ylabel('Moving Average MAE')\n",
    "plt.title('CSL 5L')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7278916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### without batch processing #########\n",
    "data = df_normalized.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "data['Target'] = data.groupby(case_id_col)[target_col].shift(-1)\n",
    "data['Target_orig'] = data.groupby(case_id_col)['Titer (g/L) original'].shift(-1)\n",
    "data['Target'] = data.groupby(case_id_col)['Target'].ffill()\n",
    "data['Target_orig'] = data.groupby(case_id_col)['Target_orig'].ffill()\n",
    "\n",
    "historic, current = processor.split_data(data, train_ratio=0.5, split=\"temporal\")\n",
    "historic.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort', inplace=True)\n",
    "current.sort_values([timestamp_col], ascending=True, kind='mergesort', inplace=True)\n",
    "\n",
    "if config == 'no_encoding_bucketing' or config == 'encoding_bucketing':\n",
    "    features_used = features + ['Cluster']\n",
    "else:\n",
    "    features_used = features\n",
    "\n",
    "# n_neighbors = 200\n",
    "# # Initialize the NearestNeighbors model\n",
    "# nn_model = NearestNeighbors(n_neighbors=n_neighbors, metric=\"cosine\")\n",
    "# # Fit the model on the historic data\n",
    "# nn_model.fit(historic[features_used])\n",
    "\n",
    "nn_model = processor.train_nn_model(historic[features_used])\n",
    "\n",
    "for index, row in current.iterrows():\n",
    "    # Find the n nearest neighbors for the selected row\n",
    "    # distances, indices = nn_model.kneighbors([row[features_used]])\n",
    "    distances, indices = processor.find_nearest_neighbors(nn_model, [row[features_used]])\n",
    "    nearest_neighbors = historic.iloc[indices[0]]\n",
    "\n",
    "    target = nearest_neighbors['Target'].values\n",
    "    target_test = row['Target']\n",
    "\n",
    "    if target_test is None:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    if method == 'Catboost':\n",
    "        # Create the CatBoostRegressor model\n",
    "        model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='MAE', verbose=0)\n",
    "        model.fit(nearest_neighbors[features_used], target)\n",
    "\n",
    "    if method == 'HMM':\n",
    "        # Create an instance of the HMM model\n",
    "        model = hmm.GaussianHMM(n_components=7)  # Specify the number of hidden states\n",
    "        model.fit(df_without_last[features+['Cluster']])\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    preds = model.predict(row[features_used])\n",
    "\n",
    "    # true_conc_glu = row['Target_orig']\n",
    "    # preds_scaled = scalers[target_col].inverse_transform(preds.reshape(-1, 1))\n",
    "\n",
    "    key = row[case_id_col] + '_' + str(row[work_day_col])\n",
    "    results.append({\n",
    "        'key': key,\n",
    "        'row_data': row.to_dict(),\n",
    "        'true_value': row['Target'],\n",
    "        'predicted_value': preds\n",
    "    })\n",
    "\n",
    "    # Add the current row with its prediction to the historic data\n",
    "    row_with_prediction = row.copy()\n",
    "    # row_with_prediction[target_col] = preds_scaled[0][0]\n",
    "    historic = pd.concat([historic, pd.DataFrame([row_with_prediction])], ignore_index=True)\n",
    "    historic.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort', inplace=True)\n",
    "    nn_model =processor.train_nn_model(historic[features_used])  # Refit the model with the updated historic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f436b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_prefix_length = 1\n",
    "max_prefix_length = df_normalized[work_day_col].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_manager = DatasetManager(\"5L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_test_prefix_generation = time.time()\n",
    "dt_prefixes = dataset_manager.generate_prefix_data(df_normalized, min_prefix_length, max_prefix_length)\n",
    "test_prefix_generation_time = time.time() - start_test_prefix_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f083e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove both EncoderFactory and AggregateTransformer from sys.modules\n",
    "modules_to_remove = ['EncoderFactory', 'transformers.AggregateTransformer', 'DatasetManager']\n",
    "for module in modules_to_remove:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "# Re-import the modules\n",
    "import EncoderFactory\n",
    "import transformers.AggregateTransformer\n",
    "import DatasetManager\n",
    "from DatasetManager import DatasetManager\n",
    "\n",
    "# Reload the modules\n",
    "importlib.reload(transformers.AggregateTransformer)\n",
    "importlib.reload(EncoderFactory)\n",
    "# importlib.reload(DatasetManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d790f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderFactory.get_encoder(method='agg', case_id_col=case_id_col, static_cat_cols=None, static_num_cols=None, dynamic_cat_cols=['Cluster'],\n",
    "                dynamic_num_cols=features, fillna=True, max_events=None, activity_col=None, resource_col=None, timestamp_col=timestamp_col,\n",
    "                scale_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_transformed = encoder.transform(dt_prefixes)\n",
    "dt_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "method = 'Catboost'\n",
    "# config = 'no_encoding_no_bucketing'\n",
    "# config = 'no_encoding_bucketing'\n",
    "# config = 'encoding_no_bucketing'\n",
    "config = 'encoding_bucketing'\n",
    "\n",
    "data = dt_prefixes.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "# data['Target'] = data.groupby(case_id_col)[target_col].shift(-1)\n",
    "# data['Target_orig'] = data.groupby(case_id_col)['Titer (g/L) original'].shift(-1)\n",
    "# data['Target'] = data.groupby(case_id_col)['Target'].ffill()\n",
    "# data['Target_orig'] = data.groupby(case_id_col)['Target_orig'].ffill()\n",
    "\n",
    "historic, current = split_data(data, train_ratio=0.5, split=\"temporal\")\n",
    "historic.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort', inplace=True)\n",
    "current.sort_values([timestamp_col], ascending=True, kind='mergesort', inplace=True)\n",
    "\n",
    "if config == 'no_encoding_bucketing' or config == 'encoding_bucketing':\n",
    "    features_used = features + ['Cluster']\n",
    "else:\n",
    "    features_used = features\n",
    "\n",
    "# Initialize the NearestNeighbors model\n",
    "nn_model = NearestNeighbors(n_neighbors=200)\n",
    "# Fit the model on the historic data\n",
    "nn_model.fit(historic[features_used])\n",
    "\n",
    "for index, row in current.iterrows():\n",
    "    # Find the n nearest neighbors for the selected row\n",
    "    distances, indices = nn_model.kneighbors([row[features_used]])\n",
    "    nearest_neighbors = historic.iloc[indices[0]]\n",
    "\n",
    "    target = nearest_neighbors['Target'].values\n",
    "    target_test = row['Target']\n",
    "\n",
    "    if target_test is None:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    if method == 'Catboost':\n",
    "        # Create the CatBoostRegressor model\n",
    "        model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='MAE', verbose=0)\n",
    "        model.fit(nearest_neighbors[features_used], target)\n",
    "\n",
    "    if method == 'HMM':\n",
    "        # Create an instance of the HMM model\n",
    "        model = hmm.GaussianHMM(n_components=7)  # Specify the number of hidden states\n",
    "        model.fit(df_without_last[features+['Cluster']])\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    preds = model.predict(row[features_used])\n",
    "\n",
    "    true_conc_glu = row['Target_orig']\n",
    "    preds_scaled = scalers[target_col].inverse_transform(preds.reshape(-1, 1))\n",
    "    \n",
    "    key = row[case_id_col] + '_' + str(row[work_day_col])\n",
    "    results.append({\n",
    "        'key': key,\n",
    "        'row_data': row.to_dict(),\n",
    "        'true_value': true_conc_glu,\n",
    "        'predicted_value': preds_scaled[0][0]\n",
    "    })\n",
    "\n",
    "    # Add the current row with its prediction to the historic data\n",
    "    row_with_prediction = row.copy()\n",
    "    # row_with_prediction[target_col] = preds_scaled[0][0]\n",
    "    historic = pd.concat([historic, pd.DataFrame([row_with_prediction])], ignore_index=True)\n",
    "    historic.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort', inplace=True)\n",
    "    nn_model.fit(historic[features_used])  # Refit the model with the updated historic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate metrics\n",
    "true_values = results_df['true_value']\n",
    "predicted_values = results_df['predicted_value']\n",
    "\n",
    "MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "RMSE_t = math.sqrt(MSE_t)\n",
    "r2_t = r2_score(true_values, predicted_values)\n",
    "mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "# Save results to a CSV file\n",
    "# results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"MAE: {MAE_t}\")\n",
    "print(f\"MSE: {MSE_t}\")\n",
    "print(f\"RMSE: {RMSE_t}\")\n",
    "print(f\"R2: {r2_t}\")\n",
    "print(f\"MAPE: {mape_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc98450",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7258d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'results/{method}_{config}_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dd5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "method = 'Catboost'\n",
    "# config = 'no_encoding_no_bucketing'\n",
    "config = 'no_encoding_bucketing'\n",
    "# config = 'encoding_no_bucketing'\n",
    "# config = 'encoding_bucketing'\n",
    "\n",
    "data = df_normalized.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "data['Target'] = data.groupby(case_id_col)[target_col].shift(-1)\n",
    "data['Target_orig'] = data.groupby(case_id_col)['Titer (g/L) original'].shift(-1)\n",
    "data['Target'] = data.groupby(case_id_col)['Target'].ffill()\n",
    "data['Target_orig'] = data.groupby(case_id_col)['Target_orig'].ffill()\n",
    "\n",
    "historic, current = split_data(data, train_ratio=0.5, split=\"temporal\")\n",
    "historic.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort', inplace=True)\n",
    "current.sort_values([timestamp_col], ascending=True, kind='mergesort', inplace=True)\n",
    "\n",
    "if config == 'no_encoding_bucketing' or config == 'encoding_bucketing':\n",
    "    features_used = features + ['Cluster']\n",
    "else:\n",
    "    features_used = features\n",
    "\n",
    "\n",
    "for index, row in current.iterrows():\n",
    "\n",
    "    target = historic['Target'].values\n",
    "    target_test = row['Target']\n",
    "\n",
    "    if target_test is None:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    if method == 'Catboost':\n",
    "        # Create the CatBoostRegressor model\n",
    "        model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='MAE', verbose=0, random_state=123)\n",
    "        model.fit(historic[features_used], target)\n",
    "\n",
    "    if method == 'HMM':\n",
    "        # Create an instance of the HMM model\n",
    "        model = hmm.GaussianHMM(n_components=7)  # Specify the number of hidden states\n",
    "        model.fit(df_without_last[features+['Cluster']])\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    preds = model.predict(row[features_used])\n",
    "\n",
    "    true_conc_glu = row['Target_orig']\n",
    "    preds_scaled = scalers[target_col].inverse_transform(preds.reshape(-1, 1))\n",
    "    \n",
    "    key = row[case_id_col] + '_' + str(row[work_day_col])\n",
    "    results.append({\n",
    "        'key': key,\n",
    "        'row_data': row.to_dict(),\n",
    "        'true_value': true_conc_glu,\n",
    "        'predicted_value': preds_scaled[0][0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe54dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2752721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "true_values = results_df['true_value']\n",
    "predicted_values = results_df['predicted_value']\n",
    "\n",
    "MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "RMSE_t = math.sqrt(MSE_t)\n",
    "r2_t = r2_score(true_values, predicted_values)\n",
    "mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "# Save results to a CSV file\n",
    "# results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"MAE: {MAE_t}\")\n",
    "print(f\"MSE: {MSE_t}\")\n",
    "print(f\"RMSE: {RMSE_t}\")\n",
    "print(f\"R2: {r2_t}\")\n",
    "print(f\"MAPE: {mape_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'results/baseline_{method}_{config}_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "method = 'Catboost'\n",
    "# config = 'no_encoding_no_bucketing'\n",
    "# config = 'no_encoding_bucketing'\n",
    "# config = 'encoding_no_bucketing'\n",
    "config = 'encoding_bucketing'\n",
    "\n",
    "data = dt_prefixes.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "# data['Target'] = data.groupby(case_id_col)[target_col].shift(-1)\n",
    "# data['Target_orig'] = data.groupby(case_id_col)['Titer (g/L) original'].shift(-1)\n",
    "# data['Target'] = data.groupby(case_id_col)['Target'].ffill()\n",
    "# data['Target_orig'] = data.groupby(case_id_col)['Target_orig'].ffill()\n",
    "\n",
    "historic, current = split_data(data, train_ratio=0.5, split=\"temporal\")\n",
    "historic.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort', inplace=True)\n",
    "current.sort_values([timestamp_col], ascending=True, kind='mergesort', inplace=True)\n",
    "\n",
    "if config == 'no_encoding_bucketing' or config == 'encoding_bucketing':\n",
    "    features_used = features + ['Cluster']\n",
    "else:\n",
    "    features_used = features\n",
    "\n",
    "\n",
    "for index, row in current.iterrows():\n",
    "\n",
    "    target = historic['Target'].values\n",
    "    target_test = row['Target']\n",
    "\n",
    "    if target_test is None:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    if method == 'Catboost':\n",
    "        # Create the CatBoostRegressor model\n",
    "        model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='MAE', verbose=0, random_state=123)\n",
    "        model.fit(historic[features_used], target)\n",
    "\n",
    "    if method == 'HMM':\n",
    "        # Create an instance of the HMM model\n",
    "        model = hmm.GaussianHMM(n_components=7)  # Specify the number of hidden states\n",
    "        model.fit(df_without_last[features+['Cluster']])\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    preds = model.predict(row[features_used])\n",
    "\n",
    "    true_conc_glu = row['Target_orig']\n",
    "    preds_scaled = scalers[target_col].inverse_transform(preds.reshape(-1, 1))\n",
    "    \n",
    "    key = row[case_id_col] + '_' + str(row[work_day_col])\n",
    "    results.append({\n",
    "        'key': key,\n",
    "        'row_data': row.to_dict(),\n",
    "        'true_value': true_conc_glu,\n",
    "        'predicted_value': preds_scaled[0][0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "true_values = results_df['true_value']\n",
    "predicted_values = results_df['predicted_value']\n",
    "\n",
    "MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "RMSE_t = math.sqrt(MSE_t)\n",
    "r2_t = r2_score(true_values, predicted_values)\n",
    "mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "# Save results to a CSV file\n",
    "# results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"MAE: {MAE_t}\")\n",
    "print(f\"MSE: {MSE_t}\")\n",
    "print(f\"RMSE: {RMSE_t}\")\n",
    "print(f\"R2: {r2_t}\")\n",
    "print(f\"MAPE: {mape_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'results/baseline_{method}_{config}_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "# Ensure the data is sorted by case ID and workday\n",
    "df_encoded = df_normalized.sort_values(by=[case_id_col, work_day_col])\n",
    "df_encoded = df_encoded.drop([timestamp_col], axis=1)\n",
    "\n",
    "# Function to create accumulated sequences\n",
    "def create_accumulated_sequences(df):\n",
    "    sequences = []\n",
    "    for case_id, group in df.groupby(case_id_col):\n",
    "        accumulated_data = []\n",
    "        for i in range(len(group)):\n",
    "            accumulated_data.append(group.iloc[:i+1].drop(columns=[case_id_col, work_day_col]).values.flatten())\n",
    "            sequences.append(np.concatenate(accumulated_data))\n",
    "    return sequences\n",
    "\n",
    "# Create the accumulated sequences\n",
    "sequences = create_accumulated_sequences(df_encoded)\n",
    "\n",
    "# Pad the sequences to the same length\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "\n",
    "# Flatten the sequences to find unique tokens\n",
    "flattened_sequences = np.concatenate(padded_sequences).flatten()\n",
    "\n",
    "# Find unique tokens\n",
    "unique_tokens = np.unique(flattened_sequences)\n",
    "\n",
    "# Set vocab_size to the number of unique tokens plus one\n",
    "vocab_size = len(unique_tokens) + 1\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Define the embedding model\n",
    "embedding_dim = 128  # Dimension of the embedding space\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "# Compile the model to avoid graph execution error\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# Apply the embedding transformation\n",
    "embedded_sequences = model.predict(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Viability (%)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8294abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized['Viability original'] = scalers[target_col].inverse_transform(df_normalized[target_col].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ba970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "true_values = results_df['true_value']\n",
    "predicted_values = results_df['predicted_value']\n",
    "\n",
    "MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "RMSE_t = math.sqrt(MSE_t)\n",
    "r2_t = r2_score(true_values, predicted_values)\n",
    "mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "# Save results to a CSV file\n",
    "# results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"MAE: {MAE_t}\")\n",
    "print(f\"MSE: {MSE_t}\")\n",
    "print(f\"RMSE: {RMSE_t}\")\n",
    "print(f\"R2: {r2_t}\")\n",
    "print(f\"MAPE: {mape_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_cluster = pd.DataFrame(results)\n",
    "results_df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "true_values = results_df_cluster['true_value']\n",
    "predicted_values = results_df_cluster['predicted_value']\n",
    "\n",
    "MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "RMSE_t = math.sqrt(MSE_t)\n",
    "r2_t = r2_score(true_values, predicted_values)\n",
    "mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "# Save results to a CSV file\n",
    "# results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"MAE: {MAE_t}\")\n",
    "print(f\"MSE: {MSE_t}\")\n",
    "print(f\"RMSE: {RMSE_t}\")\n",
    "print(f\"R2: {r2_t}\")\n",
    "print(f\"MAPE: {mape_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f33a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_baseline = pd.DataFrame(results)\n",
    "results_df_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "true_values = results_df_baseline['true_value']\n",
    "predicted_values = results_df_baseline['predicted_value']\n",
    "\n",
    "MAE_t = mean_absolute_error(true_values, predicted_values)\n",
    "MSE_t = mean_squared_error(true_values, predicted_values)\n",
    "RMSE_t = math.sqrt(MSE_t)\n",
    "r2_t = r2_score(true_values, predicted_values)\n",
    "mape_t = mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "# Save results to a CSV file\n",
    "# results_df.to_csv('predictions_with_row_data.csv', index=False)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"MAE: {MAE_t}\")\n",
    "print(f\"MSE: {MSE_t}\")\n",
    "print(f\"RMSE: {RMSE_t}\")\n",
    "print(f\"R2: {r2_t}\")\n",
    "print(f\"MAPE: {mape_t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62106467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row_data column\n",
    "row_data_df = pd.json_normalize(results_df_baseline['row_data'])\n",
    "\n",
    "# Drop the original row_data column from results_df_baseline\n",
    "tmp = results_df_baseline.drop(columns=['row_data'])\n",
    "\n",
    "# Concatenate the normalized row_data DataFrame with the original DataFrame\n",
    "tmp = pd.concat([tmp, row_data_df], axis=1)\n",
    "\n",
    "# Retain true_value and predicted_value columns\n",
    "tmp = tmp[['true_value', 'predicted_value'] + list(row_data_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row_data column\n",
    "row_data_df = pd.json_normalize(results_df['row_data'])\n",
    "\n",
    "# Drop the original row_data column from results_df_baseline\n",
    "tmp2 = results_df.drop(columns=['row_data'])\n",
    "\n",
    "# Concatenate the normalized row_data DataFrame with the original DataFrame\n",
    "tmp2 = pd.concat([tmp2, row_data_df], axis=1)\n",
    "\n",
    "# Retain true_value and predicted_value columns\n",
    "tmp2 = tmp2[['true_value', 'predicted_value'] + list(row_data_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the row_data column\n",
    "row_data_df = pd.json_normalize(results_df_cluster['row_data'])\n",
    "\n",
    "# Drop the original row_data column from results_df_baseline\n",
    "tmp3 = results_df_cluster.drop(columns=['row_data'])\n",
    "\n",
    "# Concatenate the normalized row_data DataFrame with the original DataFrame\n",
    "# tmp3 = pd.concat([tmp3, row_data_df], axis=1)\n",
    "\n",
    "# Retain true_value and predicted_value columns\n",
    "tmp3 = tmp3[['true_value', 'predicted_value'] + list(row_data_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_avg_mae(df, true_col, pred_col, window_size=5):\n",
    "    true_values = df[true_col].to_numpy()\n",
    "    predicted_values = df[pred_col].to_numpy()\n",
    "\n",
    "    num_rows_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    for i in range(2, len(true_values) + 1):\n",
    "        num_rows_list.append(i)\n",
    "        mae = mean_absolute_error(true_values[:i], predicted_values[:i])\n",
    "        mae_list.append(mae)\n",
    "\n",
    "    mae_df = pd.DataFrame({'num_rows': num_rows_list, 'mae': mae_list})\n",
    "    mae_df['moving_avg_mae'] = mae_df['mae'].rolling(window=window_size).mean()\n",
    "    \n",
    "    return mae_df\n",
    "\n",
    "# Calculate moving average MAE for tmp\n",
    "mae_df_tmp = calculate_moving_avg_mae(tmp, 'true_value', 'predicted_value')\n",
    "\n",
    "# Calculate moving average MAE for tmp2\n",
    "mae_df_tmp2 = calculate_moving_avg_mae(tmp2, 'true_value', 'predicted_value')\n",
    "\n",
    "# Calculate moving average MAE for tmp2\n",
    "# mae_df_tmp3 = calculate_moving_avg_mae(tmp3, 'true_value', 'predicted_value')\n",
    "\n",
    "# Plot the moving average MAE for both DataFrames\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mae_df_tmp['num_rows'], mae_df_tmp['moving_avg_mae'], label='regular learning', color='blue')\n",
    "plt.plot(mae_df_tmp2['num_rows'], mae_df_tmp2['moving_avg_mae'], label='just-in-time learning', color='red')\n",
    "# plt.plot(mae_df_tmp3['num_rows'], mae_df_tmp3['moving_avg_mae'], label='just-in-time learning with bucketing', color='green')\n",
    "plt.xlabel('Number of Observed Rows')\n",
    "plt.ylabel('Moving Average MAE')\n",
    "plt.title('Moving Average MAE vs Number of Observed events')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47455b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_avg_rmse(df, true_col, pred_col, window_size=5):\n",
    "    true_values = df[true_col].to_numpy()\n",
    "    predicted_values = df[pred_col].to_numpy()\n",
    "\n",
    "    num_rows_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    for i in range(2, len(true_values) + 1):\n",
    "        num_rows_list.append(i)\n",
    "        rmse = np.sqrt(mean_squared_error(true_values[:i], predicted_values[:i]))\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "    rmse_df = pd.DataFrame({'num_rows': num_rows_list, 'rmse': rmse_list})\n",
    "    rmse_df['moving_avg_rmse'] = rmse_df['rmse'].rolling(window=window_size).mean()\n",
    "    \n",
    "    return rmse_df\n",
    "\n",
    "# Calculate moving average RMSE for tmp\n",
    "rmse_df_tmp = calculate_moving_avg_rmse(tmp, 'true_value', 'predicted_value')\n",
    "\n",
    "# Calculate moving average RMSE for tmp2\n",
    "rmse_df_tmp2 = calculate_moving_avg_rmse(tmp2, 'true_value', 'predicted_value')\n",
    "\n",
    "# Plot the moving average RMSE for both DataFrames\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(rmse_df_tmp['num_rows'], rmse_df_tmp['moving_avg_rmse'], label='regular learning', color='blue')\n",
    "plt.plot(rmse_df_tmp2['num_rows'], rmse_df_tmp2['moving_avg_rmse'], label='just-in-time learning', color='red')\n",
    "plt.xlabel('Number of Observed Rows')\n",
    "plt.ylabel('Moving Average RMSE')\n",
    "plt.title('Moving Average RMSE vs Number of Observed events')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_avg_r2(df, true_col, pred_col, window_size=5):\n",
    "    true_values = df[true_col].to_numpy()\n",
    "    predicted_values = df[pred_col].to_numpy()\n",
    "\n",
    "    num_rows_list = []\n",
    "    r2_list = []\n",
    "\n",
    "    for i in range(10, len(true_values) + 1):\n",
    "        num_rows_list.append(i)\n",
    "        r2 = r2_score(true_values[:i], predicted_values[:i])\n",
    "        r2_list.append(r2)\n",
    "\n",
    "    r2_df = pd.DataFrame({'num_rows': num_rows_list, 'r2': r2_list})\n",
    "    r2_df['moving_avg_r2'] = r2_df['r2'].rolling(window=window_size).mean()\n",
    "    \n",
    "    return r2_df\n",
    "\n",
    "# Calculate moving average R² for tmp\n",
    "r2_df_tmp = calculate_moving_avg_r2(tmp, 'true_value', 'predicted_value')\n",
    "\n",
    "# Calculate moving average R² for tmp2\n",
    "r2_df_tmp2 = calculate_moving_avg_r2(tmp2, 'true_value', 'predicted_value')\n",
    "\n",
    "# Plot the moving average R² for both DataFrames\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(r2_df_tmp['num_rows'], r2_df_tmp['moving_avg_r2'], label='regular learning', color='blue')\n",
    "plt.plot(r2_df_tmp2['num_rows'], r2_df_tmp2['moving_avg_r2'], label='just-in-time learning', color='red')\n",
    "plt.xlabel('Number of Observed Rows')\n",
    "plt.ylabel('Moving Average R²')\n",
    "plt.title('Moving Average R² vs Number of Observed events')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adjusted_r2(r2, n, k):\n",
    "    if n <= k + 1:\n",
    "        return np.nan  # Return NaN if the calculation is not possible\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "def calculate_moving_avg_adjusted_r2(df, true_col, pred_col, window_size=5):\n",
    "    true_values = df[true_col].to_numpy()\n",
    "    predicted_values = df[pred_col].to_numpy()\n",
    "    k = 1  # Number of predictors\n",
    "\n",
    "    num_rows_list = []\n",
    "    adjusted_r2_list = []\n",
    "\n",
    "    for i in range(10, len(true_values) + 1):\n",
    "        num_rows_list.append(i)\n",
    "        r2 = r2_score(true_values[:i], predicted_values[:i])\n",
    "        adjusted_r2 = calculate_adjusted_r2(r2, i, k)\n",
    "        adjusted_r2_list.append(adjusted_r2)\n",
    "\n",
    "    adjusted_r2_df = pd.DataFrame({'num_rows': num_rows_list, 'adjusted_r2': adjusted_r2_list})\n",
    "    adjusted_r2_df['moving_avg_adjusted_r2'] = adjusted_r2_df['adjusted_r2'].rolling(window=window_size).mean()\n",
    "    \n",
    "    return adjusted_r2_df\n",
    "\n",
    "# Calculate moving average adjusted R² for tmp\n",
    "adjusted_r2_df_tmp = calculate_moving_avg_adjusted_r2(tmp, 'true_value', 'predicted_value')\n",
    "\n",
    "# Calculate moving average adjusted R² for tmp2\n",
    "adjusted_r2_df_tmp2 = calculate_moving_avg_adjusted_r2(tmp2, 'true_value', 'predicted_value')\n",
    "\n",
    "# Plot the moving average adjusted R² for both DataFrames\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(adjusted_r2_df_tmp['num_rows'], adjusted_r2_df_tmp['moving_avg_adjusted_r2'], label='regular learning', color='blue')\n",
    "plt.plot(adjusted_r2_df_tmp2['num_rows'], adjusted_r2_df_tmp2['moving_avg_adjusted_r2'], label='just-in-time learning', color='red')\n",
    "plt.xlabel('Number of Observed Rows')\n",
    "plt.ylabel('Moving Average Adjusted R²')\n",
    "plt.title('Moving Average Adjusted R² vs Number of Observed events')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "method = 'Catboost'\n",
    "\n",
    "data = df_normalized.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "data['Target'] = data[target_col].shift(-1)\n",
    "data['Target_orig'] = data['Titer (g/L) original'].shift(-1)\n",
    "\n",
    "historic, current = split_data(data, train_ratio=0.5, split=\"temporal\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_train, df_test = split_data(data, split=\"loo\", leave_out=[latest_case_id_col])\n",
    "\n",
    "\n",
    "data = data.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "df_train = df_train.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "df_test = df_test.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "\n",
    "df_without_last = df_train.groupby('UID').apply(remove_last_row).reset_index(drop=True)\n",
    "df_without_last_test = df_test.groupby('UID').apply(remove_last_row).reset_index(drop=True)\n",
    "\n",
    "target = df_without_last['Target'].values\n",
    "# mask = np.isnan(target)\n",
    "# target = target[~mask]\n",
    "\n",
    "target_test = df_without_last_test['Target'].values\n",
    "# mask = np.isnan(target_test)\n",
    "# target_test = target_test[~mask]\n",
    "\n",
    "if method == 'Catboost':\n",
    "    # Create the CatBoostRegressor model\n",
    "    model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='MAE', verbose=0)\n",
    "    model.fit(df_without_last[features+['Cluster']], target)\n",
    "\n",
    "if method == 'HMM':\n",
    "    # Create an instance of the HMM model\n",
    "    model = hmm.GaussianHMM(n_components=7)  # Specify the number of hidden states\n",
    "    model.fit(df_without_last[features+['Cluster']])\n",
    "\n",
    "# Make predictions on the testing data\n",
    "preds = model.predict(df_without_last_test[features+['Cluster']])\n",
    "\n",
    "true_conc_glu = df_without_last_test['Target_orig'].to_numpy()\n",
    "preds_scaled = scalers[target_col].inverse_transform(preds.reshape(-1, 1))\n",
    "# preds_scaled = np.expm1(preds)\n",
    "\n",
    "results_folder = f'results_figures_{method}_rerun'\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "plt.plot(true_conc_glu, label='True Values')\n",
    "plt.plot(preds_scaled, label='Predicted Values')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Titer (g/L)')\n",
    "plt.title(f'True vs Predicted Titer for UID: {bioreactor}')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(results_folder, f'{bioreactor}.png'))\n",
    "plt.close()\n",
    "\n",
    "MAE_t = mean_absolute_error(true_conc_glu, preds_scaled)\n",
    "MSE_t = mean_squared_error(true_conc_glu, preds_scaled)\n",
    "# RMSE_g = mean_squared_error(true_conc_glu, conc_glucose, squared=False)\n",
    "RMSE_t = math.sqrt(MSE_t)\n",
    "r2_t = r_squared = r2_score(true_conc_glu, preds_scaled)\n",
    "mape_t = mean_absolute_percentage_error(true_conc_glu, preds_scaled)\n",
    "\n",
    "results[bioreactor] = {'titer_MAE': MAE_t, 'titer_MSE': MSE_t, 'titer_RMSE':RMSE_t, 'titer_R2': r2_t, 'titer_MAPE': mape_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results).T\n",
    "# catboost regular\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df_results[df_results.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709eb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results).T\n",
    "# catboost regular ـ old results with fewer experiments\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df_results[df_results.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553bbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results).T\n",
    "# HMM regular \n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df_results[df_results.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a trained model named 'model' and a dataset named 'X'\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(df_train[features])\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 20)) \n",
    "shap.summary_plot(shap_values, df_train[features], plot_type='bar', show=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e61c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "method = 'Catboost'\n",
    "for bioreactor in UIDs:\n",
    "    data = df_normalized.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "    data['Target'] = data[target_col].shift(-1)\n",
    "    data['Target_orig'] = data['Titer (g/L) original'].shift(-1)\n",
    "    data['Target_log'] = np.log1p(data['Target_orig']) \n",
    "    df_train, df_test = split_data(data, split=\"loo\", leave_out=[bioreactor])\n",
    "\n",
    "    \n",
    "    data = data.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "    df_train = df_train.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "    df_test = df_test.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "    \n",
    "    df_without_last = df_train.groupby('UID').apply(remove_last_row).reset_index(drop=True)\n",
    "    df_without_last_test = df_test.groupby('UID').apply(remove_last_row).reset_index(drop=True)\n",
    "\n",
    "    target = df_without_last['Target_log'].values\n",
    "    # mask = np.isnan(target)\n",
    "    # target = target[~mask]\n",
    "\n",
    "    target_test = df_without_last_test['Target_log'].values\n",
    "    # mask = np.isnan(target_test)\n",
    "    # target_test = target_test[~mask]\n",
    "    \n",
    "    if method == 'Catboost':\n",
    "        # Create the CatBoostRegressor model\n",
    "        model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, loss_function='MAE', verbose=0)\n",
    "        model.fit(df_without_last[features], target)\n",
    "\n",
    "    if method == 'HMM':\n",
    "        # Create an instance of the HMM model\n",
    "        model = hmm.GaussianHMM(n_components=7)  # Specify the number of hidden states\n",
    "        model.fit(df_without_last[features])\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    preds = model.predict(df_without_last_test[features])\n",
    "\n",
    "    true_conc_glu = df_without_last_test['Target_orig'].to_numpy()\n",
    "    # preds_scaled = scalers[target_col].inverse_transform(preds.reshape(-1, 1))\n",
    "    preds_scaled = np.expm1(preds)\n",
    "\n",
    "    results_folder = f'results_figures_{method}_log'\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.makedirs(results_folder)\n",
    "\n",
    "    plt.plot(true_conc_glu, label='True Values')\n",
    "    plt.plot(preds_scaled, label='Predicted Values')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Titer (g/L)')\n",
    "    plt.title(f'True vs Predicted Titer for UID: {bioreactor}')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_folder, f'{bioreactor}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    MAE_t = mean_absolute_error(true_conc_glu, preds_scaled)\n",
    "    MSE_t = mean_squared_error(true_conc_glu, preds_scaled)\n",
    "    # RMSE_g = mean_squared_error(true_conc_glu, conc_glucose, squared=False)\n",
    "    RMSE_t = math.sqrt(MSE_t)\n",
    "    r2_t = r_squared = r2_score(true_conc_glu, preds_scaled)\n",
    "    mape_t = mean_absolute_percentage_error(true_conc_glu, preds_scaled)\n",
    "\n",
    "    results[bioreactor] = {'titer_MAE': MAE_t, 'titer_MSE': MSE_t, 'titer_RMSE':RMSE_t, 'titer_R2': r2_t, 'titer_MAPE': mape_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results).T\n",
    "# catboost regular log\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df_results[df_results.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "method = 'Catboost'\n",
    "for bioreactor in UIDs:\n",
    "    data = df_normalized.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "    data['Target'] = data[target_col].shift(-1)\n",
    "    data['Target_orig'] = data['Titer (g/L) original'].shift(-1)\n",
    "    # df['Target'] = df['Titer (g/L) original'].shift(-1)\n",
    "    # df['Target_log'] = np.log1p(df['Target']) \n",
    "    df_train, df_test = split_data(data, split=\"loo\", leave_out=[bioreactor])\n",
    "\n",
    "    \n",
    "    data = data.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "    df_train = df_train.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "    df_test = df_test.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "    \n",
    "    df_without_last = df_train.groupby('UID').apply(remove_last_row).reset_index(drop=True)\n",
    "    df_without_last_test = df_test.groupby('UID').apply(remove_last_row).reset_index(drop=True)\n",
    "\n",
    "    target = df_without_last['Target'].values\n",
    "    # mask = np.isnan(target)\n",
    "    # target = target[~mask]\n",
    "\n",
    "    target_test = df_without_last_test['Target'].values\n",
    "    # mask = np.isnan(target_test)\n",
    "    # target_test = target_test[~mask]\n",
    "\n",
    "    input_data = df_without_last[features].to_numpy().reshape(-1, 1, len(features))\n",
    "    input_data_test = df_without_last_test[features].to_numpy().reshape(-1, 1, len(features))\n",
    "    \n",
    "    # Define LSTM model\n",
    "    model = Sequential()\n",
    "    # model.add(Embedding(input_dim=len(features), output_dim=50, input_length=max_sequence_len))\n",
    "    model.add(LSTM(units=100))\n",
    "    model.add(Dense(units=1, activation='relu'))  # Change the units to 1 for regression\n",
    "    # model.build(input_shape=df_without_last[features].shape)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])  # Use mean squared error loss for regression\n",
    "    \n",
    "    #create checkpoint during training\n",
    "    checkpoint_path = f\"model_checkpoints/model_checkpoints_dataBricksTiter/training_without_{bioreactor}/cp.ckpt/checkpoint.weights.h5\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    try:\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    except FileExistsError:\n",
    "        # directory already exists\n",
    "        pass\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only=True, verbose=1)\n",
    "    \n",
    "    try:\n",
    "        model.fit(input_data, target, epochs=50, callbacks=[cp_callback], verbose=2)\n",
    "    except InvalidArgumentError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    # Loads the weights\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "    # Re-evaluate the model\n",
    "    loss, acc = model.evaluate(input_data_test, target_test, verbose=2)\n",
    "    print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    \n",
    "    with open('out.txt', 'a') as f:\n",
    "        print(\"{}, accuracy: {:5.2f}%\\n\".format(bioreactor, (100 * acc)), file=f)\n",
    "\n",
    "    preds = model.predict(input_data_test)\n",
    "\n",
    "    true_conc_glu = df_without_last_test['Target_orig'].to_numpy()\n",
    "    preds_scaled = scalers[target_col].inverse_transform(preds.reshape(-1, 1))\n",
    "    # preds_scaled = np.expm1(preds)\n",
    "\n",
    "    results_folder = f'results_figures_LSTM'\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.makedirs(results_folder)\n",
    "\n",
    "    plt.plot(true_conc_glu, label='True Values')\n",
    "    plt.plot(preds_scaled, label='Predicted Values')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Titer (g/L)')\n",
    "    plt.title(f'True vs Predicted Titer for UID: {bioreactor}')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_folder, f'{bioreactor}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    MAE_t = mean_absolute_error(true_conc_glu, preds_scaled)\n",
    "    MSE_t = mean_squared_error(true_conc_glu, preds_scaled)\n",
    "    # RMSE_g = mean_squared_error(true_conc_glu, conc_glucose, squared=False)\n",
    "    RMSE_t = math.sqrt(MSE_t)\n",
    "    r2_t = r_squared = r2_score(true_conc_glu, preds_scaled)\n",
    "    mape_t = mean_absolute_percentage_error(true_conc_glu, preds_scaled)\n",
    "\n",
    "    results[bioreactor] = {'titer_MAE': MAE_t, 'titer_MSE': MSE_t, 'titer_RMSE':RMSE_t, 'titer_R2': r2_t, 'titer_MAPE': mape_t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results).T\n",
    "# lstm regular no sequence\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df_results[df_results.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042135c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for bioreactor in UIDs:\n",
    "    data = df_normalized.sort_values([case_id_col, work_day_col], ascending=True, kind='mergesort')\n",
    "    data['Target'] = data[target_col].shift(-1)\n",
    "    data['Target_orig'] = data['Titer (g/L) original'].shift(-1)\n",
    "    # df['Target'] = df['Titer (g/L) original'].shift(-1)\n",
    "    # df['Target_log'] = np.log1p(df['Target']) \n",
    "    df_train, df_test = split_data(data, split=\"loo\", leave_out=[bioreactor])\n",
    "\n",
    "    \n",
    "    data = data.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "    df_train = df_train.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "    df_test = df_test.groupby('UID').apply(lambda x: x.sort_values(by=work_day_col)).reset_index(drop=True)\n",
    "    \n",
    "    # Group by 'UID' and concatenate values of 'value' column into a string\n",
    "    sequences_all =data.groupby('UID').apply(lambda x: ' '.join(str(v) for v in x['Cluster'])).tolist()\n",
    "    sequences = df_train.groupby('UID').apply(lambda x: ' '.join(str(v) for v in x['Cluster'])).tolist()\n",
    "    sequences_test = df_test.groupby('UID').apply(lambda x: ' '.join(str(v) for v in x['Cluster'])).tolist()\n",
    "    \n",
    "    df_without_last = df_train.groupby('UID').apply(remove_last_row).reset_index(drop=True)\n",
    "    df_without_last_test = df_test.groupby('UID').apply(remove_last_row).reset_index(drop=True)\n",
    "    \n",
    "    vocab_size, max_sequence_len = get_size_max_len(sequences_all)\n",
    "    input_sequences, target_sequences = tokenize_and_pad(sequences, max_sequence_len)\n",
    "    input_sequences_test, target_sequences_test = tokenize_and_pad(sequences_test, max_sequence_len)\n",
    "\n",
    "    target = df_without_last['Target'].values\n",
    "    # mask = np.isnan(target)\n",
    "    # target = target[~mask]\n",
    "\n",
    "    target_test = df_without_last_test['Target'].values\n",
    "    # mask = np.isnan(target_test)\n",
    "    # target_test = target_test[~mask]\n",
    "    \n",
    "    # Define LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=50, input_length=max_sequence_len))\n",
    "    model.add(LSTM(units=100))\n",
    "    model.add(Dense(units=1, activation='relu'))  # Change the units to 1 for regression\n",
    "    # model.build(input_shape=df_without_last[features].shape)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])  # Use mean squared error loss for regression\n",
    "    \n",
    "    #create checkpoint during training\n",
    "    checkpoint_path = f\"model_checkpoints/model_checkpoints_dataBricksTiterCluster/training_without_{bioreactor}/cp.ckpt/checkpoint.weights.h5\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    try:\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    except FileExistsError:\n",
    "        # directory already exists\n",
    "        pass\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only=True, verbose=1)\n",
    "    \n",
    "    try:\n",
    "        model.fit(input_sequences, target, epochs=50, callbacks=[cp_callback], verbose=2)\n",
    "    except InvalidArgumentError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    # Loads the weights\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "    # Re-evaluate the model\n",
    "    loss, acc = model.evaluate(input_sequences_test, target_test, verbose=2)\n",
    "    print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    \n",
    "    with open('out.txt', 'a') as f:\n",
    "        print(\"{}, accuracy: {:5.2f}%\\n\".format(bioreactor, (100 * acc)), file=f)\n",
    "\n",
    "    preds = model.predict(input_sequences_test)\n",
    "\n",
    "    true_conc_glu = df_without_last_test['Target_orig'].to_numpy()\n",
    "    preds_scaled = scalers[target_col].inverse_transform(preds.reshape(-1, 1))\n",
    "    # preds_scaled = np.expm1(preds)\n",
    "\n",
    "    results_folder = f'results_figures_LSTM_cluster'\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.makedirs(results_folder)\n",
    "\n",
    "    plt.plot(true_conc_glu, label='True Values')\n",
    "    plt.plot(preds_scaled, label='Predicted Values')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Titer (g/L)')\n",
    "    plt.title(f'True vs Predicted Titer for UID: {bioreactor}')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_folder, f'{bioreactor}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    MAE_t = mean_absolute_error(true_conc_glu, preds_scaled)\n",
    "    MSE_t = mean_squared_error(true_conc_glu, preds_scaled)\n",
    "    # RMSE_g = mean_squared_error(true_conc_glu, conc_glucose, squared=False)\n",
    "    RMSE_t = math.sqrt(MSE_t)\n",
    "    r2_t = r_squared = r2_score(true_conc_glu, preds_scaled)\n",
    "    mape_t = mean_absolute_percentage_error(true_conc_glu, preds_scaled)\n",
    "\n",
    "    results[bioreactor] = {'titer_MAE': MAE_t, 'titer_MSE': MSE_t, 'titer_RMSE':RMSE_t, 'titer_R2': r2_t, 'titer_MAPE': mape_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ebbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results).T\n",
    "# lstm regular cluster sequence\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df_results[df_results.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer\n",
    "model.add(Conv2D(5, (3, 3), strides=(1, 1), padding='valid', activation='relu', input_shape=(10, 10, 1)))\n",
    "\n",
    "# Add the max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# Flatten the output from the previous layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the fully connected layer\n",
    "model.add(Dense(6, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c4a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_dim=10, kernel_size=3, strrides=1, padding='None'))\n",
    "model.add(MaxPool2D(units=100))\n",
    "model.add(Dense(units=1, activation='relu'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
